<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Zeebe Chaos Blog</title>
        <link>https://zeebe-io.github.io/zeebe-chaos/</link>
        <description>Zeebe Chaos Blog</description>
        <lastBuildDate>Thu, 12 Dec 2024 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[News from Camunda Exporter project]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project</guid>
            <pubDate>Thu, 12 Dec 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[In this Chaos day, we want to verify the current state of the exporter project and run benchmarks with it. Comparing]]></description>
            <content:encoded><![CDATA[<p>In this Chaos day, we want to verify the current state of the exporter project and run benchmarks with it. Comparing
with a previous version (v8.6.6) should give us a good hint on the current state and potential improvements.</p>
<p><strong>TL;DR;</strong> The latency of user data availability has improved due to our architecture change, but we still need to fix some bugs before our planned release of the Camunda Exporter. This experiment allows us to detect three new bugs, fixing this should allow us to make the system more stable.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">â€‹</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="benchmarks">Benchmarks<a href="https://zeebe-io.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#benchmarks" class="hash-link" aria-label="Direct link to Benchmarks" title="Direct link to Benchmarks">â€‹</a></h3>
<p>We have seen in previous experiments and benchmarks that the realistic benchmarks are not yet totally reliable, as they seem to overload at some point the system. This can happen if there is a hiccup and jobs take longer to process. Jobs in the queue are getting delayed, and time out, they are sent out to different workers, but we will reach them at some point again the jobs, and we will publish also for this job a message. This in general increases the load of the system as we have to timeout jobs, we have to handle additional message publish, etc.</p>
<p>Additionally, message publish can be rejected, when this happens we wait for another timeout adding again load on the system, more and more retries happen, etc. This breaks the benchmark performance.</p>
<p>To avoid this, we reduce the benchmark payload for now, which is in charge of creating multiple instances and call activities, etc. To be specific, they reduced the items from 50 to 5
but scaled the starter to start more instances. With this payload, we can scale more fine granular. Each instance can create 5 sub-instances, when creating three process instances  we create effectively 15 instances/token.</p>
<p>As this benchmark runs quite stable, it allows us to better compare the latency between base and main.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="details-experiment">Details Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#details-experiment" class="hash-link" aria-label="Direct link to Details Experiment" title="Direct link to Details Experiment">â€‹</a></h3>
<p>We will run two benchmarks one against 8.6.6, call based, and one against the current main branch (commit a1609130).</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>When running the base and the main and comparing each other we expect that the general throughput should be similar.
Furthermore, we expect that the latency until the user sees data (or data is written into ES and searchable) should be lowered on the main branch rather than on the base.</p>
<p>Note: Right now we don't have a good metric to measure that data is available for the user, we plan to implement this in the starter benchmark application at some point via querying the REST API. For now, we calculate different average latencies together, whereas we take as elastic search flush a constant of 2 seconds.</p>
<p>We expect a reduction of latency as we reduce one additional hop/usage of ES as intermediate storage, before aggregation.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="base">Base<a href="https://zeebe-io.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#base" class="hash-link" aria-label="Direct link to Base" title="Direct link to Base">â€‹</a></h4>
<p><img decoding="async" loading="lazy" alt="current-8.6" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/current-miro-659b193b670b1b604ebb32ff30b067a4.png" width="1096" height="885" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="main">Main<a href="https://zeebe-io.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#main" class="hash-link" aria-label="Direct link to Main" title="Direct link to Main">â€‹</a></h4>
<p><img decoding="async" loading="lazy" alt="main-target" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/target-1781d302fcf5b933b427a8f5d5df7bd7.png" width="1114" height="736" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>We have set up both benchmarks, running as described above with changed payloads.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="general-performance">General Performance<a href="https://zeebe-io.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#general-performance" class="hash-link" aria-label="Direct link to General Performance" title="Direct link to General Performance">â€‹</a></h4>
<p>The general throughput performance looks similar. The resource consumption looks similar as well, but we didn't investigate this more deeply. Will be done separate.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="base-general">Base general<a href="https://zeebe-io.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#base-general" class="hash-link" aria-label="Direct link to Base general" title="Direct link to Base general">â€‹</a></h5>
<p><img decoding="async" loading="lazy" alt="base-general" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/base-general-452effab191f32fcf5a140949ec5a024.png" width="1901" height="780" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="main-general">Main general<a href="https://zeebe-io.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#main-general" class="hash-link" aria-label="Direct link to Main general" title="Direct link to Main general">â€‹</a></h5>
<p><img decoding="async" loading="lazy" alt="main-general" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/main-general-a2f75f96be9f6682c54ab3cdfb931a8f.png" width="1889" height="784" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="latency">Latency<a href="https://zeebe-io.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#latency" class="hash-link" aria-label="Direct link to Latency" title="Direct link to Latency">â€‹</a></h4>
<p>This experiment aims to show the difference in the data availability for the user.</p>
<p>In order to better visualize the dashboard has been adjusted for this experiment.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="base-latency">Base latency<a href="https://zeebe-io.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#base-latency" class="hash-link" aria-label="Direct link to Base latency" title="Direct link to Base latency">â€‹</a></h5>
<p><img decoding="async" loading="lazy" alt="base-latency" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/base-latencies-tree-17aa593ad5dc16c9ca89726c38155b82.png" width="1134" height="793" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="main-latency">Main latency<a href="https://zeebe-io.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#main-latency" class="hash-link" aria-label="Direct link to Main latency" title="Direct link to Main latency">â€‹</a></h5>
<p>As we expected we were able to reduce the latency data is available for the user by the additional ES flush, reducing it by ~2 seconds.</p>
<p><img decoding="async" loading="lazy" alt="main-latency" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/main-latencies-tree-7908eb4f973bd8e21f5fab8b2aec36bb.png" width="1078" height="581" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="result">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#result" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">â€‹</a></h3>
<p>We were able to show that the latency has been reduced under normal load.</p>
<p><strong>Note:</strong> Be aware this experiment only runs benchmarks with less-to-normal load, on higher load this might change, and need to be tested separately.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="found-bugs">Found Bugs<a href="https://zeebe-io.github.io/zeebe-chaos/2024/12/12/News-from-Camunda-Exporter-project#found-bugs" class="hash-link" aria-label="Direct link to Found Bugs" title="Direct link to Found Bugs">â€‹</a></h4>
<p>Within the experiment, we run into several other issues. Especially after running for a while, when pods got restarted and importer have been enabled, the Camunda Exporter broke.</p>
<p><img decoding="async" loading="lazy" alt="exporting-fail" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exporting-fail-2ddb3996ac30f721fe4e9a1ec8fcce7a.png" width="951" height="449" class="img_ev3q"></p>
<p>This caused to increase in the latency.</p>
<p><img decoding="async" loading="lazy" alt="exporting-fail-latency" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exporting-fail-latency-15efaf79627febc56dbe8ee0247c87d3.png" width="1888" height="193" class="img_ev3q"></p>
<p>The exporter was not able to detect correctly anymore that the importing was done but was still flushing periodically (which is as well wrong)</p>
<p>See related GitHub issue(s)</p>
<ul>
<li><a href="https://github.com/camunda/camunda/issues/26046" target="_blank" rel="noopener noreferrer">Importer(s) are not communicating import done correctly</a></li>
<li><a href="https://github.com/camunda/camunda/issues/26047" target="_blank" rel="noopener noreferrer">Exporter flushes periodically even when importer not completed</a></li>
</ul>
<p>Furthermore, based on logs we saw that the treePath hasn't been published correctly in the Exporter.</p>
<ul>
<li><a href="https://github.com/camunda/camunda/issues/26048" target="_blank" rel="noopener noreferrer">Camunda Exporter is not able to consume treePath</a></li>
</ul>]]></content:encoded>
            <category>availability</category>
        </item>
        <item>
            <title><![CDATA[Impact of Camunda Exporter on processing performance]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance</guid>
            <pubDate>Thu, 14 Nov 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[In our last Chaos day we experimented with the Camunda Exporter MVP. After our MVP we continued with Iteration 2, where we migrated the Archiver deployments and added a new Migration component (allows us to harmonize indices).]]></description>
            <content:encoded><![CDATA[<p>In our <a href="https://zeebe-io.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP">last Chaos day</a> we experimented with the Camunda Exporter MVP. After our MVP we continued with Iteration 2, where we migrated the Archiver deployments and added a new Migration component (allows us to harmonize indices).</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/it2-migration-1c91d1203aba0c2d454ce583eac8703c.png" width="1088" height="888" class="img_ev3q"></p>
<p>Additionally, <a href="https://github.com/zeebe-io/benchmark-helm/pull/202" target="_blank" rel="noopener noreferrer">some fixes and improvements</a> have been done to the realistic benchmarks that should allow us to better compare the general performance with a realistic good performing benchmark.</p>
<p>Actually, this is what we want to explore and experiment with today.</p>
<ul>
<li>Does the Camunda Exporter (since the last benchmark) impact performance of the overall system?<!-- -->
<ul>
<li>If so how?</li>
</ul>
</li>
<li>How can we potentially mitigate this?</li>
</ul>
<p><strong>TL;DR;</strong> Today's, results showed that enabling the Camunda Exporter causes a 25% processing throughput drop. We identified the CPU as a bottleneck. It seems to be mitigated by either adjusting the CPU requests or removing the ES exporter. With these results, we are equipped to make further investigations and decisions.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="benchmarks">Benchmarks<a href="https://zeebe-io.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#benchmarks" class="hash-link" aria-label="Direct link to Benchmarks" title="Direct link to Benchmarks">â€‹</a></h2>
<p>As in the <a href="https://zeebe-io.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP">last Chaos day</a> we use the new realistic benchmarks, that contain a much more complex process model and workload.
We recently found some smaller issues in our benchmarks, related to <a href="https://github.com/zeebe-io/benchmark-helm/pull/204" target="_blank" rel="noopener noreferrer">CPU throttling</a> and <a href="https://github.com/zeebe-io/benchmark-helm/pull/202" target="_blank" rel="noopener noreferrer">undersized workers</a>, these issues have been fixed. This allowed us to reach a much better workload/throughput on our weekly benchmarks, which we take here as a base for our comparison.</p>
<p>The newest benchmark helm charts have been updated to the first <a href="https://github.com/zeebe-io/benchmark-helm/releases/tag/zeebe-benchmark-0.3.8" target="_blank" rel="noopener noreferrer">Camunda Platform alpha1</a>, which includes the Camunda Exporter.</p>
<p>Today we run the following benchmarks</p>
<ul>
<li>Use Camunda Exporter, with disabled Importer in our benchmark</li>
<li>Use Camunda Exporter, with disabled Importer and disabled ES exporter</li>
<li>Use Camunda Exporter, with disabled Importer and higher CPU on brokers</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="benchmark-base">Benchmark: Base<a href="https://zeebe-io.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#benchmark-base" class="hash-link" aria-label="Direct link to Benchmark: Base" title="Direct link to Benchmark: Base">â€‹</a></h3>
<p>As we can see we can have a healthy cluster with a stable load where we reach to complete ~50 process instances, with that ~100 tasks, per second. All of this with a low backpressure.</p>
<p><img decoding="async" loading="lazy" alt="general" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/base-general-0d9b87e3c4c22e9a88803bb3d6c65356.png" width="2213" height="863" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="benchmark-camunda-exporter">Benchmark: Camunda Exporter<a href="https://zeebe-io.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#benchmark-camunda-exporter" class="hash-link" aria-label="Direct link to Benchmark: Camunda Exporter" title="Direct link to Benchmark: Camunda Exporter">â€‹</a></h3>
<p>When running our benchmarks with the Camunda Exporter the first thing we can observe is that the backpressure is much higher and the throughput went down by ~25-30%. We are now able to complete ~36 process instances, meaning 72 tasks, per second.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/it2-exporter-general-bb19c0d984757686f856a5e0817987e8.png" width="2216" height="870" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="latency">Latency<a href="https://zeebe-io.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#latency" class="hash-link" aria-label="Direct link to Latency" title="Direct link to Latency">â€‹</a></h4>
<p>Looking at the processing latency we can observe a significant increase</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="base">Base<a href="https://zeebe-io.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#base" class="hash-link" aria-label="Direct link to Base" title="Direct link to Base">â€‹</a></h5>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/base-latency-53b85441222c4d658fe76896d4e970c7.png" width="2237" height="332" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/base-latency2-77df15ea527525cc0e2a17e7f2394435.png" width="2230" height="569" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="camunda-exporter">Camunda Exporter<a href="https://zeebe-io.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#camunda-exporter" class="hash-link" aria-label="Direct link to Camunda Exporter" title="Direct link to Camunda Exporter">â€‹</a></h5>
<p>The process instance execution p99 has been increased from ~4s to +60s, the p50 went from ~0,5s to ~3,7s.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/it2-exporter-latency-1c325d61ad7921f9fd60a5174f232047.png" width="2223" height="324" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/it2-exporter-latency2-e7fbece39a4cf20fcf5e7a9086fe7798.png" width="2228" height="562" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="cpu">CPU<a href="https://zeebe-io.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#cpu" class="hash-link" aria-label="Direct link to CPU" title="Direct link to CPU">â€‹</a></h4>
<p>Investing this, we can look at the CPU. On our base Benchmark, we have CPU throttling at around 20%.</p>
<p><img decoding="async" loading="lazy" alt="cpu" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/base-cpu-2bd3f742bb3e63c939f4bcbb2e5abf35.png" width="2227" height="678" class="img_ev3q"></p>
<p>When comparing this with the Camunda Exporter benchmark, we can see that the CPU throttling went up to 80%. The benchmark is close to its limits.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/it2-exporter-cpu-0364f523f3197afc5a588c6a6720a491.png" width="2225" height="678" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="benchmark-without-es-exporter">Benchmark: Without ES exporter<a href="https://zeebe-io.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#benchmark-without-es-exporter" class="hash-link" aria-label="Direct link to Benchmark: Without ES exporter" title="Direct link to Benchmark: Without ES exporter">â€‹</a></h3>
<p>As we have seen the Camunda Exporter, causes the Brokers to consume a lot more CPU. This is kind of  expected as there is much more running now in our system.</p>
<p>As an additional experiment, we want to run the Benchmarks with the Camunda Exporter, without the Elasticsearch exporter. The hypothesis is that we can reduce the resource consumption and use it for the Camunda Exporter. The Elasticsearch exporter is with 8.7, only necessary for Optimize.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/no-es-general-371f07a7a870c2cf0aa69b513f2254da.png" width="1898" height="861" class="img_ev3q"></p>
<p>After setting up the benchmark we can observe that the throughput went back to normal.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="latency-1">Latency<a href="https://zeebe-io.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#latency-1" class="hash-link" aria-label="Direct link to Latency" title="Direct link to Latency">â€‹</a></h4>
<p>The latency is reduced, and we can also observe that it seems to drop over time as well.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/no-es-latency-29c218d2f4f7032be0c97ac70aadc4aa.png" width="1896" height="338" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/no-es-latency2-e8f5eca0ae902ff1a29285d700d489c3.png" width="1896" height="566" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="cpu-1">CPU<a href="https://zeebe-io.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#cpu-1" class="hash-link" aria-label="Direct link to CPU" title="Direct link to CPU">â€‹</a></h4>
<p>The CPU throttling is dropping at some point, which explains the other drop of latency.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/no-es-cpu-df76c342afd4c0e936dca6b8bfd8a1a0.png" width="1889" height="676" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="benchmark-more-cpu">Benchmark: More CPU<a href="https://zeebe-io.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#benchmark-more-cpu" class="hash-link" aria-label="Direct link to Benchmark: More CPU" title="Direct link to Benchmark: More CPU">â€‹</a></h3>
<p>As we're migrating logic from the actual Importer deployment to the Camunda Exporter, we can get rid of such extra deployment and bound resources. Arguably we can use these free resources and assign them to the brokers.</p>
<p>When we look at the Camunda Exporter benchmark, the Operate deployment itself doesn't use many resources and likely don't need the assigned ones.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/it2-exporter-operate-cpu-cd3a0bb1a0ad83932e56e8c228f90a65.png" width="1113" height="313" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/change-resources-90f0b2609a3be8ba06662ba3c003ed93.png" width="1207" height="827" class="img_ev3q"></p>
<p>This change allows us to bring the throughput as well back to normal.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/more-cpu-general-ef1023e3caa361ad74e2ce9292cebeb1.png" width="1898" height="877" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="latency-2">Latency<a href="https://zeebe-io.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#latency-2" class="hash-link" aria-label="Direct link to Latency" title="Direct link to Latency">â€‹</a></h4>
<p>The latency is similar to our base benchmark.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/more-cpu-latency-538c03c7b6b866deaf65d4ac62eeb47c.png" width="1891" height="334" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/more-cpu-latency2-e8a9e06a59bc6acfd6f1485162bfe663.png" width="1897" height="564" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="cpu-2">CPU<a href="https://zeebe-io.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#cpu-2" class="hash-link" aria-label="Direct link to CPU" title="Direct link to CPU">â€‹</a></h4>
<p>The CPU throttling has been reduced to almost zero. Interesting is that we don't use much more CPU resources (just slightly more, before ~1350m now ~1450 CPU). Increasing our requests by a little, allowed us to remove the CPU throttling. This is something we likely want to investigate further.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/more-cpu-cpu-5a2492087066afabd9b25114a27aaa78.png" width="1887" height="680" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="results">Results<a href="https://zeebe-io.github.io/zeebe-chaos/2024/11/14/Impact-of-Camunda-Exporter-on-processing-performance#results" class="hash-link" aria-label="Direct link to Results" title="Direct link to Results">â€‹</a></h3>
<p>As we have seen, introducing (or enabling) the Camunda Exporter, can or will increase our processing latency and reduce our potential processing throughput. This obviously depends on the cluster load.</p>
<p>We were able to pinpoint the problem due to limited resources, to be specific CPU is the bottleneck.</p>
<p>This is expected, as running the Camunda Exporter means we are running more logic inside the Zeebe system.</p>
<p>We can mitigate this with:</p>
<ul>
<li>reducing load from the system, via disabling the additional ES exporter</li>
<li>give the system more resources</li>
</ul>]]></content:encoded>
            <category>performance</category>
        </item>
        <item>
            <title><![CDATA[Camunda Exporter MVP]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP</guid>
            <pubDate>Thu, 24 Oct 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[After a long pause, I come back with an interesting topic to share and experiment with. Right now we are re-architecture]]></description>
            <content:encoded><![CDATA[<p>After a long pause, I come back with an interesting topic to share and experiment with. Right now we are re-architecture
Camunda 8. One important part (which I'm contributing to) is to get rid of Webapps Importer/Archivers and move
data aggregation closer to the engine (inside a Zeebe Exporter).</p>
<p>Today, I want to experiment with the first increment/iteration of our so-called MVP. The MVP targets green field installations where you simply deploy Camunda (with a new Camunda Exporter enabled) without Importers.</p>
<p><strong>TL;DR;</strong> All our experiments were successful. The MVP is a success, and we are looking forward to further improvements and additions. Next stop Iteration 2: Adding Archiving historic data and preparing for data migration (and polishing MVP).</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="camunda-exporter">Camunda Exporter<a href="https://zeebe-io.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#camunda-exporter" class="hash-link" aria-label="Direct link to Camunda Exporter" title="Direct link to Camunda Exporter">â€‹</a></h2>
<p>The <a href="https://github.com/camunda/product-hub/issues/2128" target="_blank" rel="noopener noreferrer">Camunda Exporter project</a> deserves a complete own blog post, here is just a short summary.</p>
<p>Our current Camunda architecture looks something like this (simplified).</p>
<p><img decoding="async" loading="lazy" alt="current" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/current-miro-659b193b670b1b604ebb32ff30b067a4.png" width="1096" height="885" class="img_ev3q"></p>
<p>It has certain challenges, like:</p>
<ul>
<li>Space: duplication of data in ES</li>
<li>Maintenance: duplication of importer and archiver logic</li>
<li>Performance: Round trip (delay) of data visible to the user</li>
<li>Complexity: installation and operational complexity (we need separate pods to deploy)</li>
<li>Scalability: The Importer is not scalable in the same way as Zeebe or brokers (and workload) are.</li>
</ul>
<p>These challenges we obviously wanted to overcome and the plan (as mentioned earlier) is to get rid of the need of separate importers and archivers (and in general to have separate application; but this is a different topic).</p>
<p>The plan for this project looks something like this:</p>
<p><img decoding="async" loading="lazy" alt="plan" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/how-brown-field-929f9a23e6dfee9ede15e76b1a134fdc.png" width="1228" height="904" class="img_ev3q"></p>
<p>We plan to:</p>
<ol>
<li>Harmonize the existing indices stored in Elasticsearch/Opensearch<!-- -->
<ul>
<li>Space: Reduce the unnecessary data duplication</li>
</ul>
</li>
<li>Move importer and archiver logic into a new Camunda exporter<!-- -->
<ul>
<li>Performance: This should allow us to reduce one additional hop (as we don't need to use ES/OS as a queue)</li>
<li>Maintenance: Indices and business logic is maintained in one place</li>
<li>Scalability: With this approach, we can scale with partitions, as Camunda Exporters are executed for each partition separately (soon partition scaling will be introduced)</li>
<li>Complexity: The Camunda Exporter will be built-in and shipped with Zeebe/Camunda 8. No additional pod/application is needed.</li>
</ul>
</li>
</ol>
<p>Note: Optimize is right now out of scope (due to time), but will later be part of this as well.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="mvp">MVP<a href="https://zeebe-io.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#mvp" class="hash-link" aria-label="Direct link to MVP" title="Direct link to MVP">â€‹</a></h3>
<p>After we know what we want to achieve what is the Minimum viable product (MVP)?</p>
<p>We have divided the Camunda Exporter in 3-4 iterations. You can see and read more about this <a href="https://github.com/camunda/issues/issues/803" target="_blank" rel="noopener noreferrer">here</a>.</p>
<p>The first iteration contains the MVP (the first breakthrough). Providing the Camunda Exporter with the basic functionality ported from the Operate and Tasklist importers, writing into harmonized indices.</p>
<p>The MVP is targeting green field installations (clean installations) of Camunda 8 with Camunda Exporter without running the old Importer (no data migration yet),</p>
<p><img decoding="async" loading="lazy" alt="mvp" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/it1-mvp-421ca897b91c0d03c1d77adde73b48a7.png" width="1069" height="870" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">â€‹</a></h2>
<p>What I want to verify today, when I deploy the Camunda 8 stack with Camunda Exporter (and Importer disabled):</p>
<ul>
<li>Are webapps schemas created in ES, by the new Camunda Exporter</li>
<li>Is data exported into the indices</li>
<li>Can Operate show data? (right now just checking for basic functionality)</li>
</ul>
<p>Additionally, I would like to understand what the performance looks like, how the system behaves with two ES exporters (the old ES exporter and the new Camunda Exporter), and more.</p>
<p>For our experiment, I use a <a href="https://github.com/camunda/camunda/issues/21472" target="_blank" rel="noopener noreferrer">newly defined realistic benchmark</a> (with a more complex process model). More about this in a separate blog post.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>I can deploy the newest helm charts (alpha stage), by disabling Importer manually, and will be able to use Zeebe and Operate together. See the verifications above.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>As always we use our <a href="https://github.com/zeebe-io/benchmark-helm" target="_blank" rel="noopener noreferrer">benchmark-helm charts</a> (that building on top of our <a href="https://github.com/camunda/camunda-platform-helm" target="_blank" rel="noopener noreferrer">Camunda Platform Helm</a> charts).</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="installation">Installation<a href="https://zeebe-io.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#installation" class="hash-link" aria-label="Direct link to Installation" title="Direct link to Installation">â€‹</a></h3>
<p>I had to adjust our benchmarks to <a href="https://github.com/zeebe-io/benchmark-helm/commit/db682a89788d6c511083ec743c6cf7d358155e3c" target="_blank" rel="noopener noreferrer">use the alpha snapshots </a></p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">dependencies</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> camunda</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">platform</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">repository</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"oci://ghcr.io/camunda/helm"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">version</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"0.0.0-snapshot-alpha"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">condition</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"camunda.enabled"</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>and <a href="https://github.com/zeebe-io/benchmark-helm/commit/aafac6e9ec78e9cfd2e59a5b6f30bf887a4fcbd0" target="_blank" rel="noopener noreferrer">disable the Importer via ENV</a></p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">env</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> CAMUNDA_OPERATE_IMPORTERENABLED</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">value</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"false"</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>With that, we can install our chart:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ helm install zeebe-benchmark-test charts/zeebe-benchmark/ --render-subchart-notes -f charts/zeebe-benchmark/values-realistic-benchmark.yaml --set global.elasticsearch.prefix=null</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="basic-first-verification">Basic First Verification<a href="https://zeebe-io.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#basic-first-verification" class="hash-link" aria-label="Direct link to Basic First Verification" title="Direct link to Basic First Verification">â€‹</a></h3>
<p>After our benchmark chart is deployed we can already see the first time our Camunda Exporter running <!-- -->ðŸŽ‰</p>
<p><img decoding="async" loading="lazy" alt="firsttime" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/first-time-seeing-camunda-exporter-70ed9f616eb84150a74085d4c29a3bff.png" width="1253" height="528" class="img_ev3q"></p>
<p>Worth mentioning that the Camunda Export already comes with some metrics, visible on our Zeebe Dashboard</p>
<p><img decoding="async" loading="lazy" alt="metrics" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/mvp-c8-exporter-metrics-c26a2e069e64c8a894ec4d5ffa718a70.png" width="1293" height="751" class="img_ev3q">
<img decoding="async" loading="lazy" alt="metrics2" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/mvp-c8-exporter-metrics2-062900d6bdddbdc951da85805bf2d89e.png" width="1263" height="407" class="img_ev3q"></p>
<p>The general overview also looks good. No obvious problem.</p>
<p><img decoding="async" loading="lazy" alt="general" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/mvp-general-overview-ee162c7186d9914428efb78c3f57c8f1.png" width="2532" height="812" class="img_ev3q"></p>
<p>Looking into logs we can see that at the start it fails temporarily because ES is not yet ready to accept the schema creation.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">ERROR - Failed to open exporter 'CamundaExporter'. Retrying...</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img decoding="async" loading="lazy" alt="log" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exporter-opened-ed454d2a9960e13dd721f43ff2fe47ec.png" width="1004" height="198" class="img_ev3q"></p>
<p>At some point, the exporter can be opened and the loop stops.</p>
<p>I think generally it shouldn't be an ERROR but more a WARN (but these are details we can fix). Follow-up.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="verify-operate-data">Verify Operate Data<a href="https://zeebe-io.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#verify-operate-data" class="hash-link" aria-label="Direct link to Verify Operate Data" title="Direct link to Verify Operate Data">â€‹</a></h3>
<p>To make sure that Operate is not importing, I checked the Operate dashboard. We can see that there is no Importer metrics. Furthermore, in the configuration and logs we see no indication of importing.</p>
<p><img decoding="async" loading="lazy" alt="op-metrics" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/no-importer-metrics-4adf3f44ee863313bc7db7536fb82476.png" width="2548" height="531" class="img_ev3q"></p>
<p>We can now start to port-forward to operate:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">k port-forward svc/zeebe-benchmark-test-operate 8081:80</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>When opening Operate we see unfortunately no data.</p>
<p><img decoding="async" loading="lazy" alt="operate-no-data" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/mvp-no-data-operate-a93144c5143ac98ec9aef7e9a4b82329.png" width="2448" height="862" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="investigating-missing-data">Investigating missing data<a href="https://zeebe-io.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#investigating-missing-data" class="hash-link" aria-label="Direct link to Investigating missing data" title="Direct link to Investigating missing data">â€‹</a></h4>
<p>We need to understand why there is no data available for Operate.</p>
<p>What we saw is that the Camunda Exporter is open (logs), that it is also makes progress and data is written to elastic (metrics). What we haven't checked Elasticsearch in detail.</p>
<p>Looking into ES dashboard we can see that indices are created, but the Operate indices seem to be empty.</p>
<p><img decoding="async" loading="lazy" alt="es-indices" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/mvp-operate-indices-empty-546f9dc0740acb0c660046b97d81e621.png" width="2531" height="588" class="img_ev3q"></p>
<p>When checking the Zeebe indices:</p>
<p><img decoding="async" loading="lazy" alt="zeebe-indices" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/mvp-zeebe-indices-filled-1125b6776b8ca7d9e08b2c2e4043b3c5.png" width="2542" height="537" class="img_ev3q"></p>
<p>we can see that they are filled. An attentive reader will also chekc that there actuall some prefix problem in the indices.</p>
<p>Thanks to Deepthi which spotted this as well (and told me), we were exporting to the wrong index names. There was a <a href="https://github.com/camunda/camunda-platform-helm/blob/46f6ee9d828439b0b1cf37bae4d135ba5281a832/charts/camunda-platform-alpha/templates/zeebe/configmap.yaml#L66" target="_blank" rel="noopener noreferrer">bug</a> existing in the current alpha Helm chart version.</p>
<p><img decoding="async" loading="lazy" alt="wrong-prefix" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/mvp-wrong-prefix-817f26674c55ba97e399e60d0e7261fe.png" width="2530" height="429" class="img_ev3q"></p>
<p>This has been fixed with <a href="https://github.com/camunda/camunda-platform-helm/pull/2506" target="_blank" rel="noopener noreferrer">PR-2506</a>. Until this gets merged I changed this manually via:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Get the templates </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm template zeebe-benchmark-test charts/zeebe-benchmark/ --render-subchart-notes -f charts/zeebe-benchmark/values-realistic-benchmark.yaml --output-dir templates</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Adjust the config map - remove the prefix</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">vim templates/zeebe-benchmark/charts/camunda-platform/templates/zeebe/configmap.yaml </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Apply all manifests</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">k apply -f . --recursive</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<blockquote>
<p><strong>Note:</strong></p>
<p>I also tried</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">helm template charts/zeebe-benchmark/ --version 0.0.0-snapshot-alpha     --show-only charts/camunda-platform/templates/zeebe/configmap.yaml --set global.elasticsearch.prefix=null</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>But this breaks the ES exporter.</p>
</blockquote>
<p>With this change we were can see that indices are correctly created and filled!</p>
<p><img decoding="async" loading="lazy" alt="indices-filled" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/mvp-fixed-prefix-indices-1fb3dae117514d6a849127d776edad93.png" width="1269" height="390" class="img_ev3q"></p>
<p>Finally, we are able to see data in Operate! <!-- -->ðŸš€<!-- --> <strong>WITHOUT ANY IMPORTER.</strong></p>
<p><img decoding="async" loading="lazy" alt="mvp-operate-data.png" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/mvp-operate-data-eb8f2bc8a636a72be68760c53817192a.png" width="1258" height="524" class="img_ev3q">
<img decoding="async" loading="lazy" alt="mvp-operate-instance.png" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/mvp-operate-instance-27c3cfefb626236cc70f14ae7fb55d17.png" width="2536" height="926" class="img_ev3q">
<img decoding="async" loading="lazy" alt="mvp-operate-pi.png" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/mvp-operate-pi-9a30d4606bee4f381e9643812a3b0471.png" width="1243" height="888" class="img_ev3q">
<img decoding="async" loading="lazy" alt="operate-overview" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/mvp-decisions-cea9463cdf38ecc36a14fbc131985a9b.png" width="1261" height="944" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://zeebe-io.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">â€‹</a></h2>
<p>The MVP is a success. We were able to provide a Camunda Exporter that creates the necessary harmonized schema and migrate the basic business logic from Operate and Tasklist into the exporter. This allows us to use only the Camunda Exporter without running any Importer pod/application.</p>
<p>Great work Team <!-- -->ðŸš€<!-- --> <!-- -->ðŸŽ‰</p>
<p><strong>Next stop:</strong></p>
<p><em>Iteration 2:</em></p>
<ul>
<li>Implementing migration logic for old data</li>
<li>Moving Archiver logic (for historical data) into the Exporter</li>
<li>Polish MVP state (add some missing features like TreePath, etc.)</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="additional-notes">Additional notes<a href="https://zeebe-io.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#additional-notes" class="hash-link" aria-label="Direct link to Additional notes" title="Direct link to Additional notes">â€‹</a></h3>
<p>This time I was not able to deep dive into performance or stability for this change. I plan to do this next.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="found-bugs">Found Bugs<a href="https://zeebe-io.github.io/zeebe-chaos/2024/10/24/Camunda-Exporter-MVP#found-bugs" class="hash-link" aria-label="Direct link to Found Bugs" title="Direct link to Found Bugs">â€‹</a></h3>
<ul>
<li>ERROR log level for logs that are transitive</li>
<li>Auth/User indices are still prefixed with identity</li>
</ul>]]></content:encoded>
            <category>performance</category>
        </item>
        <item>
            <title><![CDATA[Optimizing cluster sizing using a real world benchmark]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2024/10/14/Optimizing-cluster-sizing-using-a-real-world-benchmark</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2024/10/14/Optimizing-cluster-sizing-using-a-real-world-benchmark</guid>
            <pubDate>Mon, 14 Oct 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[Our first goal of this experiment is to use a benchmarks to]]></description>
            <content:encoded><![CDATA[<p>Our first goal of this experiment is to use a benchmarks to
derive new optimized cluster configuration that can handle
at least 100 tasks per second, while maintaining low backpressure and low latency.</p>
<p>For our experiment, we use a newly defined realistic benchmark (with a more complex process model). More about this in a separate blog post.</p>
<p>The second goal is to scale out optimized cluster configuration
resources linearly and see if the performance scales accordingly.</p>
<p><strong>TL;DR;</strong></p>
<p>We used a realistic benchmark to derive a new
cluster configuration based on previous requirements.</p>
<p>When we scale this base configuration linearly we see that the performance
increases almost linearly as well, while maintaining low
backpressure and low latency.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2024/10/14/Optimizing-cluster-sizing-using-a-real-world-benchmark#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">â€‹</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2024/10/14/Optimizing-cluster-sizing-using-a-real-world-benchmark#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>We expect that we can find a cluster configuration that can handle at 100
tasks second to be significantly reduced in resources in relation to our
smaller clusters (G3-S HA Plan) since these can process significantly above
our initial target.</p>
<p>We also expect that we can scale this base configuration linearly, and that
the processing tasks rate to grow initially a bit faster than linearly due to
the lower relative overhead, and if we keep expanding further to flatten due
to the partition count being a bottleneck.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2024/10/14/Optimizing-cluster-sizing-using-a-real-world-benchmark#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="minimal-requirements-for-our-cluster">Minimal Requirements for our Cluster<a href="https://zeebe-io.github.io/zeebe-chaos/2024/10/14/Optimizing-cluster-sizing-using-a-real-world-benchmark#minimal-requirements-for-our-cluster" class="hash-link" aria-label="Direct link to Minimal Requirements for our Cluster" title="Direct link to Minimal Requirements for our Cluster">â€‹</a></h4>
<p>Based on known customer usage, and our own previous experiments, we
determined that the new cluster would need to create and complete a
baseline of 100 tasks per second, or about 8.6 million tasks per day.</p>
<p>Other metrics that we want to preserve and keep track are the backpressure
to preserve user experience, guarantee that exporting speed can keep up
with the processing speed, write-to-import latency which tells us how long
it takes for a record to be written to being imported by our other
apps such as the operator.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="reverse-engineering-the-cluster-configuration">Reverse Engineering the Cluster Configuration<a href="https://zeebe-io.github.io/zeebe-chaos/2024/10/14/Optimizing-cluster-sizing-using-a-real-world-benchmark#reverse-engineering-the-cluster-configuration" class="hash-link" aria-label="Direct link to Reverse Engineering the Cluster Configuration" title="Direct link to Reverse Engineering the Cluster Configuration">â€‹</a></h4>
<p>For our new configurations the only resources that we are going to change
are the ones relevant to the factors described above. These are the
resources allocated to our zeebe-brokers, gateway and elasticSearch.</p>
<p>Our starting point in resources was the configuration for our G3-S HA Plan
as this already had the capability to significantly outperform the current
goal of 100 tasks per second.</p>
<p>The next step was to deploy our realistic benchmark, with a payload of 5
customer disputes per instance and start 7 instances per second, this
generated approximately 120 tasks per second (some buffer was added to guarantee performance).</p>
<p>After this we reduced the resources iteratively until we saw any increase
in backpressure, given that no there was no backlog of records, and no
significant increase in the write to import latency.</p>
<p>The results for our new cluster are specified bellow in the tables, where
our starting cluster configuration is the G3-S HA Plan and the new
configuration cluster is the G3 - BasePackage HA.</p>
<table><thead><tr><th>G3-S HA</th><th>CPU Limit</th><th>Memory Limit in GB</th></tr></thead><tbody><tr><td>operate</td><td>2</td><td>2</td></tr><tr><td>operate.elasticsearch</td><td>6</td><td>6</td></tr><tr><td>optimize</td><td>2</td><td>2</td></tr><tr><td>tasklist</td><td>2</td><td>2</td></tr><tr><td>zeebe.broker</td><td>2.88</td><td>12</td></tr><tr><td>zeebe.gateway</td><td>0.9</td><td>0.8</td></tr><tr><td><strong>TOTAL</strong></td><td><strong>15.78</strong></td><td><strong>24.8</strong></td></tr></tbody></table>
<table><thead><tr><th>G3 - BasePackage HA</th><th>CPU Limit</th><th>Memory Limit in GB</th></tr></thead><tbody><tr><td>operate</td><td>1</td><td>1</td></tr><tr><td>operate.elasticsearch</td><td>3</td><td>4.5</td></tr><tr><td>optimize</td><td>1</td><td>1.6</td></tr><tr><td>tasklist</td><td>1</td><td>1</td></tr><tr><td>zeebe.broker</td><td>1.5</td><td>4.5</td></tr><tr><td>zeebe.gateway</td><td>0.6</td><td>1</td></tr><tr><td><strong>TOTAL</strong></td><td><strong>8.1</strong></td><td><strong>13.6</strong></td></tr></tbody></table>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="reduction-in-resources-for-our-optimized-cluster">Reduction in Resources for our Optimized Cluster<a href="https://zeebe-io.github.io/zeebe-chaos/2024/10/14/Optimizing-cluster-sizing-using-a-real-world-benchmark#reduction-in-resources-for-our-optimized-cluster" class="hash-link" aria-label="Direct link to Reduction in Resources for our Optimized Cluster" title="Direct link to Reduction in Resources for our Optimized Cluster">â€‹</a></h5>
<table><thead><tr><th style="text-align:left"></th><th style="text-align:right">CPU Reduction (%)</th><th style="text-align:right">Memory Reduction (%)</th></tr></thead><tbody><tr><td style="text-align:left">zeebe.broker</td><td style="text-align:right">47.92</td><td style="text-align:right">62.5</td></tr><tr><td style="text-align:left">zeebe.gateway</td><td style="text-align:right">33.33</td><td style="text-align:right">-25.0</td></tr><tr><td style="text-align:left">operate.elasticsearch</td><td style="text-align:right">50.00</td><td style="text-align:right">25.0</td></tr></tbody></table>
<p>Total cluster reduction:</p>
<table><thead><tr><th style="text-align:left"></th><th style="text-align:right">G3-S HA</th><th style="text-align:right">G3 - BasePackage HA</th><th style="text-align:right">Reduction (%)</th></tr></thead><tbody><tr><td style="text-align:left">CPU Limits</td><td style="text-align:right">15.78</td><td style="text-align:right">8.1</td><td style="text-align:right">49</td></tr><tr><td style="text-align:left">Memory Limits</td><td style="text-align:right">24.8</td><td style="text-align:right">13.6</td><td style="text-align:right">45</td></tr></tbody></table>
<p>The process of reducing the hardware requirements was donne initially by
scaling down the resources of the zeebe-broker, gateway and elasticSearch.
The other components were left untouched, as they had no impact in our key
metrics, and were scaled down later in separate experiences to maintain
user experience.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="scaling-out-the-cluster">Scaling out the Cluster<a href="https://zeebe-io.github.io/zeebe-chaos/2024/10/14/Optimizing-cluster-sizing-using-a-real-world-benchmark#scaling-out-the-cluster" class="hash-link" aria-label="Direct link to Scaling out the Cluster" title="Direct link to Scaling out the Cluster">â€‹</a></h4>
<p>Now for the scaling procedure we intend to see if we can linearly increase
the allocated resources and having a corresponding performance increase,
while keeping the backpressure low, low latency, and user experience.</p>
<p>For this we started with the G3 - BasePackage HA configuration and
incremented the load again until we saw any increase in backpressure,
capture our key metrics and repeated the process for the cluster
configuration resources respectively multiplied by 2x, 3x, and 4x.</p>
<p>This means that the resources allocated for our clusters were:</p>
<table><thead><tr><th style="text-align:left"></th><th style="text-align:right">Base 1x</th><th style="text-align:right">Base 2x</th><th style="text-align:right">Base 3x</th><th style="text-align:right">Base 4x</th></tr></thead><tbody><tr><td style="text-align:left">CPU Limits</td><td style="text-align:right">8.7</td><td style="text-align:right">17.4</td><td style="text-align:right">26.1</td><td style="text-align:right">34.8</td></tr><tr><td style="text-align:left">Memory Limits</td><td style="text-align:right">14.9</td><td style="text-align:right">29.8</td><td style="text-align:right">44.7</td><td style="text-align:right">59.6</td></tr></tbody></table>
<p>The results in the table bellow show the performance of our several cluster
configurations:</p>
<table><thead><tr><th style="text-align:left"></th><th style="text-align:right">Base 1x</th><th style="text-align:right">Base 2x</th><th style="text-align:right">Base 3x</th><th style="text-align:right">Base 4x</th></tr></thead><tbody><tr><td style="text-align:left">Process Instances/s</td><td style="text-align:right">7</td><td style="text-align:right">12</td><td style="text-align:right">23</td><td style="text-align:right">27</td></tr><tr><td style="text-align:left">Tasks/s</td><td style="text-align:right">125</td><td style="text-align:right">217</td><td style="text-align:right">414</td><td style="text-align:right">486</td></tr><tr><td style="text-align:left">Average Backpressure</td><td style="text-align:right">2%</td><td style="text-align:right">2%</td><td style="text-align:right">3%</td><td style="text-align:right">6%</td></tr><tr><td style="text-align:left">Write-to-Import Latency</td><td style="text-align:right">90s</td><td style="text-align:right">120s</td><td style="text-align:right">150s</td><td style="text-align:right">390s</td></tr><tr><td style="text-align:left">Write-to-Process Latency</td><td style="text-align:right">140ms</td><td style="text-align:right">89ms</td><td style="text-align:right">200ms</td><td style="text-align:right">160ms</td></tr><tr><td style="text-align:left">Records Processed Rate</td><td style="text-align:right">2500</td><td style="text-align:right">4700</td><td style="text-align:right">7800</td><td style="text-align:right">11400</td></tr><tr><td style="text-align:left">Records Exported Rate</td><td style="text-align:right">2100</td><td style="text-align:right">3900</td><td style="text-align:right">6500</td><td style="text-align:right">9200</td></tr></tbody></table>
<p>This first observations is that the performance scales particularly well by
just adding more resources to the cluster, particularly for a linear
increase of the resources the performance as measured by tasks completed
increases slightly less than linearly (comparing the 1x and 4x task/s we
get 388% the initial rate).</p>
<p>This a very good result as it means that we can scale our system linearly
(at least initially) to handle the expected increase in loads.</p>
<p>Importantly, the backpressure is kept low, and the write-to-import latency
only increases significantly if we leave the cluster running at max rate
for long periods of time. For slightly lower rates the write-to-import
latency is kept in the single digits of seconds or lower tens. This might
imply that a these sustained max rates, the amount records generated starts
to be too much for either ElasticSearch or our web apps that import these
records to handle. Some further investigation could be done here to
investigate the bottleneck.</p>
<p>Another metric also relevant but not shown in this table is the backlog of
records not exported, which kept at almost null through all the experiments
conducted.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-found">Bugs found<a href="https://zeebe-io.github.io/zeebe-chaos/2024/10/14/Optimizing-cluster-sizing-using-a-real-world-benchmark#bugs-found" class="hash-link" aria-label="Direct link to Bugs found" title="Direct link to Bugs found">â€‹</a></h3>
<p>During the initial tests, we had several OOM errors in the gateways pods.
After some investigation, we found that this was exclusive to the Camunda 8.
6.0 version, which consumes more memory in the gateway than the previous
versions. This explains why the gateway memory limits were the only
resource that was increased in the new reduced cluster configuration.</p>]]></content:encoded>
            <category>performance</category>
        </item>
        <item>
            <title><![CDATA[Improve Operate import latency]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency</guid>
            <pubDate>Mon, 19 Aug 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[In our last Chaos Day we experimented with Operate and different load (Zeebe throughput). We observed that a higher load caused a lower import latency in Operate. The conclusion was that it might be related to Zeebe's exporting configuration, which is affected by a higher load.]]></description>
            <content:encoded><![CDATA[<p><a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/16/Operate-load-handling">In our last Chaos Day</a> we experimented with Operate and different load (Zeebe throughput). We observed that a higher load caused a lower import latency in Operate. The conclusion was that it might be related to Zeebe's exporting configuration, which is affected by a higher load.</p>
<p>In today's chaos day we want to verify how different export and import configurations can affect the importing latency.</p>
<p><strong>TL;DR;</strong> We were able to decrease the import latency by ~35% (from 5.7 to 3.7 seconds), by simply reducing the <code>bulk.delay</code> configuration. This worked on low load and even higher load, without significant issues.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="background">Background<a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency#background" class="hash-link" aria-label="Direct link to Background" title="Direct link to Background">â€‹</a></h2>
<p><em>In the following I want to briefly explain a bit more the background of how exporting and importing play together. If you are already aware feel free to jump to the <a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency#chaos-experiment">next section</a>.</em></p>
<hr>
<p>To understand how the importing of Operate is affected and works, we first have to take a look at Zeebe.</p>
<p>Zeebe exports data to Elasticsearch via its Elasticsearch Exporter. The exporter collects data before sending it to Elasticsearch in bulk requests. The amount of data, which is collected in the exporter, is configurable and by default set to 1000 records per batch/bulk. Additionally, there is a memory limit which is taken into account that is set to 10 MB. When the bulk request is reaching that size, the request is sent as well. To cover cases of low load, there is a delay option, which is per default set to 5 seconds. This means, that every 5 seconds the bulk request is sent, even if it is not full.</p>
<p>This explains also the results from <a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/16/Operate-load-handling">our last Chaos Day</a>, where the import latency was around 5 seconds on a lower load.</p>
<p>In the following, we have written down the sequence of steps a command has to take, and its resulting events until it is visible to the user in Operate. This should allow to better understand how and by what the import latency is affected, and what we might want to tune and experiment further.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">User Command is sent to Gateway </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--&gt;Gateway sents Command to the right Broker</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">----&gt;Broker processes command and produces events</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">------&gt;Events are exported by Broker to ES (worst case: 5s flush) </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--------&gt;ES refreshes after one second</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">----------&gt;Operate import processing/rewriting data</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">------------&gt;ES refreshes after one second</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--------------&gt;Operate can query the data -&gt; User can see the data </span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>About Elasticsearch and its default refresh configuration, etc. you can read <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-indexing-speed.html#_unset_or_increase_the_refresh_interval" target="_blank" rel="noopener noreferrer">here</a>.</p>
<p>Based on this, we know we have the following minimum delay:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">delay = 2 seconds (due to ES refresh)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      + (5 seconds from exporter on low load)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      + network delay </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      + processing delay </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      + Exporter and Operate data un/marshaling/processing</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Today, we will experiment with the Elasticsearch exporter configurations to improve the import latency.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">â€‹</a></h2>
<p>As we have seen <a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/16/Operate-load-handling">in a previous chaos day</a> high load affects the importing latency positively. The thesis is that this is due to the export flush delay, which is mostly affecting the exporting on lower load.</p>
<p>Today we want to prove the following:</p>
<blockquote>
<p><strong>Hypothesis</strong></p>
<p>When we set the exporting/flush delay to a lower value (ex. 1 second), we are improving the import latency for lower load scenarios without affecting the system negatively.</p>
</blockquote>
<p>We can define the following <code>unknowns</code>, that we want to explore further as well:</p>
<ul>
<li>It is not clear how lower flush delay affects the system on higher loads.</li>
<li>It is not clear how smaller values (under 1 second) for the flush delay affect the system, no matter of high or low load.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<ol>
<li>When we set the exporting/flush delay to a lower value (ex. 1 second), we are improving the import latency for lower load scenarios without affecting the system negatively.</li>
<li>When we set the exporting/flush delay to a lower value (ex. 1 second), we are improving the import latency for higher load scenarios, <strong>but decreasing the import throughput</strong></li>
<li>When we set the exporting/flush delay to a small value (under 1 second), we are affecting the import throughput negatively</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>As always, we set a base installation up to compare against. The load is moderate-to-low (15 PI/s). We can compare the data from the <a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/16/Operate-load-handling">last chaos day</a> here as well.</p>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Base: Helm install command</summary><div><div class="collapsibleContent_i85q"><pre><p>helm install $(releaseName) $(chartPath) --render-subchart-notes <br>
<!-- -->--set global.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebe.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebe.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebeGateway.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebeGateway.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set starter.rate=5 <br>
<!-- -->--set worker.replicas=1 <br>
<!-- -->--set timer.replicas=1 <br>
<!-- -->--set timer.rate=5 <br>
<!-- -->--set publisher.replicas=1 <br>
<!-- -->--set publisher.rate=5 <br>
<!-- -->--set camunda-platform.operate.enabled=true <br>
<!-- -->--set camunda-platform.operate.image.repository=gcr.io/zeebe-io/operate <br>
<!-- -->--set camunda-platform.operate.image.tag=ck-operate-benchmark <br>
<!-- -->--set camunda-platform.elasticsearch.master.persistence.size=128Gi <br>
<!-- -->--set camunda-platform.zeebe.retention.minimumAge=1d \</p></pre></div></div></details>
<p>We see similar results as on the <a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/16/Operate-load-handling#base">last Chaos day</a>.</p>
<p><img decoding="async" loading="lazy" alt="base-latency" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/base-latency-b7ca1d69a5c6419365516c262ccea9fa.png" width="949" height="340" class="img_ev3q">
<img decoding="async" loading="lazy" alt="base-throughput" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/base-throughput-55ff3e3256fa6ddc44ed107960c6a18d.png" width="948" height="262" class="img_ev3q"></p>
<p>We are able to import around 360 records per second, while Zeebe exports 413. Be aware that some are ignored by Operate.
A record has on average a delay of 5.69 seconds from being written by Zeebe to being imported by Operate (and written into the
end Elasticsearch index).</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="first-experiment-lower-flush-delay">First experiment: Lower flush delay<a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency#first-experiment-lower-flush-delay" class="hash-link" aria-label="Direct link to First experiment: Lower flush delay" title="Direct link to First experiment: Lower flush delay">â€‹</a></h4>
<blockquote>
<p>When we set the exporting/flush delay to a lower value (ex. 1 second), we are improving the import latency for lower load scenarios without affecting the system negatively.</p>
</blockquote>
<p>To reduce the exporter flush delay we use the following configuration:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">exporters</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">elasticsearch</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">bulk</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">delay</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This can be set in our <a href="https://github.com/zeebe-io/benchmark-helm" target="_blank" rel="noopener noreferrer">benchmark-helm</a> directly via: <code>--set zeebe.config.zeebe.broker.exporters.elasticsearch.args.bulk.delay=1</code></p>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Lower flush delay: Helm install command</summary><div><div class="collapsibleContent_i85q"><pre><p>helm install $(releaseName) $(chartPath) --render-subchart-notes <br>
<!-- -->--set global.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebe.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebe.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebeGateway.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebeGateway.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set starter.rate=5 <br>
<!-- -->--set worker.replicas=1 <br>
<!-- -->--set timer.replicas=1 <br>
<!-- -->--set timer.rate=5 <br>
<!-- -->--set publisher.replicas=1 <br>
<!-- -->--set publisher.rate=5 <br>
<!-- -->--set camunda-platform.operate.enabled=true <br>
<!-- -->--set camunda-platform.operate.image.repository=gcr.io/zeebe-io/operate <br>
<!-- -->--set camunda-platform.operate.image.tag=ck-operate-benchmark <br>
<!-- -->--set camunda-platform.elasticsearch.master.persistence.size=128Gi <br>
<!-- -->--set camunda-platform.zeebe.retention.minimumAge=1d <br>
<!-- -->--set zeebe.config.zeebe.broker.exporters.elasticsearch.args.bulk.delay=1</p></pre></div></div></details>
<p><img decoding="async" loading="lazy" alt="lower-delay" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/lower-delay-base-d12d1ae908d186eaa1e7c53db1c25df3.png" width="942" height="350" class="img_ev3q">
<img decoding="async" loading="lazy" alt="lower-delay-throughput" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/lower-delay-base-load-throughput-2f84411bbd0df079f7c760b882b00f1f.png" width="931" height="264" class="img_ev3q"></p>
<p>With setting the <code>bulk.delay</code> to one second, we were able to reduce the import latency by ~2 seconds, from 5.69 to 3.68 seconds.
That is a 35% decrease, while other factors stay the same. We can observe that the throughput stays the same (while of course, the load is rather moderate-to-low).</p>
<p>This proved our first hypothesis from above. <!-- -->âœ…</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="second-experiment-lower-delay-with-higher-load">Second Experiment: Lower delay with higher load<a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency#second-experiment-lower-delay-with-higher-load" class="hash-link" aria-label="Direct link to Second Experiment: Lower delay with higher load" title="Direct link to Second Experiment: Lower delay with higher load">â€‹</a></h4>
<blockquote>
<p>When we set the exporting/flush delay to a lower value (ex. 1 second), we are improving the import latency for higher load scenarios, <strong>but decreasing the import throughput</strong></p>
</blockquote>
<p>Similar to the first experiment we set the delay to one second, and increased the load in the same way as we did
<a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/16/Operate-load-handling#high-load">here</a> before.</p>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Lower flush delay with high load: Helm install command</summary><div><div class="collapsibleContent_i85q"><pre><p>helm install $(releaseName) $(chartPath) --render-subchart-notes <br>
<!-- -->--set global.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebe.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebe.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebeGateway.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebeGateway.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set starter.rate=50 <br>
<!-- -->--set worker.replicas=1 <br>
<!-- -->--set timer.replicas=1 <br>
<!-- -->--set timer.rate=50 <br>
<!-- -->--set publisher.replicas=1 <br>
<!-- -->--set publisher.rate=50 <br>
<!-- -->--set camunda-platform.operate.enabled=true <br>
<!-- -->--set camunda-platform.operate.image.repository=gcr.io/zeebe-io/operate <br>
<!-- -->--set camunda-platform.operate.image.tag=ck-operate-benchmark <br>
<!-- -->--set camunda-platform.elasticsearch.master.persistence.size=128Gi <br>
<!-- -->--set camunda-platform.zeebe.retention.minimumAge=1d <br>
<!-- -->--set zeebe.config.zeebe.broker.exporters.elasticsearch.args.bulk.delay=1</p></pre></div></div></details>
<p><img decoding="async" loading="lazy" alt="higher-load" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/lower-delay-high-load-latency-0e25d5853d6c133948c594bb1efb631b.png" width="1903" height="339" class="img_ev3q">
<img decoding="async" loading="lazy" alt="higher-load-throughput" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/lower-delay-high-load-throughput-30c09f7fe98dd22bd5f4199e48fd79bb.png" width="1895" height="252" class="img_ev3q"></p>
<p>We can see that the latency has been increased a bit, versus the lower load benchmark, but it has improved compared to the
benchmark <a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/16/Operate-load-handling#high-load">the last chaos day</a>. :information: An interesting factor is that it seems that the throughput from Zeebe has changed as well, that in consequence increased the import throughput.</p>
<p>Looking into it further, we can see that the job and process instance creation and completion have changed by ~13-18 percent. Before we had around 130 process instance completion per second.</p>
<p><img decoding="async" loading="lazy" alt="backpressure-higher-load" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/backpressure-higher-load-7ea4904a9e4209bb0f55935db995a5a6.png" width="707" height="450" class="img_ev3q"></p>
<p>In the recent benchmark, we almost reach our target load (150 PI/s) with 147 process instance completions per second.</p>
<p><img decoding="async" loading="lazy" alt="backpressure-higher-load-lower-delay" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/backpressure-lower-delay-higher-load-690a52e13a2e7d988eb29d2cf103250f.png" width="709" height="454" class="img_ev3q"></p>
<p>The reason seem to be the different backpressure. Backpressure has been decreased from ~20 % to 5-10%. This might be because our backpressure strategy has recently changed and now takes exporting into account. See also <a href="https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting">related chaos day about this topic</a>.</p>
<p><em><strong>Update</strong></em>:</p>
<p>Looking into it further, the backpressure is not affected by the newest feature (as it was not enabled by default). This was discussed internally with the Zeebe team.</p>
<p><img decoding="async" loading="lazy" alt="higher-load-less-throughput-commit-latency" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/higher-load-less-throughput-commit-latency-9c60c6c92511ef060343e3628b6ff144.png" width="1906" height="519" class="img_ev3q"></p>
<p>The slower benchmark, seem to have a degraded commit latency, which in consequence slows down the whole system. It is unclear right now, why this is.</p>
<p>The faster benchmark, with the configured exporting, has a much better commit latency. It is unlikely that the exporter configuration affected this part of the system. We will have to retry the both benchmarks.</p>
<p><img decoding="async" loading="lazy" alt="higher-load-higher-throughput" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/higher-load-higher-throughput-commit-latency-fe734971e6c84fd5fcc91f0be184c03b.png" width="1909" height="525" class="img_ev3q"></p>
<p><em><strong>Update 20-08-2024</strong></em></p>
<p>We run additional benchmarks to verify the behavior on high load. This time we haven't seen any differences in terms
of processing performance in both benchmarks.</p>
<p>The benchmark without the configuration, reaches similar numbers (146 PI/s), as the other before.</p>
<p><img decoding="async" loading="lazy" alt="20-08-high-throughput" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/2024-08-20_high-load-throughput-9af777e2e4b2ca7f505630269e5dfc26.png" width="2539" height="383" class="img_ev3q"></p>
<p>Benchmark with configuring the flush delay reaches comparable numbers.</p>
<p><img decoding="async" loading="lazy" alt="20-08-high-throughput" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/2024-08-20_high-load-throughput-lower-delay-b7a3a17768405a0cf71ee848cb882bae.png" width="2539" height="376" class="img_ev3q"></p>
<p>During running the benchmarks we run into another issue, for which we opened the following <a href="https://github.com/camunda/camunda/issues/21376" target="_blank" rel="noopener noreferrer">issue #21376</a>.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="additional-finding">Additional finding<a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency#additional-finding" class="hash-link" aria-label="Direct link to Additional finding" title="Direct link to Additional finding">â€‹</a></h5>
<p>An interesting additional finding has been done. When the Operate import fails or restarts (that can easily happen with preemptive nodes), then the importer backlog can be significant. This is especially an issue on higher constant load.</p>
<p><img decoding="async" loading="lazy" alt="import-delay" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/import-delay-90beae953db149d42fff5c116f738a60.png" width="1908" height="446" class="img_ev3q"></p>
<p>In our benchmark after the importer failed, it took ~20 minutes until the backlog was processed and the import latency was back to normal.</p>
<p><img decoding="async" loading="lazy" alt="recover-import-delay" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/import-delay-recover-6be36a1bd65171855f7b87125cdea6b5.png" width="1906" height="349" class="img_ev3q"></p>
<p>This shows that Operate, especially the importer is quite sensitive to restarts. This is likely to be changed and improved when
Operates importing mechanism is moved into Zeebe, as a separate exporter see <a href="https://github.com/camunda/camunda/issues/16912" target="_blank" rel="noopener noreferrer">related GH issue</a>.</p>
<p>On a lower load, the impact of an importer restart is negligible, as we can see below.</p>
<p><img decoding="async" loading="lazy" alt="no-impoact-low-load-restart" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/no-import-delay-restart-low-load-181ded52fb60f7d19889f6663b5454d0.png" width="1900" height="446" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="third-experiment">Third experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency#third-experiment" class="hash-link" aria-label="Direct link to Third experiment" title="Direct link to Third experiment">â€‹</a></h4>
<blockquote>
<p>When we set the exporting/flush delay to a small value (under 1 second), we are affecting the import throughput negatively</p>
</blockquote>
<p>We were not able to set the <code>bulk.delay</code> to a smaller value than 1 second, as the configuration only accepts longs. The values seem to be expected to be seconds. When setting it to zero, no improvement has been observed (versus one second).</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="potential-improvements">Potential improvements<a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/19/Operate-improve-import-latency#potential-improvements" class="hash-link" aria-label="Direct link to Potential improvements" title="Direct link to Potential improvements">â€‹</a></h2>
<ul>
<li>Allow to configure <code>bulk.delay</code> in non-second format (be able to specify the time/duration format)</li>
<li>The <code>bulk.delay</code> configures a timer, which gets triggered with the given value. This means the flush can happen, even if flush was executed before causing flush with little buffers.</li>
<li>Importing is highly affected by pod restarts, this can cause issues on higher load, due to a growing backlog. Making import idempotent, and scaling importers would help here.</li>
<li><a href="https://github.com/camunda/camunda/issues/21376" target="_blank" rel="noopener noreferrer">Zeebe exporting latency can increase significantly without clear root cause #21376</a>.</li>
</ul>]]></content:encoded>
            <category>performance</category>
        </item>
        <item>
            <title><![CDATA[Operate load handling]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2024/08/16/Operate-load-handling</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2024/08/16/Operate-load-handling</guid>
            <pubDate>Fri, 16 Aug 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[Happy to announce that we are broadening the scope of our Chaos days, to look holistically at the whole Camunda Platform, starting today.]]></description>
            <content:encoded><![CDATA[<p>ðŸŽ‰<!-- --> Happy to announce that we are broadening the scope of our Chaos days, to look holistically at the whole Camunda Platform, starting today.
In the past Chaos days we often had a close look (or concentrated mostly) at Zeebe performance and stability.</p>
<p>Today, we will look at the Operate import performance and how Zeebe processing throughput might affect (or not?) the throughput and latency of the Operate import. Is it decoupled as we thought?</p>
<p>The import time is an important metric, representing the time until data from Zeebe processing is
visible to the User (excluding Elasticsearch's indexing). It is measured from when the record is written to the log, by the Zeebe processor, until Operate reads/imports it from Elasticsearch and converts it into its data model. We got much feedback (and experienced this on our own) that
Operate is often lagging behind or is too slow, and of course we want to tackle and investigate this further.</p>
<p>The results from this Chaos day and related benchmarks should allow us to better understand how the current importing
of Operate performs, and what its affects. Likely it will be a series of posts to investigate this further. In general,
the data will give us some guidance and comparable numbers for the future to improve the importing time. See also related GitHub issue <a href="https://github.com/camunda/camunda/issues/16912" target="_blank" rel="noopener noreferrer">#16912</a> which targets to improve such.</p>
<p><strong>TL;DR;</strong> We were not able to show that Zeebe throughput doesn't affect Operate importing time. We have seen that Operate can be positively affected by the throughput of Zeebe. Surprisingly, Operate was faster to
import if Zeebe produced more data (with a higher throughput). One explanation of this might be that Operate was then less idle.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/16/Operate-load-handling#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">â€‹</a></h2>
<p>As previously mentioned we will today look at the Operate's import latency and throughput. For that, I have created a
new Benchmark dashboard. That allows us to see Zeebe and Operate performance together, at once.</p>
<p><img decoding="async" loading="lazy" alt="default-latency" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/default-latency-42bb59a3c0e41198245a39881eb5efe6.png" width="1898" height="344" class="img_ev3q">
<img decoding="async" loading="lazy" alt="default-throughput" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/default-throughput-633e5b518b1315340f16824249676ad4.png" width="1897" height="486" class="img_ev3q"></p>
<p>During building that dashboard I realized that we missed some detail metrics. For example, the latency of writing and then exporting a record,
is currently not measured. Furthermore, we have operating limited metrics, thus allowing us only to see the average
latency, not p99 nor p90. This needs to be enhanced in the future.</p>
<p>We will run three benchmarks (base, high load, and low load), and use again our <a href="https://github.com/zeebe-io/benchmark-helm" target="_blank" rel="noopener noreferrer">benchmark helm chart</a> for such.
All defaults from the helm charts are used, if not other specified. The most important ones, which are static over all benchmarks are listed below.</p>
<table><thead><tr><th>Config</th><th>Value</th></tr></thead><tbody><tr><td>Broker</td><td>3</td></tr><tr><td>Partitions</td><td>3</td></tr><tr><td>Replication</td><td>3</td></tr><tr><td>Broker Mem</td><td>4G</td></tr><tr><td>Broker CPU</td><td>1350m</td></tr><tr><td>Broker Disk</td><td>32g</td></tr><tr><td>Gateways</td><td>2</td></tr><tr><td>Gateway Mem</td><td>1G</td></tr><tr><td>Gateway CPU</td><td>450m</td></tr><tr><td>ES nodes</td><td>3</td></tr><tr><td>ES CPU</td><td>2</td></tr><tr><td>ES Mem</td><td>6G</td></tr><tr><td>ES Disk</td><td>128g</td></tr><tr><td>Operate replicas</td><td>1</td></tr><tr><td>Operate Memory</td><td>2g</td></tr><tr><td>Operate CPU</td><td>2</td></tr></tbody></table>
<p>With the base, we should see how the import performs normally. As base, we will use the same configuration as we use in our weekly benchmarks, see
<a href="https://github.com/camunda/camunda/blob/main/.github/workflows/zeebe-medic-benchmarks.yml#L78-L89" target="_blank" rel="noopener noreferrer">here</a>.</p>
<p>We use the same applications that we use for our other benchmarks, the code can be found <a href="https://github.com/camunda/camunda/tree/main/zeebe/benchmarks/project" target="_blank" rel="noopener noreferrer">here</a></p>
<p>The base looks like the following:</p>
<table><thead><tr><th>Config</th><th>Value</th></tr></thead><tbody><tr><td>Starter</td><td>5 PI/s</td></tr><tr><td>Worker</td><td>1 Replica</td></tr><tr><td>Timer</td><td>5  PI/s</td></tr><tr><td>Publisher</td><td>5   PI/s</td></tr><tr><td>Variables</td><td>46 Kb</td></tr></tbody></table>
<p>The "Starter" deploys a process model with one task and creates instances at a rate of 5 process instances per second (PI/s). The "Worker" is handling such related tasks. The "Timer" deploys a process model with one timer catch event, and creates instances in a rate of 5 PI/s. The "Publisher" deploys a process model with a message catch event, and publishes messages at a rate of 5 per second. On each process instance variables of the size of 46 kilobytes are sent as payload, to mimic a more realistic scenario.</p>
<p>Going out of the base configuration we are adjusting the rate to a higher value (multiplied by 10), and to a lower value (divided by 5). This means for the high load benchmark we will have a rate of 50 PI/s per application (~150 PI/s), and for the lower load, we will have a rate of 1 PI/s per application (~3 PI/s).</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/16/Operate-load-handling#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>With the base benchmark, we will see how Operate is performing on a moderate load. As the importing of Operate is decoupled the higher load nor the lower load should have a significant impact on the importing time. It might be that due to a higher load on Zeebe, and a slightly bigger backlog the import time might be a bit higher for Operate.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/16/Operate-load-handling#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="base">Base<a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/16/Operate-load-handling#base" class="hash-link" aria-label="Direct link to Base" title="Direct link to Base">â€‹</a></h4>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Helm install command</summary><div><div class="collapsibleContent_i85q"><pre><p>helm install $(releaseName) $(chartPath) --render-subchart-notes <br>
<!-- -->--set global.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebe.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebe.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebeGateway.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebeGateway.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set starter.rate=5 <br>
<!-- -->--set worker.replicas=1 <br>
<!-- -->--set timer.replicas=1 <br>
<!-- -->--set timer.rate=5 <br>
<!-- -->--set publisher.replicas=1 <br>
<!-- -->--set publisher.rate=5 <br>
<!-- -->--set camunda-platform.operate.enabled=true <br>
<!-- -->--set camunda-platform.operate.image.repository=gcr.io/zeebe-io/operate <br>
<!-- -->--set camunda-platform.operate.image.tag=ck-operate-benchmark <br>
<!-- -->--set camunda-platform.elasticsearch.master.persistence.size=128Gi <br>
<!-- -->--set camunda-platform.zeebe.retention.minimumAge=1d \</p></pre></div></div></details>
<p>With a moderate load (as described above) we can see how large the import delay already is.</p>
<p><img decoding="async" loading="lazy" alt="base-latency" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/default-latency-42bb59a3c0e41198245a39881eb5efe6.png" width="1898" height="344" class="img_ev3q"></p>
<p>The import latency from Operate is above 5 seconds.</p>
<p>As expected we can see that we complete 15 process instances per second. We process around 145 records per second, and export 415 records per second. Operate is only reading 370 records per second because not all records are consumed by Operate.</p>
<p><img decoding="async" loading="lazy" alt="base-throughput" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/default-throughput-633e5b518b1315340f16824249676ad4.png" width="1897" height="486" class="img_ev3q"></p>
<p>Here it might make sense to configure the exporter, to only export the important ones.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="high-load">High load<a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/16/Operate-load-handling#high-load" class="hash-link" aria-label="Direct link to High load" title="Direct link to High load">â€‹</a></h4>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Helm install command</summary><div><div class="collapsibleContent_i85q"><pre><p>helm install $(releaseName) $(chartPath) --render-subchart-notes <br>
<!-- -->--set global.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebe.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebe.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebeGateway.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebeGateway.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set starter.rate=50 <br>
<!-- -->--set worker.replicas=3 <br>
<!-- -->--set timer.replicas=1 <br>
<!-- -->--set timer.rate=50 <br>
<!-- -->--set publisher.replicas=1 <br>
<!-- -->--set publisher.rate=50 <br>
<!-- -->--set camunda-platform.operate.enabled=true <br>
<!-- -->--set camunda-platform.operate.image.repository=gcr.io/zeebe-io/operate <br>
<!-- -->--set camunda-platform.operate.image.tag=ck-operate-benchmark <br>
<!-- -->--set camunda-platform.elasticsearch.master.persistence.size=128Gi <br>
<!-- -->--set camunda-platform.zeebe.retention.minimumAge=1d \</p></pre></div></div></details>
<p>Looking at the high load benchmark, we can see something surprising. The Operate import latency has been decreased. From ~5.7 to 4.4 seconds, which is a 30% improvement. The Zeebe processing latency has been increased due to the higher load.</p>
<p><img decoding="async" loading="lazy" alt="high-load-latency" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/high-load-latency-e3e962e93add61bbff99b5bb718735f7.png" width="1904" height="346" class="img_ev3q"></p>
<p>We can see that Zeebe is not able to handle ~150 instances, this can have multiple causes, too few workers, or other configurations, but this is irrelevant for today's benchmark.</p>
<p><img decoding="async" loading="lazy" alt="high-load-throughput" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/high-load-throughput-a7467757d779975bc0daa55c7214a683.png" width="1904" height="493" class="img_ev3q"></p>
<p>A huge amount of records (3158) are imported by Operate per second, with the same configuration as for the base benchmark. It looks like there is still room (we might investigate this further next time).</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="low-load">Low load<a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/16/Operate-load-handling#low-load" class="hash-link" aria-label="Direct link to Low load" title="Direct link to Low load">â€‹</a></h4>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Helm install command</summary><div><div class="collapsibleContent_i85q"><pre><p>helm install $(releaseName) $(chartPath) --render-subchart-notes <br>
<!-- -->--set global.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebe.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebe.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set camunda-platform.zeebeGateway.image.repository=gcr.io/zeebe-io/zeebe <br>
<!-- -->--set camunda-platform.zeebeGateway.image.tag=ck-operate-benchmark-1ad8f375 <br>
<!-- -->--set starter.rate=1 <br>
<!-- -->--set worker.replicas=1 <br>
<!-- -->--set timer.replicas=1 <br>
<!-- -->--set timer.rate=1 <br>
<!-- -->--set publisher.replicas=1 <br>
<!-- -->--set publisher.rate=1 <br>
<!-- -->--set camunda-platform.operate.enabled=true <br>
<!-- -->--set camunda-platform.operate.image.repository=gcr.io/zeebe-io/operate <br>
<!-- -->--set camunda-platform.operate.image.tag=ck-operate-benchmark <br>
<!-- -->--set camunda-platform.elasticsearch.master.persistence.size=128Gi <br>
<!-- -->--set camunda-platform.zeebe.retention.minimumAge=1d \</p></pre></div></div></details>
<p><img decoding="async" loading="lazy" alt="low-load-latency" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/low-load-latency-c26a6962a6679f059431e24501a86518.png" width="1897" height="343" class="img_ev3q"></p>
<p>Unexpected or even counterintuitive is that on a lower load the import time went up again or is similar to the base benchmark ~5.7 seconds to import a record.</p>
<p><img decoding="async" loading="lazy" alt="low-load-throughput" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/low-load-throughput-87a6f32932cbb31cea39dc24a4f2af8c.png" width="1905" height="494" class="img_ev3q"></p>
<p>Zeebe is reaching the 3 PI/s and exporting again a bit more than Operate is importing, as described before likely to some filters.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="result">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/16/Operate-load-handling#result" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">â€‹</a></h3>
<p>We were not able to prove that Zeebe throughput doesn't affect Operate's import time. What we have seen is that higher throughput on the Zeebe side positively affects Operate's import time (import delay decreases from 5.7 seconds to 4.4 seconds). This was not just a short outlier, it was shown over a long period.</p>
<p>It is likely related to how Zeebe exporting and Operate importing work together. Zeebe exporting collects several data before it is sent to Elasticsearch. Either if a certain time is due or a certain amount is reached. Operate might be idle from time to time and "sleep" and wake up every certain seconds to import again.</p>
<p>We have to investigate this further to understand all the details, but I think this as already an interesting learning.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="next">Next<a href="https://zeebe-io.github.io/zeebe-chaos/2024/08/16/Operate-load-handling#next" class="hash-link" aria-label="Direct link to Next" title="Direct link to Next">â€‹</a></h2>
<p>In the following, I listed some potential improvements and investigations we might want to do next:</p>
<ul>
<li>We need better metrics in Operate, e.g. histograms to have p99, and p90 for import latency</li>
<li>We need the measure the export latency, to better understand and compare how long the import time really is</li>
<li>Investigate whether we can better configure exporting and importing, to reduce delays.</li>
<li>Can we filter more records and this affects positively the importing?</li>
</ul>]]></content:encoded>
            <category>performance</category>
        </item>
        <item>
            <title><![CDATA[Using flow control to handle bottleneck on exporting]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting</guid>
            <pubDate>Thu, 25 Jul 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[Zeebe 8.6 introduces a new unified flow control mechanism that is able to limit user commands (by default it tries to achieve 200ms response times) and rate limit writes of new records in general (disabled by default).]]></description>
            <content:encoded><![CDATA[<p>Zeebe 8.6 introduces a new unified flow control mechanism that is able to limit user commands (by default it tries to achieve 200ms response times) and rate limit writes of new records in general (disabled by default).
Limiting the write rate is a new feature that can be used to prevent building up an excessive exporting backlog.
There are two ways to limit the write rate, either by setting a static limit or by enabling throttling that dynamically adjust the write rate based on the exporting backlog and rate.
In these experiments, we will test both ways of limiting the write rate and observe the effects on processing and exporting.</p>
<p><strong>TL;DR;</strong>
Both setting a static write rate limit and enabling throttling of the write rate can be used to prevent building up an excessive exporting backlog.
For users, this will be seen as backpressure because processing speed is limited by the rate at which it can write processing results.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="static-write-limit">Static write limit<a href="https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting#static-write-limit" class="hash-link" aria-label="Direct link to Static write limit" title="Direct link to Static write limit">â€‹</a></h2>
<p>We will construct a cluster under normal utilization and then artificially degrade the exporting process.
After this we will apply flow control settings to statically rate limit all writes.
The limit will be set slightly lower than the observed exporting rate.</p>
<p>For this we will use the flow control endpoint to temporarily configure the write rate limit.</p>
<p>To fetch the current configuration we can port forward to one of the zeebe pods and use the command:</p>
<div class="language-Shell language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">GET /actuator/flowControl</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img decoding="async" loading="lazy" alt="original-configuration" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/original-configuration-568ece5f5f513848f06d772b821f7ba6.png" width="586" height="532" class="img_ev3q"></p>
<p>To configure the write rate limit we use the same endpoint, for example:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">POST /actuator/flowControl</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "write": {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "enabled": true,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "limit": 400</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>When we start to degrade the exporting rate, we expect to see the exporting backlog to increase steadily.</p>
<p>Once a static write rate limit below the degraded exporting rate is applied, we expect fewer rates and slower processing.
The exporting backlog should decrease again until we eventually reach zero backlog again.
Backpressure should increase because processing has slowed down and some requests will be rejected by the write rate limit.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>After we artificially degrade the exporter performance, we see a constant increase in records not exported since the processing is still happening at the same rate.</p>
<p><img decoding="async" loading="lazy" alt="exporting-per-partition" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exporting-per-partition-post-degraded-exporting-45c6750dac85bf4a0a2b949833b6dfd0.png" width="1999" height="379" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="processing-per-partition" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/processing-per-partition-post-degraded-exporting-0e056df5c7a61f47f01c6a3cee5a3c41.png" width="1999" height="378" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="exporter-backlog" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/number-of-records-not-exported-post-degraded-exporting-6df4c3931c2367ce522bac8f9a3a7698.png" width="1362" height="534" class="img_ev3q"></p>
<p>After applying a static rate limit of 400 to be slightly lower than the observed 500-600 of the exporting rate, we see that the processing speed changes accordingly.</p>
<p><img decoding="async" loading="lazy" alt="processing-per-partition-post-rate-limit" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/processing-per-partition-post-rate-limit-3cf3e06b8171ca675e12333dce4385aa.png" width="1999" height="371" class="img_ev3q"></p>
<p>As expected we also see this reflected in backpressure that sees the user commands being rejected in a much higher portion.</p>
<p><img decoding="async" loading="lazy" alt="backpressure" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/backpressure-post-rate-limit-90eba93cb2dd681bfa3d67074ff83713.png" width="1532" height="460" class="img_ev3q"></p>
<p>We also observe that the backlog of records not exported starts to decrease at the rate of the difference between exported and written records.</p>
<p><img decoding="async" loading="lazy" alt="exporter-backlog-post-rate-limit" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/number-of-records-not-exported-post-rate-limit-0e96e608f6826f596b09a32806640ea3.png" width="1360" height="540" class="img_ev3q"></p>
<p>These observations match our expectations and show that a static write rate limit can be used to prevent building up an excessive exporting backlog.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="dynamic-write-rate-throttling">Dynamic write rate throttling<a href="https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting#dynamic-write-rate-throttling" class="hash-link" aria-label="Direct link to Dynamic write rate throttling" title="Direct link to Dynamic write rate throttling">â€‹</a></h2>
<p>Choosing a static write rate limit is not a full solution because we can't predict the actual exporting rates.
To address this, we can enable write rate throttling that will dynamically adjust the write rate based on the exporting backlog and rate.</p>
<p>To enable write rate throttling we can use the flow control endpoint again, for example:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">POST /actuator/flowControl</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "write": {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "enabled": true,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "limit": 2500,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "throttling": {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "enabled": true,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "acceptableBacklog": 100000,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "minimumLimit": 100,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "resolution": "15s"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-1">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting#expected-1" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>Similar to the first experiment, we expect to see the exporting backlog increase when we artificially degrade the exporting performance.
After enabling write rate throttling, we expect that the write rate is reduced significantly and eventually matches the exporting rate.
The reduced write rate should show up as backpressure.
Eventually, the exporting backlog settles at the configured acceptable backlog.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-1">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting#actual-1" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>Re-running the same setup, but using the throttling of writes with an acceptable backlog at 100,000  of not exported records, and a limit higher than our processing speed (so has to not impact the experience), we get the following results:</p>
<p><img decoding="async" loading="lazy" alt="number-of-records-not-exported-post-throttling" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/number-of-records-not-exported-post-throttling-89e888362474746d19c4047766c42cd0.png" width="1098" height="454" class="img_ev3q"></p>
<p>The orange underline metric displays when the throttled write rate is applied.</p>
<p><img decoding="async" loading="lazy" alt="exporting-per-partition-post-throttling" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exporting-per-partition-post-throttling-725f5e30d24caaef42c564ce2a986dcd.png" width="1999" height="293" class="img_ev3q"></p>
<p>From the panels of the â€œExporting per Partitionâ€ and â€œNumber of records not exportedâ€, we can observe that during the re-run of the experience our artificially degrading of the exporters only affected Exporters 2 and 3.
After we enable throttling, the backlog on these affected exporters starts to decrease as expected, later stabilizing on around 100,000 records.
This will drop back to 0 once we remove the artificial degrading of the exporters.</p>
<p><img decoding="async" loading="lazy" alt="backpressure-post-throttling" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/backpressure-post-throttling-77bb875c059269233e3d7b30c81ca1b9.png" width="1984" height="460" class="img_ev3q"></p>
<p>In the backpressure, we observe that this increases mostly on the affected partitions 2 and 3, and once the number of records not exported reaches the acceptable level this lowers slightly and stabilizes.</p>
<p><img decoding="async" loading="lazy" alt="processing-per-partition-post-throttling" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/processing-per-partition-post-throttling-9aa68235837dd795cbb5a10bd875f3b5.png" width="1999" height="290" class="img_ev3q"></p>
<p>Finally, on the panel that shows the processing per partition, we also confirm the expectation that since one of the exporters was not affected by the artificial degrading of the exporter, some additional traffic gets re-routed to this partition, after the throttling gets applied.
On the affected partitions we see the processing decreasing slightly in line with the exporting on the same partitions.</p>
<p>Overall the observations match our expectations and show that write rate throttling succeeds and keeps exporting backlog limited.</p>]]></content:encoded>
            <category>availability</category>
        </item>
        <item>
            <title><![CDATA[Using flow control to handle uncontrolled process loops]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops</guid>
            <pubDate>Thu, 25 Jul 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[Zeebe 8.6 introduces a new unified flow control mechanism that is able to limit user commands (by default it tries to achieve 200ms response times) and rate limit writes of new records in general (disabled by default).]]></description>
            <content:encoded><![CDATA[<p>Zeebe 8.6 introduces a new unified flow control mechanism that is able to limit user commands (by default it tries to achieve 200ms response times) and rate limit writes of new records in general (disabled by default).</p>
<p>Limiting the write rate is a new feature that can be used to prevent building up an excessive exporting backlog.</p>
<p>In these experiments we will test what happens with the deployment of endless
loops that result in high processing load, and how we can use the new
flow control to keep the cluster stable.</p>
<p><strong>TL;DR;</strong></p>
<p>Enabling the write rate limiting can help mitigate the effects caused by
process instances that contain uncontrolled loops by preventing building up an
excessive exporting backlog.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mitigating-the-performance-impacts-of-deployed-loops">Mitigating the performance impacts of deployed loops:<a href="https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops#mitigating-the-performance-impacts-of-deployed-loops" class="hash-link" aria-label="Direct link to Mitigating the performance impacts of deployed loops:" title="Direct link to Mitigating the performance impacts of deployed loops:">â€‹</a></h2>
<p>When an uncontrolled loop is accidentally deployed this tends to use of
most of the
processing resources of the partitions where instances are running.</p>
<p>Such instances completely occupies its partition, starves other instances and results in slow response times.</p>
<p>Usually, these problems should be addressed before other issues arise, such as full disk due to a large backlog of not exported records (max exporting speed tends to be slower than max processing speed).</p>
<p>Using the write rate limiter, we can slow down the processing speed and
give us more time to address the issue, while at the same time enabling us to reduce or maintain the backlog size and reduce risks of side effects.</p>
<p>To reduce the rate write limit we will use the unified control endpoint and configure write limit to be significantly lower than the processing speed.</p>
<p>To fetch the current configuration we can port forward to one of the zeebe pods and use the command:</p>
<div class="language-Shell language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">GET /actuator/flowControl</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img decoding="async" loading="lazy" alt="original-configuration" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/original-configuration-568ece5f5f513848f06d772b821f7ba6.png" width="586" height="532" class="img_ev3q"></p>
<p>To configure the write rate limit we use the same endpoint:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">POST /actuator/flowControl</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   "write": {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        "enabled": true,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        "limit": 3000,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>For this experiment we will test the impact of write rate limits both in
single loops and dual loops.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="single-loop-processing">Single loop processing:<a href="https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops#single-loop-processing" class="hash-link" aria-label="Direct link to Single loop processing:" title="Direct link to Single loop processing:">â€‹</a></h2>
<p><img decoding="async" loading="lazy" alt="single-loop" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/single-loop-2c6d288753c26789a55ac011536dcf6a.png" width="1090" height="634" class="img_ev3q"></p>
<p>This single-loop process will hoard the processing resources and never complete but will append to the processing queue only the next step in the process.</p>
<p>This means that the number of records not processed will only grow if many other processes or requests are arriving at the same time, at a faster rate than the cluster can process.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-results">Expected results:<a href="https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops#expected-results" class="hash-link" aria-label="Direct link to Expected results:" title="Direct link to Expected results:">â€‹</a></h3>
<p>When deploying a process instance with a single loop we should see the
processing rate in the partition increases significantly.</p>
<p>This can lead to processing speed to surpass the exporting speed, which
results in increase in the backlog of exported records.</p>
<p>Using the rate write limits to restrict the processing speed enables us to
reduce the backlog size and give more time for the user to fix the
underlying issues with the cluster.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>By deploying a single loop model we can see that the processing and writing
increases in the same partition and stabilizes around 5 000, later at
around 17:55 we apply the write rate limit of 3 000, and the processing
gets limited accordingly.</p>
<p>This leads to some of the requests being
redirected to
the other partitions which cause the processing in these to increase.</p>
<p><img decoding="async" loading="lazy" alt="single-loop-processing-per-partition" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/single-loop-processing-per-partition-5a64caa8af538a2e888591a0d00f7ab1.png" width="1999" height="290" class="img_ev3q"></p>
<p>When observing the backpressure, we can draw the same conclusions as from
the processing per partition graph, after the model gets deployed, we see an
increase in the backpressure to around 7% in the partition where the loop
instance was deployed.</p>
<p>Once the limit gets set at around 17:55 the backpressure in this partition
increases even more, to around 22% with the backpressure in the other partitions also increasing significantly.</p>
<p>This follows the expected results since with the limiting processing, the after partition will reject even more commands, which get redirected to the remaining partitions which also cause their load to increase and therefore their backpressure as well.</p>
<p><img decoding="async" loading="lazy" alt="single-loop-backpressure" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/single-loop-backpressure-3a91001378b847e1184ccb2e1e36d13a.png" width="1972" height="456" class="img_ev3q"></p>
<p>Observing the exporting per partition panel we can see that the exporting also increases in the affected partition, and this gets reduced after the limit gets imposed.</p>
<p><img decoding="async" loading="lazy" alt="single-loop-exporting-per-partition" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/single-loop-exporting-per-partition-c72cfee7a14b98c2a7e45945c63f2e99.png" width="1999" height="293" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="dual-loop-processing">Dual loop processing:<a href="https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops#dual-loop-processing" class="hash-link" aria-label="Direct link to Dual loop processing:" title="Direct link to Dual loop processing:">â€‹</a></h2>
<p><img decoding="async" loading="lazy" alt="double-loop" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/dual-loop-629f9c9afa1f36b5bab529656d32cf42.png" width="976" height="612" class="img_ev3q"></p>
<p>On the other hand, this dual loop process during its run will always create more records than can be processed since it doubles in the last step.</p>
<p>This will create a steady increase in records not processed even if no other processes or requests are competing for processing time.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h2>
<p>When deploying a process instance with a dual loop we should expect to see
a rapid increase in the processing speed and also in the number of records
not processed.</p>
<p>In this case, restricting the processing speed should not decrease the
backlog of processed records since on each run of the loop more records are
created than
processed.</p>
<p>However, it should help us at least in reducing the pace of the increase in
the backlog and therefore give us more time to address the
underlying problem.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="actual-1">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops#actual-1" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h2>
<p>After deploying the dual loop we can see that the processing quickly jumps to its peak, at around 18:11 we configure the write rate limit at 3000.</p>
<p>Unlike the previous experience here we can observe that the processing speed in the other partitions was already increasing before the configuration gets applied.</p>
<p><img decoding="async" loading="lazy" alt="dual-loop-processing-per-partition" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/dual-loop-processing-per-partition-89041e42051a2123a5c442c197ad08fe.png" width="1999" height="288" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="dual-loop-exporting-per-partition" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/dual-loop-exporting-per-partition-65937890949ec823d82338a744ad7ffe.png" width="1999" height="295" class="img_ev3q"></p>
<p>Observing the backpressure we get the answer as to why the processing in the other partitions was already increasing before the configuration gets applied.</p>
<p>The backpressure had already reached at 100% which means that the dual loop process by itself hoarded completely the processing resources of the partition.</p>
<p><img decoding="async" loading="lazy" alt="dual-loop-backpressure" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/dual-loop-backpressure-824800471f8562faea35e72be8d9be05.png" width="1966" height="462" class="img_ev3q"></p>
<p>Observing the number of records not processed we conclude as expected that
limiting the write rate cannot stop the records backlog from continuing to increase, but we can see that the slope of the curve is smaller after configuring the limit.</p>
<p><img decoding="async" loading="lazy" alt="dual-loop-records-not-exported" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/dual-loop-number-of-records-not-processed-7e4a14070299c6842e16c7496e6b99cd.png" width="1106" height="462" class="img_ev3q"></p>
<p>Overall the results match our expectations that the flow control configuration can be leveraged to give us more control of the cluster, which in the case of acting on deployed loop instances can give us more tools to address these issues.</p>
<p><em>Footnote:
(As of the latest release, it is no longer possible to deploy processes that
contain a straight-through processing loops such as the ones used in this
experience).</em></p>]]></content:encoded>
            <category>availability</category>
        </item>
        <item>
            <title><![CDATA[Reducing the job activation delay]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency</guid>
            <pubDate>Fri, 19 Jan 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[With the addition of end-to-end job streaming capabilities in Zeebe, we wanted to measure the improvements in job activation latency:]]></description>
            <content:encoded><![CDATA[<p>With the addition of end-to-end job streaming capabilities in Zeebe, we wanted to measure the improvements in job activation latency:</p>
<ul>
<li>How much is a single job activation latency reduced?</li>
<li>How much is the activation latency reduced between each task of the same process instance?</li>
<li>How much is the activation latency reduced on large clusters with a high broker and partition count?</li>
</ul>
<p>Additionally, we wanted to guarantee that every component involved in streaming, including clients, would remain resilient in the face of load surges.</p>
<p><strong>TL;DR;</strong> Job activation latency is greatly reduced, with task based workloads seeing up to 50% reduced overall execution latency. Completing a task now immediately triggers pushing out the next one, meaning the latency to activate the next task in a sequence is bounded by how much time it takes to process its completion in Zeebe. Activation latency is unaffected by how many partitions or brokers there in a cluster, as opposed to job polling, thus ensuring scalability of the system. Finally, reuse of gRPC's flow control mechanism ensure clients cannot be overloaded even in the face of load surges, without impacting other workloads in the cluster.</p>
<p><a href="https://docs.camunda.io/docs/components/concepts/job-workers/#job-streaming" target="_blank" rel="noopener noreferrer">Head over to the documentation to learn how to start using job push!</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="why-job-activation-latency-matters">Why job activation latency matters<a href="https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#why-job-activation-latency-matters" class="hash-link" aria-label="Direct link to Why job activation latency matters" title="Direct link to Why job activation latency matters">â€‹</a></h2>
<p>Jobs are one of the fundamental building blocks of Zeebe, representing primarily all tasks (e.g. service, send, user), as well as some less obvious symbols (e.g. intermediate message throw event). In essence, they represent the actual unit of work in a process, the part users will implement, i.e. the actual application code. To reduce the likelihood of a job being worked on by multiple clients at the same time, it first goes through an activation process, where it is soft-locked for a specific amount of time. Soft-locked here means anyone can still interact with it - they can complete the job, fail it, etc. Only the activation is locked out, meaning no one else can activate the job until it's timed out.</p>
<p>This means that most workloads will consist mostly of job interactions: creation, activation, completion, etc. As such, it's critical to ensure clients receive jobs as fast as possible in order to make progress.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="polling-a-first-implementation">Polling: a first implementation<a href="https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#polling-a-first-implementation" class="hash-link" aria-label="Direct link to Polling: a first implementation" title="Direct link to Polling: a first implementation">â€‹</a></h2>
<p>Back in 2018, Zeebe introduced the <code>ActivateJobs</code> RPC for its gRPC clients, analogous to fetching and locking <a href="https://docs.camunda.org/manual/7.20/user-guide/process-engine/external-tasks/" target="_blank" rel="noopener noreferrer">external tasks in Camunda 7.x</a>. This endpoint allowed clients to activate fetch and activate a specific number of available jobs. In other words, it allowed them to <em>poll</em> for jobs.</p>
<p>This was the first implementation to activate and work on jobs in Zeebe for multiple reason:</p>
<ul>
<li>It follows a simple request/response pattern</li>
<li>Flow control is delegated to the client/user</li>
<li>Most other approaches will build onto the building blocks used by polling</li>
<li>You will likely implement polling anyway as a fallback for other approaches (e.g. pushing)</li>
</ul>
<p>Grossly simplified, the implementation worked like this:</p>
<p><img decoding="async" loading="lazy" alt="Job polling" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/job-poll-fbf0a5b11cac5467c5daba1424bc9230.png" width="784" height="554" class="img_ev3q"></p>
<ul>
<li>A client initiates an <code>ActivateJobs</code> call by sending an initial request</li>
<li>The gateway receives the request and validates it</li>
<li>The gateway starts polling each partition synchronously one by one</li>
<li>Whenever jobs are received from a partition, it forwards them to the client</li>
<li>When all partitions are exhausted, or the maximum number of jobs have been activated, the request is closed</li>
</ul>
<p>Already we can infer certain performance bottle necks based on the following:</p>
<ul>
<li>Every request - whether client to gateway, or gateway to broker - adds delay to the activation latency</li>
<li>In the worst case scenario, we have to poll <em>every</em> partition.</li>
<li>The gateway does not know in advance which partitions have jobs available.</li>
<li>Scaling out your clients may have adverse effects by sending out too many requests which all have to be processed independently</li>
<li><a href="https://github.com/camunda/camunda/issues/11813" target="_blank" rel="noopener noreferrer">If you have a lot of jobs, you can run into major performance issues when accessing the set of available jobs</a></li>
</ul>
<p>So if we have, say, 30 partitions, and each gateway-to-broker request takes 100ms, fetching the jobs on the last partition will take up to 3 seconds, even though the actual activation time on that partition was only 100ms.</p>
<p>Furthermore, if we have a sequence of tasks, fetching the next task in the sequence requires, in the worst case scenario, another complete round of polling through all the partitions, even though the task may already be available.</p>
<p>One would think a workaround to this issue would simply be to poll more often, but this can have an adverse impact: each polling request has to be processed by the brokers, and sending too many will simply flood your brokers and slow down all processing, further compounding the problem.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="long-polling-a-second-implementation">Long polling: a second implementation<a href="https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#long-polling-a-second-implementation" class="hash-link" aria-label="Direct link to Long polling: a second implementation" title="Direct link to Long polling: a second implementation">â€‹</a></h3>
<p>To simplify things, the Zeebe team introduced <a href="https://github.com/camunda/camunda/issues/2825" target="_blank" rel="noopener noreferrer">long polling in 2019</a>. <a href="https://en.wikipedia.org/wiki/Push_technology#Long_polling" target="_blank" rel="noopener noreferrer">Long polling</a> is a fairly common technique to emulate a push or streaming approach while maintaing the request-response pattern of polling. Essentially, if the server has nothing to send to the client, instead of completing the request it will hold it until content is available, or a timeout is reached.</p>
<p>In Zeebe, this means that if we did not reach the maximum number of jobs to activate after polling all partitions, the request is parked but not closed. Eventually when jobs are available, the brokers will make this information known to the gateways, who will then unpark the oldest request and start a new polling round.</p>
<p><img decoding="async" loading="lazy" alt="Job polling" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/job-long-poll-87a951a59369f8452d9a3e2f36421d8e.png" width="784" height="835" class="img_ev3q"></p>
<p>This solved certain problems:</p>
<ul>
<li>We reduced the amount of requests sent by clients, thus reducing load on the cluster.</li>
<li>In some cases, we reduced the latency when activating the next task in sequence.</li>
</ul>
<p>However, there are still some issues:</p>
<ul>
<li>When receiving the notification we <em>still</em> have to poll all partitions.</li>
<li>If you have multiple gateways, all gateways will start polling if they have parked requests. Some of them may not get any jobs, but they will still have sent requests to brokers which still all have to be processed.</li>
<li>In high load cases, you still need another client request/poll cycle to fetch the next task in a sequence.</li>
<li>Scaling out your clients still add more load on the system, even if the poll less often</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="job-push-third-times-the-charm">Job push: third time's the charm<a href="https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#job-push-third-times-the-charm" class="hash-link" aria-label="Direct link to Job push: third time's the charm" title="Direct link to Job push: third time's the charm">â€‹</a></h2>
<p>In order to solve these issues, the team decided to implement <a href="https://github.com/camunda/camunda/issues/11231" target="_blank" rel="noopener noreferrer">a push-based approach to job activation</a>.</p>
<p>Essentially, we added a new <code>StreamActivatedJobs</code> RPC to our gRPC protocol, a so-called <a href="https://grpc.io/docs/what-is-grpc/core-concepts/#server-streaming-rpc" target="_blank" rel="noopener noreferrer">server streaming RPC</a>. In our case, this is meant to be a long-lived stream, such that the call is completed only if the client terminates it, or if the server is shutting down.</p>
<p>The stream itself has the following lifecycle:</p>
<p><img decoding="async" loading="lazy" alt="Job push" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/job-push-a314bcca5464ddee542b00633cc58d1b.png" width="784" height="612" class="img_ev3q"></p>
<ul>
<li>The client initiates the stream by sending a job activation request much like with the <code>ActivateJobs</code> RPC.<!-- -->
<ul>
<li>Since the stream is meant to be long lived, however, there is no upper bound on the number of jobs to activate.</li>
</ul>
</li>
<li>The gateway registers the new stream with all brokers in the cluster<!-- -->
<ul>
<li>Note that there is no direct connection between brokers and client; the gateway acts as a proxy for the client.</li>
</ul>
</li>
<li>When jobs are available for activation (e.g. on creation, on timeout, on backoff, etc.), the broker activates the job and pushes it to the gateway.</li>
<li>The gateway forwards the job to the client.</li>
</ul>
<p><a href="https://docs.camunda.io/docs/components/concepts/job-workers/#how-it-works" target="_blank" rel="noopener noreferrer">You can read more about the implementation as part of our docs.</a></p>
<blockquote>
<p>Experienced readers will immediately spot that push-based approaches run the risk of overloading the client. Thanks to the built-in flow control facilities of gRPC, we can still ensure clients are resilient in the face of load surges. See <a href="https://docs.camunda.io/docs/components/concepts/job-workers/#backpressure" target="_blank" rel="noopener noreferrer">here for an explanation</a>.</p>
</blockquote>
<p>This solved most, if not all, of the problems listed above:</p>
<ul>
<li>Brokers push jobs out immediately as they become available, removing the need for a gateway-to-broker request.</li>
<li>Since the stream is long lived, there are almost no client requests required after the initial one.</li>
<li>No need to poll every partition anymore.</li>
<li>No thundering herd issues if you have many gateways all polling at the same time due to a notification.</li>
<li>Scaling out your clients adds little to no load to the system, as idle clients simply do nothing.</li>
<li>Even if you have a lot of jobs, in the average case, you never have to iterate over them and instead the broker pushes the job out on creation.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="tests-results-and-comparisons">Tests, results, and comparisons<a href="https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#tests-results-and-comparisons" class="hash-link" aria-label="Direct link to Tests, results, and comparisons" title="Direct link to Tests, results, and comparisons">â€‹</a></h3>
<p>In order to compare the advantages of pushing to polling, we did three different experiments.</p>
<blockquote>
<p>Note that all throughput measurements are in process instances executed per second, shortened to PI/s. Additionally, in the results shown below, dotted lines in graphs always refer to job polling measurements, and filled lines to job pushing.</p>
</blockquote>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="cluster-specifications">Cluster specifications<a href="https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#cluster-specifications" class="hash-link" aria-label="Direct link to Cluster specifications" title="Direct link to Cluster specifications">â€‹</a></h4>
<p>Note that, unless specificed otherwise, we used the following clusters to run the tests: 3 brokers, 2 gateways, 3 partitions, replication factor 3.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="brokers">Brokers<a href="https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#brokers" class="hash-link" aria-label="Direct link to Brokers" title="Direct link to Brokers">â€‹</a></h5>
<table><thead><tr><th>Parameter</th><th>Value</th></tr></thead><tbody><tr><td>CPU request</td><td>1350m</td></tr><tr><td>Memory request</td><td>4Gi</td></tr><tr><td>CPU thread count</td><td>3</td></tr><tr><td>IO thread count</td><td>3</td></tr><tr><td>Disk type</td><td><a href="https://cloud.google.com/compute/docs/disks#disk-types" target="_blank" rel="noopener noreferrer">pd-ssd</a></td></tr><tr><td>Disk size</td><td>32Gi</td></tr></tbody></table>
<blockquote>
<p>Disk type, size, and vCPU count in GCP is used to determine your maximum IOPS.</p>
</blockquote>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="gateways">Gateways<a href="https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#gateways" class="hash-link" aria-label="Direct link to Gateways" title="Direct link to Gateways">â€‹</a></h5>
<table><thead><tr><th>Parameter</th><th>Value</th></tr></thead><tbody><tr><td>CPU request</td><td>450m</td></tr><tr><td>Kubernetes memory request</td><td>1Gi</td></tr><tr><td>Management thread count</td><td>2</td></tr></tbody></table>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="workers">Workers<a href="https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#workers" class="hash-link" aria-label="Direct link to Workers" title="Direct link to Workers">â€‹</a></h5>
<p>To simulate work, whenever workers receive an activated job, they will wait 50ms before completing it.</p>
<table><thead><tr><th>Parameter</th><th>Value</th></tr></thead><tbody><tr><td>CPU request</td><td>500m</td></tr><tr><td>Kubernetes memory request</td><td>256Mi</td></tr><tr><td>Thread count</td><td>10</td></tr><tr><td>Max jobs active</td><td>60</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="one-task">One task<a href="https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#one-task" class="hash-link" aria-label="Direct link to One task" title="Direct link to One task">â€‹</a></h4>
<p>As our baseline test, we ran a constant throughput of 150 PI/s of a single task process workload:</p>
<p><img decoding="async" loading="lazy" alt="A single task BPMN process: start -&amp;gt; task -&amp;gt; end" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/single-task-bpmn-99ed3a15761cf3fbe8bfdc20807d4c7e.png" width="999" height="276" class="img_ev3q"></p>
<p>Since each job takes at least 50ms of work, the lower bound execution latency for this process is 50ms.</p>
<p><img decoding="async" loading="lazy" alt="Results of 150 PI/s single task process" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/single-task-benchmark-4ef8a419140fd42094f359a54a74000b.png" width="1907" height="867" class="img_ev3q"></p>
<p>The results show a sharp decrease in both the p50 and p99 of the job lifetime (i.e. the time between creation and completion). Since this workload only consists of a single task, this is mirrored in the overall process execution latency. Overall, we see that switching to a push approach yields a p50 latency improvement of 50%, and a p99 improvement of 75%!</p>
<p>Additionally, we can see with job push that the Zeebe the p50 processing overhead is ~14ms, and the p99 ~390ms. For job polling, the p50 overhead is ~70ms, and the p99 overhead is ~1.7s.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="ten-tasks">Ten tasks<a href="https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#ten-tasks" class="hash-link" aria-label="Direct link to Ten tasks" title="Direct link to Ten tasks">â€‹</a></h4>
<p>For our next test, we ran a constant throughput of 150 PI/s of a ten tasks sequence process:</p>
<p><img decoding="async" loading="lazy" alt="A ten tasks sequence BPMN process: start -&amp;gt; task_1 -&amp;gt; task_2 -&amp;gt; ... -&amp;gt; task_10 -&amp;gt; end" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/ten-tasks-bpmn-2617d2c0ddb0a87947bd2019efb66e74.png" width="2247" height="1137" class="img_ev3q"></p>
<p>Since each job takes at least 50ms of work, the lower bound execution latency for this process is 500ms.</p>
<p><img decoding="async" loading="lazy" alt="Results of 150 PI/s single task process" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/ten-tasks-benchmark-bdae0ac5942ee080b193dbe7294ced1f.png" width="1901" height="864" class="img_ev3q"></p>
<p>The results show a sharp decrease in both the p50 and p99 of the job lifetime (i.e. the time between creation and completion). In this case, the process consists of several tasks, so the process execution latency is noticeably higher. But we can see that the p50 latency for job push is ~640ms. Overall, we see that switching to a push approach yields a p50 latency improvement of 30%, and a p99 improvement of 50%!</p>
<p>Additionally, we can see with job push that the Zeebe the p50 processing overhead is ~140ms, and the p99 ~1.8s. For job polling, the p50 overhead is ~1.4s, and the p99 overhead is ~4.3s.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="large-cluster">Large cluster<a href="https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#large-cluster" class="hash-link" aria-label="Direct link to Large cluster" title="Direct link to Large cluster">â€‹</a></h4>
<p>In order to verify that the approach will scale along with the cluster size, we next compared polling and pushing with a cluster of 30 brokers and 30 partitions. Again, we tested with the single task process as above, and a constant throughput of 150 PI/s.</p>
<p><img decoding="async" loading="lazy" alt="Results of 150 PI/s against a large cluster" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/thirty-partitions-benchmark-63cde3904d51c5b209efc0a1e9aad02e.png" width="1905" height="859" class="img_ev3q"></p>
<p>For job push, we see a greatly improved p99 - since each partition is doing less work than before with 3 partitions, we can achieve much more stable performance, with the p99 being quite close to the p50.</p>
<p>For job poll however, we see the downside of having to poll each partition in turn: the p50 is worse than before, and even though the p99 is greatly improved, we can see a wave pattern where it will spike up to 3s, so a decrease compared to the smaller cluster.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="client-backpressure--load-surges">Client backpressure &amp; load surges<a href="https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#client-backpressure--load-surges" class="hash-link" aria-label="Direct link to Client backpressure &amp; load surges" title="Direct link to Client backpressure &amp; load surges">â€‹</a></h4>
<p>One of the downsides of switching to a push approach, unfortunately, is that the client is now at risk of receiving more work than it can safely handle.</p>
<p>Thankfully, HTTP/2 and gRPC both have mechanisms to ensure flow control for server streaming RPCs.</p>
<p><a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading" target="_blank" rel="noopener noreferrer">You can find our tests results in a separate blog post</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="further-reading">Further reading<a href="https://zeebe-io.github.io/zeebe-chaos/2024/01/19/Job-Activation-Latency#further-reading" class="hash-link" aria-label="Direct link to Further reading" title="Direct link to Further reading">â€‹</a></h2>
<p>You can read more about job push here:</p>
<ul>
<li><a href="https://docs.camunda.io/docs/components/concepts/job-workers/#job-streaming" target="_blank" rel="noopener noreferrer">Streaming job workers</a></li>
<li><a href="https://docs.camunda.io/docs/apis-tools/java-client/job-worker/#job-streaming" target="_blank" rel="noopener noreferrer">Job push for the Java client</a></li>
<li><a href="https://docs.camunda.io/docs/apis-tools/go-client/job-worker/#job-streaming" target="_blank" rel="noopener noreferrer">Job push for the Go client</a></li>
<li><a href="https://github.com/camunda-community-hub/spring-zeebe#enable-job-streaming" target="_blank" rel="noopener noreferrer">Job push for spring-zeebe</a></li>
</ul>
<p>Additionally, we've already written two other blog posts:</p>
<ul>
<li><a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading" target="_blank" rel="noopener noreferrer">Client backpressure resilience</a></li>
<li><a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency" target="_blank" rel="noopener noreferrer">Job stream fault tolerance</a></li>
</ul>]]></content:encoded>
            <category>availability</category>
        </item>
        <item>
            <title><![CDATA[Broker Scaling and Performance]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance</guid>
            <pubDate>Wed, 20 Dec 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[With Zeebe now supporting the addition and removal of brokers to a running cluster, we wanted to test three things:]]></description>
            <content:encoded><![CDATA[<p>With Zeebe now supporting the addition and removal of brokers to a running cluster, we wanted to test three things:</p>
<ol>
<li>Is there an impact on processing performance while scaling?</li>
<li>Is scaling resilient to high processing load?</li>
<li>Can scaling up improve processing performance?</li>
</ol>
<p><strong>TL;DR;</strong> Scaling up works even under high load and has low impact on processing performance. After scaling is complete, processing performance improves in both throughput and latency.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="impact-of-scaling-on-processing-performance">Impact of scaling on processing performance<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance#impact-of-scaling-on-processing-performance" class="hash-link" aria-label="Direct link to Impact of scaling on processing performance" title="Direct link to Impact of scaling on processing performance">â€‹</a></h2>
<p>Scaling up and down is an expensive operation where partition data is transferred between brokers, and leadership for partitions changes.
We wanted to test how much impact this has on regular processing performance.</p>
<p>To do this, we ran a benchmark with 3 brokers, 6 partitions and replication factor 3.</p>
<p>The brokers are limited to 1.35 CPUs and 4GiB RAM each.
They run with additional safety checks that are usually disabled in production and that slightly decrease the baseline processing performance.
Each broker uses a small 32GiB SSD for storage, limiting them to a few thousand IOPS.</p>
<p>The processing load was 150 processes per second, with a large payload of 32KiB each.
Each process instance has a single service task:</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/one_task-f083f237e568d87cc17eef056cb45d73.png" width="999" height="276" class="img_ev3q"></p>
<p>The processing load is generated by our own <a href="https://github.com/camunda/camunda/tree/9e723b21b0e408fc2b97fd7d3f6b092af8e62dbe/benchmarks" target="_blank" rel="noopener noreferrer">benchmarking application</a>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>When we scale up from 3 to 6 brokers, we expect a small impact on processing performance.
Request latency may increase slightly, some requests may time out and some will be rejected due to backpressure.
The overall throughput in terms of created and completed process instances as well as jobs may similarly decrease slightly.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>Following are screenshots of collected metrics.
The blue annotation marks the time where scaling occurred.</p>
<p>We see a short increase in process instance duration, meaning that some process instances were finished slightly slower than before.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/increased_process_duration-3bc31b565412bb200dd5004cf1a393f9.png" width="840" height="296" class="img_ev3q"></p>
<p>The throughput in terms of created and completed process instances and jobs remained very stable.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/stable_throughput-92c3e8b4711794408ae03779025d148b.png" width="1665" height="296" class="img_ev3q"></p>
<p>We see a small increase in requests timing out or getting rejected by backpressure.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/failed_requests-47e5e20dec7558d9bf262572e4bceef2.png" width="840" height="296" class="img_ev3q"></p>
<p>Overall, this matches our expectation and shows that scaling up has a small impact on processing performance.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="scaling-under-load">Scaling under load<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance#scaling-under-load" class="hash-link" aria-label="Direct link to Scaling under load" title="Direct link to Scaling under load">â€‹</a></h2>
<p>Since scaling up is supposed to alleviate high processing load for brokers, it's important that it works even under high load.
For this test, we increased the load on the same cluster setup as before to 210 instead of 150 process instances per second.
This is roughly the maximum throughput that the 3 brokers with 6 partitions and replication factor 3 can handle.
We can see this from the relatively high backpressure, as well as high process instance duration.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/high_load_backpressure-5c264822dfc52c8f31072e9a41e892e3.png" width="628" height="220" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/high_load_latency-75cc8b8a9b6ceb63a32d418e96a649f4.png" width="840" height="296" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-1">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance#expected-1" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>We expect that scaling up to 6 brokers will still complete successfully, even under high load.
The time it takes until scaling is complete might be slightly higher.
The impact on processing performance, both in terms of throughput and latency, may be slightly larger than in the previous experiment.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-1">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance#actual-1" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>The process instance duration did not increase, and even decreased slightly.
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/high_load_scaling_latency-bda55e145412ae73d60bcefa7129ea4c.png" width="840" height="296" class="img_ev3q"></p>
<p>Similarly, the throughput in terms of created and completed process instances and jobs remained relatively stable.
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/high_load_scaling_throughput-d1da75d1c6483a9801c0cb46c85dd112.png" width="1687" height="296" class="img_ev3q"></p>
<p>The number of failed requests increased slightly, but still well within an acceptable range.
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/high_load_scaling_failed_requests-74619f4fae76f750b3dd1a7e548ae5a9.png" width="840" height="296" class="img_ev3q"></p>
<p>The scaling operation took 5 minutes, a good portion of which is waiting for the new brokers to get scheduled and start up.</p>
<p>Overall, this matches our expectation and shows that scaling can complete fast and with low impact on processing performance, even under high load.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="scaling-up-to-improve-performance">Scaling up to improve performance<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance#scaling-up-to-improve-performance" class="hash-link" aria-label="Direct link to Scaling up to improve performance" title="Direct link to Scaling up to improve performance">â€‹</a></h2>
<p>The most obvious goal of scaling brokers is to unlock additional processing performance.
While vertical scaling is also a great option, this can hit limits imposed by your infrastructure provider.
For example, some machine types may offer great CPU performance but are severely limited in IOPS.
Additionally, vertical scaling is often more expensive than horizontal scaling.
It also comes with increased risk when a single machine fails because the remaining machines may already run at their limits and will then struggle to handle the additional load during failover.</p>
<p>To show how broker scaling can improve processing performance, we reused the same cluster setup as before.
We have 3 brokers, 6 partitions and replication factor 3.</p>
<p>The brokers are limited to 1.35 CPUs and 4GiB RAM each.
They run with additional safety checks that are usually disabled in production and that slightly decrease the baseline processing performance.
Each broker uses a small 32GiB SSD for storage, limiting them to a few thousand IOPS.</p>
<p>We changed the processing load slightly to simulate a more realistic scenario.
The new process model consists of 10 tasks with two timers in-between, each delaying the process instance by 1 minute.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/ten_tasks-97eff1de6db0dbb79ae9681cedd14a93.png" width="5823" height="576" class="img_ev3q"></p>
<p>The processing load is generated by our own <a href="https://github.com/camunda/camunda/tree/9e723b21b0e408fc2b97fd7d3f6b092af8e62dbe/benchmarks" target="_blank" rel="noopener noreferrer">benchmarking application</a>, initially starting 40 process instances per second.</p>
<p>This results in 400 jobs created and completed per second.</p>
<p>This stresses the 3 brokers and we see backpressure on all partitions.
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/perf_initial_backpressure-ff99c218bd0d2169e80612db06918bee.png" width="628" height="220" class="img_ev3q"></p>
<p>We also see a few jobs timing out, indicating that the cluster is unable to handle this load consistency:
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/perf_initial_timeouts-184ec92cae00e964d1cb981d81c9094c.png" width="840" height="220" class="img_ev3q"></p>
<p>We also see that many jobs are active for much longer than 1 second, even though the workers only delay completion by 50ms.
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/perf_initial_job_lifetime-aa635408ad750e58f3c4d5aba42cfb71.png" width="840" height="296" class="img_ev3q"></p>
<p>As hinted at before, much of this performance limit can be attributed to the limited IOPS of the small SSDs.
We see this in a very high commit and write latency, while the IOPS remain stable, right at the limit of what the SSDs can handle.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/perf_initial_iops-ef1bfdab00c42f7e496bb8361b82837f.png" width="840" height="296" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/perf_initial_commit_latency-1618c887bba63eaf893d2073070c58a6.png" width="840" height="258" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/perf_initial_write_latency-fdfbc2b5a7814ded4ce935a4432c27b2.png" width="840" height="258" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-2">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance#expected-2" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>When we scale up to 6 brokers, and thus distribute the partitions such that each broker is only leader for 1 instead of 2 partitions, we expect that processing performance improves.</p>
<p>As these things usually go, we don't expect a doubling in performance but aiming for a 1.5x improvement seems reasonable.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-2">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/20/Broker-scaling-performance#actual-2" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>Shortly after scaling up and after partition leadership has balanced, we see a significant improvement in backpressure.
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/perf_after_backpressure-8ea0858dc7e2dbd99c1d9072ad4e9d9e.png" width="628" height="220" class="img_ev3q"></p>
<p>The job lifetime decreases dramatically, with most jobs now taking &lt; 50ms from creation until completion.
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/perf_after_job_lifetime-1484937ab54af54c7c9c62e4d3f40bed.png" width="840" height="296" class="img_ev3q"></p>
<p>Overall processing latency improves similarly.
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/perf_after_processing_latency-0dc8cc62dc0d3416af386c2f7f3b8a7a.png" width="1688" height="258" class="img_ev3q"></p>
<p>Much of this improvement can be attributed to the reduced IOPS.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/perf_after_iops-9d4cfe0e830dc5b2172dba4cf77c772b.png" width="840" height="296" class="img_ev3q"></p>
<p>Commit and write latency improves accordingly.
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/perf_after_commit_latency-3038b133286dfe6303ae585152b74ddf.png" width="840" height="258" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/perf_after_write_latency-83d3d31f30acf064ee5c31792718e02c.png" width="840" height="258" class="img_ev3q"></p>
<p>Another source for improved performance is reduced CPU load.
With 3 brokers being leader for 2 partitions each, they were hitting their CPU limits and got throttled by the underlying infrastructure.
With 6 brokers, each only being leader for 1 partition, the CPU load is reduced and brokers are no longer throttled.
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/perf_after_cpu-27360ba363b21f8be99ae11009830041.png" width="840" height="296" class="img_ev3q"></p>
<p>While this is already a success, we can push things further now.
We are able to increase the load from 40 to 65 process instances per second, resulting in 650 jobs created and completed per second.
This is a 1.6x improvement over the initial load while achieving similar backpressure.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/perf_increased_load_backpressure-50539a70042461e4c0f57395ab9a2981.png" width="628" height="220" class="img_ev3q"></p>
<p>Job lifetime and overall processing latency is still better than before scaling up, even though load increased by 1.6x
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/perf_increased_load_job_lifetime-357a5db1cfce78fb1788dc3bd8dd83c5.png" width="840" height="296" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/perf_increased_load_processing_latency-629f9fc40962d34a30a3a51c2b62c7ba.png" width="1688" height="258" class="img_ev3q"></p>
<p>Overall, this shows that scaling up can improve processing performance significantly, especially when the initial cluster setup is resource limited and vertical scaling is not possible.</p>]]></content:encoded>
            <category>availability</category>
            <category>performance</category>
        </item>
        <item>
            <title><![CDATA[Dynamic Scaling with Dataloss]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2023/12/19/Dynamic-Scaling-with-Dataloss</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2023/12/19/Dynamic-Scaling-with-Dataloss</guid>
            <pubDate>Tue, 19 Dec 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[We continue our previous experiments with dynamically scaling by now also testing whether]]></description>
            <content:encoded><![CDATA[<p>We continue our <a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/18/Dynamically-scaling-brokers">previous experiments</a> with dynamically scaling by now also testing whether
the cluster survives dataloss during the process.</p>
<p>One goal is to verify that we haven't accidentally introduced a single point of failure in the cluster.
Another is to ensure that data loss does not corrupt the cluster topology.</p>
<p><strong>TL;DR;</strong>
Even with dataloss, the scaling completes successfully and with the expected results.
We found that during scaling, a single broker of the previous cluster configuration can become a single point of failure by preventing a partition from electing a leader.
This is not exactly a bug, but something that we want to improve.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="dataloss-on-the-coordinator">Dataloss on the Coordinator<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/19/Dynamic-Scaling-with-Dataloss#dataloss-on-the-coordinator" class="hash-link" aria-label="Direct link to Dataloss on the Coordinator" title="Direct link to Dataloss on the Coordinator">â€‹</a></h2>
<p>Zeebe uses Broker 0 as the coordinator for changes to the cluster topology.
While changes can only be initiated by the coordinator, losing the coordinator and it's data should not prevent the scaling operation from completing.
When the coordinator restarts without any data, it should be able to recover the cluster topology as well as the partition data from the remaining brokers.</p>
<p>To test this, we use the <code>zbchaos dataloss delete</code> and <code>zeebe dataloss recover</code> commands.
After deleting, the broker will not restart directly, instead waiting for the <code>zbchaos dataloss recover</code> command to be executed.
The <code>zbchaos dataloss recover</code> command only unblocks the broker and allows it to start, it does not restore any data and we rely on normal replication for that.</p>
<p>Shortly after triggering a scale up with <code>zbchaos cluster scale --brokers 6</code>, we trigger dataloss on the coordinator with <code>zbchaos broker dataloss delete --nodeId 0</code>.
After observing the system for a while, we then restore the coordinator with <code>zbchaos dataloss recover --nodeId 0</code>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/19/Dynamic-Scaling-with-Dataloss#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>The scaling operation eventually completes with the expected result of 6 brokers and 6 partitions, evenly distributed.
The coordinator recovers after dataloss and eventually receives the cluster topology from the remaining brokers.
The scaling operation should make progress while the coordinator is down.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/19/Dynamic-Scaling-with-Dataloss#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>After starting the operation with <code>zbchaos cluster scale --brokers 6</code> we see that the operation has started:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos cluster scale --brokers 6</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Change 18 is IN_PROGRESS with 0/24 operations complete</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We then trigger dataloss on the coordinator with <code>zbchaos broker dataloss delete --nodeId 0</code>.</p>
<p>After this, the operations do not make progress anymore and broker 5 is stuck trying to join partition 5:</p>
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"Version"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">18</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"PendingChange"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">18</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"Status"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"IN_PROGRESS"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"StartedAt"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">""</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"CompletedAt"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">""</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"InternalVersion"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"Completed"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token property" style="color:#36acaa">"Operation"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"BROKER_ADD"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token property" style="color:#36acaa">"BrokerId"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">3</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token property" style="color:#36acaa">"PartitionId"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token property" style="color:#36acaa">"Priority"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token property" style="color:#36acaa">"Operation"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"BROKER_ADD"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token property" style="color:#36acaa">"BrokerId"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">4</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token property" style="color:#36acaa">"PartitionId"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token property" style="color:#36acaa">"Priority"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token property" style="color:#36acaa">"Operation"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"BROKER_ADD"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token property" style="color:#36acaa">"BrokerId"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token property" style="color:#36acaa">"PartitionId"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token property" style="color:#36acaa">"Priority"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"Pending"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token property" style="color:#36acaa">"Operation"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"PARTITION_JOIN"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token property" style="color:#36acaa">"BrokerId"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token property" style="color:#36acaa">"PartitionId"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token property" style="color:#36acaa">"Priority"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The coordinator is a member of partition 5 but there are two remaining members of partition 5 that should allow broker 5 to join.
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/p5-roles-b75bd7b3101a80b7f59746241d1cc2e8.png" width="1288" height="493" class="img_ev3q"></p>
<p>After restoring the coordinator again with <code>zbchaos dataloss recover --nodeId 0</code>, joining eventually completes and the scaling operation finishes successfully.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/scaleup-complete-0918e350110d8454d47295f3c48a2e8e.png" width="840" height="296" class="img_ev3q"></p>
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"Version"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">19</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"LastChange"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">18</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"Status"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"COMPLETED"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"StartedAt"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"2023-12-18T17:05:55.849442157Z"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"CompletedAt"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"2023-12-18T17:17:32.913050015Z"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"PendingChange"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token null keyword" style="color:#00009f">null</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Overall, we achieve our goal that the scaling operation eventually completes with the expected result.
The coordinator recovers after dataloss and eventually receives the cluster topology from the remaining brokers.</p>
<p>However, it was unexpected that the scaling did not make progress while the coordinator was down.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="single-point-of-failure-during-scaling">Single point of failure during scaling<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/19/Dynamic-Scaling-with-Dataloss#single-point-of-failure-during-scaling" class="hash-link" aria-label="Direct link to Single point of failure during scaling" title="Direct link to Single point of failure during scaling">â€‹</a></h2>
<p>The issue that scaling did not make progress while the coordinator was reproducible.
Eventually, we diagnosed it as the following edge case:</p>
<p>When scaling up and and adding a new member to the replication group of a partition, the raft partition goes through joint consensus.
The details of this process are described in the <a href="https://raft.github.io/raft.pdf" target="_blank" rel="noopener noreferrer">raft paper</a>, but here is a very short summary:
Joint consensus is similar to a 2-phase commit, where the leader of the partition first introduces a new <em>joint consensus</em> configuration that requires quorum from both the old and new set of members.
After committing the joint consensus configuration, the leader leaves joint consensus by "forgetting" the old member set and only using the new member set.
Only after this second configuration is committed, joining of the new member is complete.</p>
<p>In our example, the new set of members has size 4, one of which is the coordinator and one is the newly joining member.
With 4 members, the quorum is 3, meaning that the partition can only elect a leader and process if at least 3 members are available.
In our experiment, we made the coordinator unavailable, so we were already down to 3 members.
Additionally, the newly joining member did not start yet because it was waiting for a successful join response from the leader.
The newly joining member never received such a response because the joint-consensus phase was not completed.
This resulted in only 2 out of 4 members being available, which is not enough to elect a leader.</p>
<p>We want to improve this behavior in the future but likely can't prevent it completely.
That means that there is an increased risk of unavailable partitions during scaling.
However, this only occurs if another broker becomes unavailable with an unfortunate timing and resolves itself automatically once the broker is available again.</p>
<p>Zeebe issue: <a href="https://github.com/camunda/camunda/issues/15679" target="_blank" rel="noopener noreferrer">https://github.com/camunda/camunda/issues/15679</a></p>]]></content:encoded>
            <category>availability</category>
        </item>
        <item>
            <title><![CDATA[Dynamically scaling brokers]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2023/12/18/Dynamically-scaling-brokers</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2023/12/18/Dynamically-scaling-brokers</guid>
            <pubDate>Mon, 18 Dec 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[We experimented with the first version of dynamic scaling in Zeebe, adding or removing brokers for a running cluster.]]></description>
            <content:encoded><![CDATA[<p>We experimented with the first version of <a href="https://docs.camunda.io/docs/next/self-managed/zeebe-deployment/operations/cluster-scaling/" target="_blank" rel="noopener noreferrer">dynamic scaling in Zeebe</a>, adding or removing brokers for a running cluster.</p>
<p>Scaling up and down is a high-level operation that consists of many steps that need to be carried co-operatively by all brokers in the cluster.
For example, adding new brokers first adds them to the replication group of the assigned partitions and then removes some of the older brokers from the replication group.
Additionally, <a href="https://docs.camunda.io/docs/next/self-managed/zeebe-deployment/configuration/priority-election/" target="_blank" rel="noopener noreferrer">priorities</a> need to be reconfigured to ensure that the cluster approaches balanced leadership eventually.</p>
<p>This orchestration over multiple steps ensures that all partitions are replicated by at least as many brokers as configured with the <code>replicationFactor</code>.
As always, when it comes to orchestrating distributed systems, there are many edge cases and failure modes to consider.</p>
<p>The goal of this experiment was to verify that the operation is resilient to broker restarts.
We can accept that operations take longer than usual to complete, but we need to make sure that the operation eventually succeeds with the expected cluster topology as result.</p>
<p><strong>TL;DR;</strong> Both scaling up and down is resilient to broker restarts, with the only effect that the operation takes longer than usual to complete.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="scaling-up-should-be-resilient-to-broker-restarts">Scaling up should be resilient to broker restarts<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/18/Dynamically-scaling-brokers#scaling-up-should-be-resilient-to-broker-restarts" class="hash-link" aria-label="Direct link to Scaling up should be resilient to broker restarts" title="Direct link to Scaling up should be resilient to broker restarts">â€‹</a></h2>
<p>We start with a cluster of 3 brokers, 6 partitions and replication factor 3.
If leadership is balanced, each broker should be leader for 2 partitions and follower for 4 partitions.
Using more partitions than brokers allows us to scale up to more brokers, distributing the partitions such that each broker has less work to do.</p>
<p>For this experiment, we introduce chaos by letting a random broker restart every 30 seconds.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/18/Dynamically-scaling-brokers#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>Even when brokers are restarting, the scale operation should eventually succeed.
The expected cluster topology after scaling up is 6 brokers, 6 partitions and replication factor 3, leading to 3 partitions for each broker instead of 6.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/18/Dynamically-scaling-brokers#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="verify-steady-state">Verify steady state<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/18/Dynamically-scaling-brokers#verify-steady-state" class="hash-link" aria-label="Direct link to Verify steady state" title="Direct link to Verify steady state">â€‹</a></h4>
<p>The current cluster topology queried with <code>zbchaos cluster status</code> shows 6 partitions with 3 replicas each, evenly distributed across the 3 brokers.</p>
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"Brokers"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"Partitions"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">3</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">4</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">6</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The above is an abbreviated version of the actual output, which contains more information.</p>
<p>All partitions are reported as healthy and leadership is balanced::</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos topology</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Node      |Partition 1         |Partition 2         |Partition 3         |Partition 4         |Partition 5         |Partition 6</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">0         |LEADER (HEALTHY)    |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)    |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1         |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)    |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)    |FOLLOWER (HEALTHY)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2         |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)    |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="scaling-up-with-broker-restarts">Scaling up with broker restarts<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/18/Dynamically-scaling-brokers#scaling-up-with-broker-restarts" class="hash-link" aria-label="Direct link to Scaling up with broker restarts" title="Direct link to Scaling up with broker restarts">â€‹</a></h4>
<p>We start the scaling with <code>zbchaos cluster scale --brokers 6</code> and restart a random broker every 30 seconds:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos cluster scale --brokers 6 &amp; </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ while true; do sleep 30; zbchaos restart broker --nodeId $(shuf -i 0-5 -n 1); done</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>After the scaling completed, we stop the restarting and let the cluste settle again for a few minutes.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="result">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/18/Dynamically-scaling-brokers#result" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">â€‹</a></h3>
<p>The scale operation succeeds and the newly reported cluster topology shows us 6 partitions with 3 replicas each, evenly distributed across 6 instead of 3 brokers:</p>
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"Brokers"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"Partitions"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">6</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">3</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">4</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"LastChange"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">14</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"Status"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"COMPLETED"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"StartedAt"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"2023-12-18T15:12:57.790824149Z"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"CompletedAt"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"2023-12-18T15:30:20.920657536Z"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>All partitions are reported as healthy and leadership is balanced:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos topology</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Node      |Partition 1         |Partition 2         |Partition 3         |Partition 4         |Partition 5         |Partition 6</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">0         |LEADER (HEALTHY)    |                    |                    |                    |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1         |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)    |                    |                    |                    |FOLLOWER (HEALTHY)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2         |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)    |                    |                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3         |                    |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)    |                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4         |                    |                    |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">5         |                    |                    |                    |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The operation succeeded in about 17 minutes, longer than usual because of the restarts:
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/scaleup-completed-dc316353bae64ec8f5db4e3b15b5388f.png" width="840" height="296" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="scaling-down-should-be-resilient-to-broker-restarts">Scaling down should be resilient to broker restarts<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/18/Dynamically-scaling-brokers#scaling-down-should-be-resilient-to-broker-restarts" class="hash-link" aria-label="Direct link to Scaling down should be resilient to broker restarts" title="Direct link to Scaling down should be resilient to broker restarts">â€‹</a></h2>
<p>Exactly like scaling up, scaling down is also a high-level operation that consists of many steps that need to be carried out by all brokers in the cluster.
Before a broker can leave, another broker first needs to join the replication group to ensure that we maintain a replication factor of 3 at all times.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-1">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/18/Dynamically-scaling-brokers#expected-1" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>Even when brokers are restarting, the scale operation should eventually succeed with the expected cluster topology as result.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-1">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/18/Dynamically-scaling-brokers#actual-1" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="verify-steady-state-1">Verify steady state<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/18/Dynamically-scaling-brokers#verify-steady-state-1" class="hash-link" aria-label="Direct link to Verify steady state" title="Direct link to Verify steady state">â€‹</a></h4>
<p>We start with the cluster topology that we got as result of the previous experiment.
6 partitions with 3 replicas distributed over 6 brokers:</p>
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"Brokers"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"Partitions"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">6</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">3</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">4</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"LastChange"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">14</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"Status"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"COMPLETED"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"StartedAt"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"2023-12-18T15:12:57.790824149Z"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"CompletedAt"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"2023-12-18T15:30:20.920657536Z"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>All partitions are reported as healthy and leadership is balanced:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos topology</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Node      |Partition 1         |Partition 2         |Partition 3         |Partition 4         |Partition 5         |Partition 6</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">0         |LEADER (HEALTHY)    |                    |                    |                    |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1         |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)    |                    |                    |                    |FOLLOWER (HEALTHY)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2         |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)    |                    |                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3         |                    |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)    |                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4         |                    |                    |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">5         |                    |                    |                    |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="scaling-down-with-broker-restarts">Scaling down with broker restarts<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/18/Dynamically-scaling-brokers#scaling-down-with-broker-restarts" class="hash-link" aria-label="Direct link to Scaling down with broker restarts" title="Direct link to Scaling down with broker restarts">â€‹</a></h4>
<p>We scale down with <code>zbchaos cluster scale --brokers 3</code> and restart a random broker every 30 seconds:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos cluster scale --brokers 3 &amp;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ while true; do sleep 30; zbchaos restart broker --nodeId $(shuf -i 0-5 -n 1); done</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="result-1">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/18/Dynamically-scaling-brokers#result-1" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">â€‹</a></h3>
<p>All 6 partitions with 3 replicas each are evenly distributed across 3 brokers, leading to 6 partitions for each broker again.</p>
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"Brokers"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"Partitions"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">3</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">4</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">6</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"LastChange"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"Id"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">16</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"Status"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"COMPLETED"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"StartedAt"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"2023-12-18T16:07:07.208363298Z"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">"CompletedAt"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"2023-12-18T16:28:58.836369836Z"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"PendingChange"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token null keyword" style="color:#00009f">null</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>All partitions are healthy and leadership is distributed evenly:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos topology</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Node      |Partition 1         |Partition 2         |Partition 3           |Partition 4         |Partition 5         |Partition 6</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">0         |LEADER (UNHEALTHY)  |FOLLOWER (HEALTHY)  |FOLLOWER (UNHEALTHY)  |LEADER (HEALTHY)    |FOLLOWER (HEALTHY)  |FOLLOWER (UNHEALTHY)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1         |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)    |FOLLOWER (HEALTHY)    |FOLLOWER (HEALTHY)  |LEADER (UNHEALTHY)  |FOLLOWER (HEALTHY)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2         |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)      |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The operation completes in 21 minutes, longer than usual because of the restarts:
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/scaledown-completed-5e14c6c4d0bd0ef621e64b075c1620ab.png" width="840" height="296" class="img_ev3q"></p>]]></content:encoded>
            <category>availability</category>
            <category>performance</category>
        </item>
        <item>
            <title><![CDATA[Job push resiliency]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency</guid>
            <pubDate>Wed, 06 Dec 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[In today's chaos day we experimented with job push resiliency.]]></description>
            <content:encoded><![CDATA[<p>In today's chaos day we experimented with job push resiliency.</p>
<p>The following experiments we have done today:</p>
<ol>
<li>Job streams should be resilient to gateway restarts/crash</li>
<li>Job streams should be resilient to leadership changes/leader restarts</li>
<li>Job streams should be resilient to cluster restarts</li>
</ol>
<p><strong>TL;DR;</strong> All experiments succeeded and showcased the resiliency even on component restarts. <!-- -->ðŸš€</p>
<p>To reduce the blast radius and to better verify that everything works as expected we use a trimmed version of our benchmark setup. This means three brokers, one partition, replication factor three, and one gateway. No starter deployed. We deployed one worker with a very high polling interval, to make sure that we rely on streaming.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="gateway-restarts">Gateway restarts<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#gateway-restarts" class="hash-link" aria-label="Direct link to Gateway restarts" title="Direct link to Gateway restarts">â€‹</a></h2>
<p>In our first experiment, we wanted to verify that: Job streaming should be resilient to gateway restarts/crashes.</p>
<p>The experiment will look like the following:</p>
<ul>
<li>Verify steady state:<!-- -->
<ul>
<li>Cluster is healthy</li>
<li>When creating an instance, and start streaming we can retrieve and complete the corresponding job</li>
</ul>
</li>
<li>Chaos injection:<!-- -->
<ul>
<li>Restarting the gateway</li>
</ul>
</li>
<li>Verify steady state:<!-- -->
<ul>
<li>Cluster is healthy</li>
<li>When creating an instance, and start streaming we can retrieve and complete the corresponding job</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>We expect that even after a gateway restart we can retrieve a job (the stream should be recreated) and complete our new instance.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>We deployed the worker (with a replica of one), and configured it with a high polling interval <code>-Dapp.worker.pollingDelay=24h</code>.</p>
<p>To run any instances we need to deploy once the benchmark process model</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">zbchaos deploy process</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Deployed given process model , under key 2251799813685249!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="verify-steady-state">Verify steady state<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#verify-steady-state" class="hash-link" aria-label="Direct link to Verify steady state" title="Direct link to Verify steady state">â€‹</a></h4>
<p>We verify the readiness and the instance creation.</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify readiness</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify instance-creation --awaitResult --verbose</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Flags: {1 LEADER -1  10  msg true 1 LEADER -1 2 LEADER -1 1701853048870 false false true false false 30 false -1 benchmark 30   1 1 benchmark-task}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Connecting to ck-np-chaos-day-job-push</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Running experiment in self-managed environment.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Port forward to ck-np-chaos-day-job-push-zeebe-gateway-68695d9cb5-lhgg5</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Successfully created port forwarding tunnel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">We await the result of the process instance creation, thus we skip the partition id check.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Send create process instance command, with BPMN process ID 'benchmark' and version '-1' (-1 means latest) [variables: '', awaitResult: true]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Created process instance with key 2251799813685251 on partition 1, required partition 0.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady-state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="injecting-chaos">Injecting chaos<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#injecting-chaos" class="hash-link" aria-label="Direct link to Injecting chaos" title="Direct link to Injecting chaos">â€‹</a></h4>
<p>Next, we will restart the gateway.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos restart gateway --verbose</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Flags: {1 LEADER -1  10  msg false 1 LEADER -1 2 LEADER -1 1701853221588 false false true false false 30 false -1 benchmark 30   1 1 benchmark-task}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Connecting to ck-np-chaos-day-job-push</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Running experiment in self-managed environment.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Restarted ck-np-chaos-day-job-push-zeebe-gateway-68695d9cb5-lhgg5</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="verify-steady-state-1">Verify steady state<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#verify-steady-state-1" class="hash-link" aria-label="Direct link to Verify steady state" title="Direct link to Verify steady state">â€‹</a></h4>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify readiness</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify instance-creation --awaitResult</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady-state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="result">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#result" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">â€‹</a></h3>
<p>The experiment succeeded. We were able to verify the steady state after the chaos injection. Furthermore, we observe in the metrics as well that the jobs have been pushed after the gateway restart. <!-- -->âœ…</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/job-push-gw-restart-16711afa005a27b6101bbd940f6f1489.png" width="939" height="667" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="with-termination">With termination<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#with-termination" class="hash-link" aria-label="Direct link to With termination" title="Direct link to With termination">â€‹</a></h3>
<p>We wanted to verify the same by terminating the gateway instead of a graceful shutdown (which is done within the restart command).</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos terminate gateway --verbose</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Flags: {1 LEADER -1  10  msg false 1 LEADER -1 2 LEADER -1 1701853482263 false false true false false 30 false -1 benchmark 30   1 1 benchmark-task}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Connecting to ck-np-chaos-day-job-push</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Running experiment in self-managed environment.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Terminated ck-np-chaos-day-job-push-zeebe-gateway-68695d9cb5-jqfzg</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Verifying the steady stated again showed no unexpected issues.</p>
<p>Out of interest we checked what is happening in worker:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">09:05:44.047 [pool-5-thread-3] WARN  io.camunda.zeebe.client.job.worker - Failed to stream jobs of type 'benchmark-task' to worker 'benchmark-worker'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">io.grpc.StatusRuntimeException: UNAVAILABLE: io exception</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We see as expected several <code>UNAVAILABLE: io exception</code> and later the worker recovered.</p>
<p>Based on the metrics we can observe the same. Jobs are pushed to the workers even after restarting the gateway.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/job-push-gw-terminate-0600fa2a9e4d0c5696531dc2da3bf391.png" width="941" height="658" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="leader-restart">Leader restart<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#leader-restart" class="hash-link" aria-label="Direct link to Leader restart" title="Direct link to Leader restart">â€‹</a></h2>
<p>In this experiment, we want to verify how resilient job push is on leader changes/restarts.</p>
<p>The verification of the steady state is the same as above, so I will skip this description here.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-1">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#expected-1" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>Workers shouldn't care about leader change, this should be handled fully by the gateway.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-1">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#actual-1" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="verify-steady-state-2">Verify steady state<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#verify-steady-state-2" class="hash-link" aria-label="Direct link to Verify steady state" title="Direct link to Verify steady state">â€‹</a></h4>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify readiness</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify instance-creation --awaitResult</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady-state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="inject-chaos">Inject chaos<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#inject-chaos" class="hash-link" aria-label="Direct link to Inject chaos" title="Direct link to Inject chaos">â€‹</a></h4>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos restart broker --partitionId 1 --role LEADER</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Restarted ck-np-chaos-day-job-push-zeebe-0</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="verify-steady-state-3">Verify steady state<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#verify-steady-state-3" class="hash-link" aria-label="Direct link to Verify steady state" title="Direct link to Verify steady state">â€‹</a></h4>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify readiness</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify instance-creation --awaitResult</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady-state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="result-1">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#result-1" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">â€‹</a></h3>
<p>We were able to verify that a leader restart doesn't cause issues and job push can handle such events.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/job-push-leader-restart-6e33baa1365cba88fc41cc9bbe92442b.png" width="926" height="866" class="img_ev3q"></p>
<p>We can see that the leader was changed, and also switched back shortly after.
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/leaderchanges-2760fa1660e1759211f9b7c3351b0ab7.png" width="475" height="311" class="img_ev3q"></p>
<p>This is caused by our leader-balancing cron job.
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/job-push-leader-restart-cronjob-fed9e516c29fde4f814cdfcb68e3f4c2.png" width="1799" height="421" class="img_ev3q"></p>
<p>This also means we had two leader changes, and the push was even pushed by the restarted node.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="complete-cluster-restart">Complete cluster restart<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#complete-cluster-restart" class="hash-link" aria-label="Direct link to Complete cluster restart" title="Direct link to Complete cluster restart">â€‹</a></h2>
<p>In this experiment, we wanted to verify whether job push can also handle a complete cluster restart.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-2">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#expected-2" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>Job push can handle a cluster restart and a corresponding job is pushed to the worker afterwards.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-2">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#actual-2" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="verify-steady-state-4">Verify steady state<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#verify-steady-state-4" class="hash-link" aria-label="Direct link to Verify steady state" title="Direct link to Verify steady state">â€‹</a></h4>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">â¯ zbchaos verify readiness</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">â¯ zbchaos verify instance-creation --awaitResult</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady-state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="inject-chaos-1">Inject chaos<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#inject-chaos-1" class="hash-link" aria-label="Direct link to Inject chaos" title="Direct link to Inject chaos">â€‹</a></h4>
<p>Right now <code>zbchaos</code> doesn't support restarting a complete cluster, so we had to fall back to <code>kubectl</code>.</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ kubectl delete pod -l=app=camunda-platform</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "ck-np-chaos-day-job-push-zeebe-0" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "ck-np-chaos-day-job-push-zeebe-1" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "ck-np-chaos-day-job-push-zeebe-2" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "ck-np-chaos-day-job-push-zeebe-gateway-68695d9cb5-hj2pf" deleted</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="verify-steady-state-5">Verify steady state<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#verify-steady-state-5" class="hash-link" aria-label="Direct link to Verify steady state" title="Direct link to Verify steady state">â€‹</a></h4>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify readiness</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify instance-creation --awaitResult</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady-state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="result-2">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#result-2" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">â€‹</a></h3>
<p>Again we were able to show that job push is resilient, and can even handle a complete cluster restart.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/job-push-cluster-restart-69a928cd76f5613126f41c66f5fd7644.png" width="930" height="677" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="found-bugs">Found Bugs<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#found-bugs" class="hash-link" aria-label="Direct link to Found Bugs" title="Direct link to Found Bugs">â€‹</a></h2>
<ul>
<li>On restart (especially on cluster restart) it looks like job push engine metrics are counted multiple times</li>
<li><a href="https://github.com/camunda/camunda/blob/a86decce9a46218798663e3466267a49adef506e/transport/src/main/java/io/camunda/zeebe/transport/stream/impl/RemoteStreamPusher.java#L55-L56C14" target="_blank" rel="noopener noreferrer">We found a place where we should better handle the exception in pushing async.</a></li>
</ul>]]></content:encoded>
            <category>availability</category>
            <category>resiliency</category>
        </item>
        <item>
            <title><![CDATA[Job push overloading]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading</guid>
            <pubDate>Thu, 30 Nov 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[In today's chaos day we (Nicolas and I) want to verify how job push behaves and in general, the Zeebe system when we have slow workers.]]></description>
            <content:encoded><![CDATA[<p>In today's chaos day we (Nicolas and I) want to verify how job push behaves and in general, the Zeebe system when we have slow workers.</p>
<p><strong>TL;DR;</strong> Right now it seems that even if we have a slow worker it doesn't impact the general system, and only affects the corresponding process instance, not other instances. We found no unexpected issues, everything performed pretty well.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">â€‹</a></h2>
<p>Firstly we want to verify that job push will not overload a worker or gateway when workers are slow.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>We expect that if the workers are slowing down, the load is distributed to other workers (if available), and it is expected that the general performance (of the affected process instance) should be slowed down. We wouldn't expect any restarts/failures on the gateway or workers.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>We deployed a normal benchmark, with <a href="https://github.com/camunda/camunda/blob/main/benchmarks/setup/default/values.yaml" target="_blank" rel="noopener noreferrer">default configurations</a>.</p>
<p>We slowed the workers down, in the sense that we changed <a href="https://github.com/zeebe-io/benchmark-helm/blob/main/charts/zeebe-benchmark/templates/worker.yaml#L30" target="_blank" rel="noopener noreferrer">the completionDelay to 1250 ms</a></p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp1-general-de6a6f7f1d6b52ae218f3c55ae8b33ce.png" width="1249" height="654" class="img_ev3q"></p>
<p>The throughput is lower than normal, as expected.</p>
<p>We see no significant increase in memory usage on the gateway, nor any outages because of this.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp1-gw-memory-220a9ab49a649d351bb58040bde2c4a0.png" width="628" height="307" class="img_ev3q"></p>
<p>We see that a high amount of job pushes fail (due to capacity constraints now in the workers).
!Jobs are yielded back to the engine.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp1-records-26fd0549438faf9475280e80678bc2ce.png" width="1249" height="344" class="img_ev3q"></p>
<p>So far so good, first experiment worked as expected <!-- -->âœ…</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="second-chaos-experiment">Second Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#second-chaos-experiment" class="hash-link" aria-label="Direct link to Second Chaos Experiment" title="Direct link to Second Chaos Experiment">â€‹</a></h2>
<p>The normal scenario when something is slow is for a user to scale up. This is what we did in the next experiment, we scaled the workers to 10 replicas (from 3), to verify how the system behaves in this case.</p>
<p>Something to keep in mind when the completion delay is 1250ms, we <a href="https://github.com/camunda/camunda/blob/7002d53a079c06ab3a94f5485f022681a41dc9ed/benchmarks/project/src/main/java/io/camunda/zeebe/Worker.java#L113" target="_blank" rel="noopener noreferrer">multiply the activation timeout by 6 in our workers</a>. This means completionDelay: 1250 -&gt; job timeout 7.5s</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-1">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#expected-1" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>We expect that we can reach a higher throughput.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-1">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#actual-1" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>Scaling the workers to 10:</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">k scale deployment worker --replicas=10</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp2-general-fcdc544e61dee39561dd634ff2259c8e.png" width="1240" height="647" class="img_ev3q"></p>
<p>We can see that after scaling we can complete more jobs.</p>
<p>The gateway memory seems to be not really affected.
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp2-gw-mem-1c710a1cc021fd9a369efee7871a6eef.png" width="633" height="307" class="img_ev3q"></p>
<p>In the job push metrics we see less job push failures.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp2-job-push-56d12fe3469c8287fdc4b6fca3d7175f.png" width="1247" height="638" class="img_ev3q"></p>
<p>When we check the written records we can see a decrease in yield, but an increase in timeouts. The reason is that we have to try several workers before giving it back.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp2-records-37ead57c1e5b9bf03bb812ee7d58abf0.png" width="1254" height="342" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp2-records2-b3733ab69b894a659d211e164c939e9e.png" width="1244" height="344" class="img_ev3q"></p>
<p>Experiment two worked as expected. <!-- -->âœ…</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="third-chaos-experiment">Third Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#third-chaos-experiment" class="hash-link" aria-label="Direct link to Third Chaos Experiment" title="Direct link to Third Chaos Experiment">â€‹</a></h2>
<p>In a real-world scenario, it will not happen if you have a slow dependency, for which for example a worker waits that you can scale and this will solve your problems. Likely you will get even slower because more pressure is put on the dependency. To mimic this scenario we experimented with increasing the completion time again. A completion delay set to 2500ms, means a job timeout of 15s.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-2">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#expected-2" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>We expect after slowing down all workers again, that our throughput goes down again, but we should see no general error. Potentially a slight memory increase because of buffering of jobs.</p>
<p>This also means more yields and fewer timeouts.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-2">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#actual-2" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>As expected again we see a drop in throughput, but it is still a bit higher than at the first experiment.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp3-general-88403398292f5c5cdbac3a1b9b8ee63d.png" width="1253" height="648" class="img_ev3q"></p>
<p>No difference at all in the memory consumption, by the gateway.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp3-memory-769d10a88790ea58ca00a995effcfa7c.png" width="628" height="306" class="img_ev3q"></p>
<p>In the records we can also again see that yield increase, and timeouts have been decreased.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp3-records-bf6c88f09631f951d4d272c346ee7768.png" width="1257" height="686" class="img_ev3q"></p>
<p>Experiment three worked as expected. <!-- -->âœ…</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="several-further-experiments">Several further experiments<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#several-further-experiments" class="hash-link" aria-label="Direct link to Several further experiments" title="Direct link to Several further experiments">â€‹</a></h2>
<p>We did several further experiments where we scaled the workers, played with the completion delay, reduced the starter load etc. At some point, we reached a state size that was too big (~2 Gig) such that this impacted our processing. We had to drain the cluster and stop the starters completely.</p>
<p>Interestingly was that when we reduced the completion delay, we just had a slight increase in completion, when we scaled down the workers (marked with the annotation in the graph), to reduce activations, we saw no difference.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp6-general-f35222d6e1d66526ef6eb07c53f10923.png" width="1258" height="646" class="img_ev3q"></p>
<p>Only when we hit a certain threshold in RocksDb (it seems to be at least), the completion went up by a lot.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp6-state-f33212be78503a223b0741b9d7a340e1.png" width="615" height="304" class="img_ev3q"></p>
<p>This is because the record processing latency was heavily reduced (likely the commit latency or iteration latency in RocksDb).</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp6-latency-0b30edf17db48cf5d056bafe677cced4.png" width="1259" height="276" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="experiment-with-worker-impact">Experiment with worker impact<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#experiment-with-worker-impact" class="hash-link" aria-label="Direct link to Experiment with worker impact" title="Direct link to Experiment with worker impact">â€‹</a></h2>
<p>We wanted to understand and experiment with the impact of a slow worker on different process instances.</p>
<p>To see such an impact in our metrics we had to patch our current execution metrics, such that includes the BPMN processId, so we can differentiate between execution times of different processes.</p>
<p>See the related branch for more details <a href="https://github.com/camunda/camunda/tree/ck-latency-metrics" target="_blank" rel="noopener noreferrer">ck-latency-metrics</a></p>
<p>Furthermore, a new process model was added <code>slow-task.bpm</code> and new deployments to create such instances and work on them. The process model was similar to the benchmark model, only the job type has been changed.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-3">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#expected-3" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>To verify was that whether a slow worker would impact other instances, this was uncertain territory we were hitting.</p>
<p>To be honest we expected it would affect them.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-3">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#actual-3" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>We started the benchmark (default configs for broker and gateway), with additional configurations:</p>
<ul>
<li>benchmark starter with 75 PI/s rate</li>
<li>3 benchmark worker (60 capacity) and completion delay of 50 ms</li>
<li>slow-task starter with 75 PI/s rate</li>
<li>3 slow-worker (60 capacity) and a completion delay of 50 ms (at the begin)</li>
</ul>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/slow-exp-base-ea8adfd10aa658d81ca76a4c342f5df7.png" width="2539" height="871" class="img_ev3q"></p>
<p>We can see based on the metrics that the execution latency is the same for both process instances, and we are able to complete our 150 PI/s.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/slow-exp-base-general-25e62c9332f1ecad2df0cb8253bb188d.png" width="1894" height="644" class="img_ev3q"></p>
<p>We slowed now the worker for the type <code>slow-task</code> down to a completion delay of 2500ms.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/slow-exp-slow-worker-2500ms-records-388a523821cc584224d95d43b30c8c6d.png" width="1694" height="682" class="img_ev3q"></p>
<p>We can see that we start to get <code>Job.YIELD</code> commands from the gateway, and we can see that the process instance execution is slowed down.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/slow-exp-slow-worker-2500ms-9c93bc66fc1f410535f45a170ba6b96a.png" width="2544" height="875" class="img_ev3q"></p>
<p>Interestingly that is only for the affected process instance, which we wanted to validate/verify.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="reasoning">Reasoning<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#reasoning" class="hash-link" aria-label="Direct link to Reasoning" title="Direct link to Reasoning">â€‹</a></h3>
<p>Our first assumption was that both instance latencies would be impacted, because are writing YIELD commands, instead of being able to complete them.</p>
<p>But another consequence comes into play. If fewer jobs are worked on, there are also fewer jobs completed, this means fewer process instances have to be continued (with batch processing until the end).</p>
<p>This means a load of yield underweights the normal load of job completions, with additional process instance continuation. That was an interesting insight for us.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="result">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#result" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">â€‹</a></h2>
<p>Right now it seems that even if we have a slow worker it doesn't impact badly the general system, and only affects the corresponding process instance, not other instances.</p>
<p>What we should or need to investigate further what if the job completion delay is much larger than the timeout. This is something we might want to test soon.</p>]]></content:encoded>
            <category>availability</category>
        </item>
        <item>
            <title><![CDATA[Hot backups impact on processing]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing</guid>
            <pubDate>Tue, 07 Nov 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[Today, we want to experiment with hot backups in SaaS and a larger runtime state in Zeebe and how it impacts the ongoing processing in Zeebe (or not?). This is part of the investigation of a recently created bug issue we wanted to verify/reproduce #14696.]]></description>
            <content:encoded><![CDATA[<p>Today, we want to experiment with hot backups in SaaS and a larger runtime state in Zeebe and how it impacts the ongoing processing in Zeebe (or not?). This is part of the investigation of a recently created bug issue we wanted to verify/reproduce <a href="https://github.com/camunda/camunda/issues/14696" target="_blank" rel="noopener noreferrer">#14696</a>.</p>
<p><strong>TL;DR;</strong> We were able to prove that hot backups are indeed not impacting overall processing throughput in Zeebe. We found that having a full Elasticsearch disk might impact or even fail your backups, which is intransparent to the user.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">â€‹</a></h2>
<p>For the experiment, we have set up a Camunda SaaS cluster (G3-M configuration), and run the <a href="https://github.com/camunda/camunda/tree/main/benchmarks/setup/cloud-default" target="_blank" rel="noopener noreferrer">cloud benchmark</a> workload against it. During the experiment, we will run a stable load, which will cause to increase in the runtime state. We will create/initiate in different stages backups to verify the impact on processing depending on state size.</p>
<p>We kept the starter rate (creation of process instance 100 PI/s) but reduced the worker capacity and replicas.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>Hot backups were built with the premise of not disrupting the processing throughput in Zeebe, which is why we define the following hypothesis:</p>
<blockquote>
<p><strong>Hypothesis</strong></p>
<p>Creating hot backups should not impact Zeebe's <em>processing throughput <em>no</em> matter how</em> large the runtime state is in Zeebe.</p>
</blockquote>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>We created a cluster in the Camunda SaaS environment (in our internal stage).</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="step-one">Step one<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#step-one" class="hash-link" aria-label="Direct link to Step one" title="Direct link to Step one">â€‹</a></h4>
<p>We created a first backup to verify that it works without issues.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="result">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#result" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">â€‹</a></h5>
<p>Success on stage one creating a backup with no actual state.</p>
<p><img decoding="async" loading="lazy" alt="first-backup" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/first-backup-5d70b491b31ac0fd1eb11d052277570c.png" width="1890" height="683" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="step-two">Step two<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#step-two" class="hash-link" aria-label="Direct link to Step two" title="Direct link to Step two">â€‹</a></h4>
<p>We started a stable load as mentioned <a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#chaos-experiment">above</a>. After reaching around ~100 MB runtime state at each partition we triggered a backup.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="result-1">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#result-1" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">â€‹</a></h5>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/general-sec-bk-c0c03a786b5e701fd6ccc9bd75f9bd78.png" width="1887" height="498" class="img_ev3q"></p>
<p>The backup was successful and we were not able to observe any disruption in the processing throughput. We can see that during the backup is taken the exporting is paused (which is expected) and afterwards it is starting to export again. <!-- -->âœ…</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="step-three">Step three<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#step-three" class="hash-link" aria-label="Direct link to Step three" title="Direct link to Step three">â€‹</a></h4>
<p>At a later stage, we tried to take a backup again with around ~300MB of runtime state in Zeebe.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="result-2">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#result-2" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">â€‹</a></h5>
<p>Based on the output from Console the backup was successful and took around one hour.</p>
<p><img decoding="async" loading="lazy" alt="third-console" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/sec-bk-console-8af4a5c33d75d3628548f9d7b21c4a66.png" width="1364" height="276" class="img_ev3q"></p>
<p>Based on our internal metrics we can also see that there is no impact on the processing throughput</p>
<p><img decoding="async" loading="lazy" alt="general-third" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/general-third-bk-3ac8aaa53e75ac20345f7ab64c6a27e3.png" width="1888" height="688" class="img_ev3q"></p>
<p>What is unclear to me is that it looks like we only took a backup of partition two. This needs to be further investigated, it might be also that the metrics are just confusing since it is resetting after the pod restarts.<!-- -->ðŸ›</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="step-four">Step four<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#step-four" class="hash-link" aria-label="Direct link to Step four" title="Direct link to Step four">â€‹</a></h4>
<p>Here we come into struggle after running the load on the cluster for quite some time we reached a runtime state size of ~1 gig. Furthermore, we filled our Elasticsearch disk tremendously.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="result-3">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#result-3" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">â€‹</a></h5>
<p>At this time we were no longer able to successfully create backups. Here I tried it first without interacting with the cluster. It failed after 1.5 hours, which is potentially the timeout.</p>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/third-bk-console-8c301c13085c61e11b5d5cafc6e245bb.png" width="1833" height="271" class="img_ev3q"></p>
<p>The backup failed, because of elastic was full.</p>
<p><img decoding="async" loading="lazy" alt="elastic-full" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/deleting-indices4-c2d15986b9499ae4ac28f1c264b1709e.png" width="1889" height="369" class="img_ev3q"></p>
<p>I went ahead to remove some data from Elastic to keep experimenting.</p>
<p><img decoding="async" loading="lazy" alt="elastic-indices" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/deleting-indices3-2051dac5d38acbe4b05b930e152283e7.png" width="1240" height="321" class="img_ev3q">
<img decoding="async" loading="lazy" alt="delete-indices" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/deleting-indices2-c6c439bda96f933647a197156063af9e.png" width="1260" height="407" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="step-five">Step five<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#step-five" class="hash-link" aria-label="Direct link to Step five" title="Direct link to Step five">â€‹</a></h4>
<p>After cleaning the Elasticsearch we retried taking a backup again. At this step, we already reached a runtime state of ~1.25G for each partition, which is quite huge.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="result-4">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#result-4" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">â€‹</a></h5>
<p>The backup took quite a while and failed again.</p>
<p><img decoding="async" loading="lazy" alt="last-bk" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/last-bk-failed-ec7ad090bc219c0a563e44cc123b3942.png" width="1814" height="398" class="img_ev3q"></p>
<p>What we can see based on the times it is likely that it here timed out again. Taking a look at the metrics we see that a backup was processed in Zeebe.</p>
<p>It had no impact on the ongoing processing throughput.</p>
<p><img decoding="async" loading="lazy" alt="fifth-bk" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/general-fifth-bk-162b830758b48c2b2a2d4359960c40e8.png" width="1895" height="685" class="img_ev3q"></p>
<p>At a later stage, we tried another backup with ~1.45G of runtime state even here we were not able to observe any issues related to the impact on processing throughput.</p>
<p><img decoding="async" loading="lazy" alt="sixth" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/general-sixth-bk-8c901d74d9665263b9436406aaeac29d.png" width="1890" height="688" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">â€‹</a></h3>
<p>âœ…<!-- --> We were able to prove that even on a large runtime state there is no observable impact on processing throughput in Zeebe.</p>
<p>Furthermore, we have seen that having a large Elastic state (almost full disk) will impact taking backups and is likely to fail them. We might need to iterate here, whether we want to tune the backup strategy, give elastic more space when taking backups, or adjust watermarks, etc.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="follow-ups">Follow-ups<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#follow-ups" class="hash-link" aria-label="Direct link to Follow-ups" title="Direct link to Follow-ups">â€‹</a></h4>
<p>We have to investigate the marking of failed backups, whether it is because of a timeout in the Operator or whether these backups are failed. It looks to me like they are marked as failed, even if they may succeed.</p>
<p>Furthermore, the completed backups seem to be misleading and are reset which causes inconsistent views.</p>]]></content:encoded>
            <category>availability</category>
        </item>
        <item>
            <title><![CDATA[Using Large Multi-Instance]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2023/06/02/Using-Large-Multi-Instance</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2023/06/02/Using-Large-Multi-Instance</guid>
            <pubDate>Fri, 02 Jun 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[New day new chaos. In today's chaos day I want to pick up a topic, which had bothered people for long time. I created a chaos day three years ago around this topic as well.]]></description>
            <content:encoded><![CDATA[<p>New day new chaos. <!-- -->ðŸ’€<!-- --> In today's chaos day I want to pick up a topic, which had bothered people for long time. I created a <a href="https://zeebe-io.github.io/zeebe-chaos/2020/07/16/big-multi-instance/" target="_blank" rel="noopener noreferrer">chaos day three years ago</a> around this topic as well.</p>
<p>Today, we experiment with large multi-instances again. In the recent patch release <a href="https://github.com/camunda/camunda/releases/tag/8.2.5" target="_blank" rel="noopener noreferrer">8.2.5</a> we fixed an issue with spawning larger multi instances. Previously if you have created a process instance with a large multi-instance it was likely that this caused to blacklist the process instance, since the multi-instance spawning ran into <code>maxMessageSize</code> limitations.</p>
<p>This means the process instance was stuck and was no longer executable. In Operate this was not shown and caused a lot of friction or confusion to users. With the recent fix, Zeebe should chunk even large collections into smaller batches to spawn/execute the multi-instance without any issues.</p>
<p><strong>TL;DR;</strong> We were able to see that even large multi-instances can be executed now. <!-- -->âœ…<!-- --> At some point, we experienced performance regressions (during creating new multi-instance elements) but the execution of the process instance doesn't fail anymore. One problem at a time, we will likely investigate further to improve the performance of such a use case.</p>
<p>When we reached the <code>maxMessageSize</code> we got a rejection, if the input collection is too large we see some weird unexpected errors from NGINX.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2023/06/02/Using-Large-Multi-Instance#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">â€‹</a></h2>
<p>We do regularly game days in Camunda, and for such we also create projects to make incidents, etc. reproducible. In today's chaos day, I will reuse some code created by <a href="https://github.com/saig0" target="_blank" rel="noopener noreferrer">Philipp Ossler</a>, thanks for that :bow: Since we mimic in such game days customers, the process is a bit more complex than necessary for such chaos day, but I will keep it like that.</p>
<p><img decoding="async" loading="lazy" alt="order-process" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/order-process-0eb9e9dc5b698919f847deb859f67f2d.png" width="3213" height="1152" class="img_ev3q"></p>
<p>The input collection <code>items</code>, which is used in the multi-instance is generated via:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">    // input size</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    final var items = IntStream.range(0, size).mapToObj(i -&gt; Map.ofEntries(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        entry("id", i)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    )).toList();</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>In the following experiment, we will play around with the <code>size</code> value.</p>
<p>For the experiment, we will use a Camunda 8 SaaS cluster with the generation <code>Zeebe 8.2.5</code> (G3-S).</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/06/02/Using-Large-Multi-Instance#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>When creating a process instance with a large collection, we expect based on the recent bug fix that the multi-instance creation is batched and created without issues.</p>
<p>One limiting factor might be the <code>maxMessageSize</code> with regard to the input collection, but in this case, I would expect that the creation of the process instance is already rejected before.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/06/02/Using-Large-Multi-Instance#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>Between the following experiments, I always recreated the clusters, to reduce the blast radius and better understand and isolate the impact.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="starting-small-20k">Starting small (20k)<a href="https://zeebe-io.github.io/zeebe-chaos/2023/06/02/Using-Large-Multi-Instance#starting-small-20k" class="hash-link" aria-label="Direct link to Starting small (20k)" title="Direct link to Starting small (20k)">â€‹</a></h4>
<p>In previous versions, the multi-instance creation failed already quite early. For example in the game day reproducer project, we had a collection defined with <code>20.000</code> items, which we are now reusing for the start.</p>
<p>The creation of the process instance worked without any issues. We can observe in Operate the incremental creation of sub-process instances, which is great.</p>
<p><img decoding="async" loading="lazy" alt="incremental-creation-20k" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/20k-operate-inc-b0e507b77799c7f950ff444259c8341f.png" width="1757" height="868" class="img_ev3q"></p>
<p>We can see in the metrics that batch processing is limited by only 2-4 commands in a batch. That is an interesting fact that might explain why it takes a while until all instances of the multi-instance sub-process are created. We can even see rollbacks during batch processing, visible in the "Number of batch processing retries" panel.</p>
<p><img decoding="async" loading="lazy" alt="processing-metrics-20k" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/20k-processing-metrics-f3f057027ec451f9024d242df2d1bef6.png" width="1894" height="755" class="img_ev3q"></p>
<p>The processing queue seems to increase dramatically.</p>
<p>After a while, we can see that all 20k instances are created without any bigger issues. <!-- -->ðŸš€</p>
<p><img decoding="async" loading="lazy" alt="complete-20k" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/20k-operate-complete-31c5d2b848c51c7b1a96e8dc6f23b5d6.png" width="1912" height="834" class="img_ev3q"></p>
<p>It took around 10 minutes. Taking a look at the metrics again we see that in between big command batches have been created/processed, which allowed us to reduce the processing queue.</p>
<p><img decoding="async" loading="lazy" alt="processing-metrics-20k-pt2" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/20k-processing-metrics-2-7976048beb0f6300cf5577d40f2c9f47.png" width="1896" height="762" class="img_ev3q"></p>
<p>In between the backpressure was quite high, but after the creation of all instances, the cluster is in a healthy state again. The creation of such multi-instance worked <!-- -->âœ…</p>
<p><img decoding="async" loading="lazy" alt="general-metrics-20k" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/20k-general-metrics-a525d7f1500dac0fd03d460b849e12e4.png" width="1893" height="940" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="increase-collection-200k">Increase collection (200k)<a href="https://zeebe-io.github.io/zeebe-chaos/2023/06/02/Using-Large-Multi-Instance#increase-collection-200k" class="hash-link" aria-label="Direct link to Increase collection (200k)" title="Direct link to Increase collection (200k)">â€‹</a></h4>
<p>Again, the creation of such a process instance was not a problem itself. We can observe the creation of the sub-process instances (multi-instance) in Operate, which happens incrementally.</p>
<p><img decoding="async" loading="lazy" alt="incremental-creation-200k" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/200k-operate-inc-586ee3f6c124c92cc6700df1b6213950.png" width="1905" height="871" class="img_ev3q"></p>
<p>It takes ages until the instances are created (After 3h ~66k instances are created). Again we see here small chunks of batches, and there are also rollbacks during batch processing.</p>
<p><img decoding="async" loading="lazy" alt="processing-metrics-200k" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/200k-processing-metrics-7a21b4741eec54581b30f819b05f3de2.png" width="1881" height="753" class="img_ev3q"></p>
<p>The processing of that partitions is in this case blocked by the multi-instance creation, we can see that on the 100% back pressure. <!-- -->âŒ</p>
<p><img decoding="async" loading="lazy" alt="general-metrics-200k" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/200k-general-metrics-3975fc0c4c761c321194cd69598a8d11.png" width="1883" height="868" class="img_ev3q"></p>
<p>Even after one hour, not all instances are created (not even 20k), it takes longer than before the creation of 20.000 instances.</p>
<p><img decoding="async" loading="lazy" alt="incremental-creation-200k-part2" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/200k-operate-inc2-8e393502149c7dc21706229b02979515.png" width="2251" height="931" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="make-it-really-big-2-million">Make it really big (2 million)<a href="https://zeebe-io.github.io/zeebe-chaos/2023/06/02/Using-Large-Multi-Instance#make-it-really-big-2-million" class="hash-link" aria-label="Direct link to Make it really big (2 million)" title="Direct link to Make it really big (2 million)">â€‹</a></h4>
<p>To escalate this even more I increase the input collection again by a factor of 10 to 2 million.</p>
<p>After creation, I see as a response the following log message in my log:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Failed to create process instance of 'order-process'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">io.camunda.zeebe.client.api.command.ClientStatusException: HTTP status code 502</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">invalid content-type: text/html</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">headers: Metadata(:status=502,date=Fri, 02 Jun 2023 11:44:57 GMT,content-type=text/html,strict-transport-security=max-age=63072000; includeSubDomains,content-length=150)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">DATA-----------------------------</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;html&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;head&gt;&lt;title&gt;502 Bad Gateway&lt;/title&gt;&lt;/head&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;body&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;center&gt;&lt;h1&gt;502 Bad Gateway&lt;/h1&gt;&lt;/center&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/body&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/html&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.zeebe.client.impl.ZeebeClientFutureImpl.transformExecutionException(ZeebeClientFutureImpl.java:93) ~[zeebe-client-java-8.0.5.jar:8.0.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.zeebe.client.impl.ZeebeClientFutureImpl.join(ZeebeClientFutureImpl.java:50) ~[zeebe-client-java-8.0.5.jar:8.0.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.cloud.gameday.ProcessApplication.createProcessInstance(ProcessApplication.java:90) ~[classes/:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.cloud.gameday.ProcessApplication.createInstanceOfProcess(ProcessApplication.java:71) ~[classes/:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.cloud.gameday.ProcessApplication.run(ProcessApplication.java:58) ~[classes/:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at org.springframework.boot.SpringApplication.callRunner(SpringApplication.java:791) ~[spring-boot-2.5.2.jar:2.5.2]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at org.springframework.boot.SpringApplication.callRunners(SpringApplication.java:775) ~[spring-boot-2.5.2.jar:2.5.2]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at org.springframework.boot.SpringApplication.run(SpringApplication.java:345) ~[spring-boot-2.5.2.jar:2.5.2]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1343) ~[spring-boot-2.5.2.jar:2.5.2]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1332) ~[spring-boot-2.5.2.jar:2.5.2]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.cloud.gameday.ProcessApplication.main(ProcessApplication.java:46) ~[classes/:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Caused by: java.util.concurrent.ExecutionException: io.grpc.StatusRuntimeException: UNAVAILABLE: HTTP status code 502</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">invalid content-type: text/html</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">headers: Metadata(:status=502,date=Fri, 02 Jun 2023 11:44:57 GMT,content-type=text/html,strict-transport-security=max-age=63072000; includeSubDomains,content-length=150)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">DATA-----------------------------</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;html&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;head&gt;&lt;title&gt;502 Bad Gateway&lt;/title&gt;&lt;/head&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;body&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;center&gt;&lt;h1&gt;502 Bad Gateway&lt;/h1&gt;&lt;/center&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/body&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/html&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396) ~[na:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073) ~[na:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.zeebe.client.impl.ZeebeClientFutureImpl.join(ZeebeClientFutureImpl.java:48) ~[zeebe-client-java-8.0.5.jar:8.0.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	... 9 common frames omitted</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>I tried to incrementally decrease the input collection until it is working again, when reaching 250k I finally see a better understandable error.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">2023-06-02 13:53:51.485 ERROR 29870 --- [           main] i.c.cloud.gameday.ProcessApplication     : Failed to create process instance of 'order-process'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">io.camunda.zeebe.client.api.command.ClientStatusException: Command 'CREATE' rejected with code 'EXCEEDED_BATCH_RECORD_SIZE': </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.zeebe.client.impl.ZeebeClientFutureImpl.transformExecutionException(ZeebeClientFutureImpl.java:93) ~[zeebe-client-java-8.0.5.jar:8.0.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.zeebe.client.impl.ZeebeClientFutureImpl.join(ZeebeClientFutureImpl.java:50) ~[zeebe-client-java-8.0.5.jar:8.0.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.cloud.gameday.ProcessApplication.createProcessInstance(ProcessApplication.java:90) ~[classes/:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.cloud.gameday.ProcessApplication.createInstanceOfProcess(ProcessApplication.java:71) ~[classes/:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.cloud.gameday.ProcessApplication.run(ProcessApplication.java:58) ~[classes/:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at org.springframework.boot.SpringApplication.callRunner(SpringApplication.java:791) ~[spring-boot-2.5.2.jar:2.5.2]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at org.springframework.boot.SpringApplication.callRunners(SpringApplication.java:775) ~[spring-boot-2.5.2.jar:2.5.2]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at org.springframework.boot.SpringApplication.run(SpringApplication.java:345) ~[spring-boot-2.5.2.jar:2.5.2]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1343) ~[spring-boot-2.5.2.jar:2.5.2]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1332) ~[spring-boot-2.5.2.jar:2.5.2]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.cloud.gameday.ProcessApplication.main(ProcessApplication.java:46) ~[classes/:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Caused by: java.util.concurrent.ExecutionException: io.grpc.StatusRuntimeException: UNKNOWN: Command 'CREATE' rejected with code 'EXCEEDED_BATCH_RECORD_SIZE': </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396) ~[na:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073) ~[na:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.zeebe.client.impl.ZeebeClientFutureImpl.join(ZeebeClientFutureImpl.java:48) ~[zeebe-client-java-8.0.5.jar:8.0.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	... 9 common frames omitted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Caused by: io.grpc.StatusRuntimeException: UNKNOWN: Command 'CREATE' rejected with code 'EXCEEDED_BATCH_RECORD_SIZE': </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.grpc.Status.asRuntimeException(Status.java:535) ~[grpc-api-1.45.1.jar:1.45.1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:478) ~[grpc-stub-1.45.1.jar:1.45.1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:562) ~[grpc-core-1.45.1.jar:1.45.1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70) ~[grpc-core-1.45.1.jar:1.45.1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:743) ~[grpc-core-1.45.1.jar:1.45.1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:722) ~[grpc-core-1.45.1.jar:1.45.1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37) ~[grpc-core-1.45.1.jar:1.45.1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133) ~[grpc-core-1.45.1.jar:1.45.1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023-06-02 13:53:51.485  INFO 29870 --- [           main] i.c.cloud.gameday.ProcessApplication     : Created process instances with large collection. [order-id: 'ba65b59b-1584-48bb-af05-3724ea15fac9']</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="results">Results<a href="https://zeebe-io.github.io/zeebe-chaos/2023/06/02/Using-Large-Multi-Instance#results" class="hash-link" aria-label="Direct link to Results" title="Direct link to Results">â€‹</a></h3>
<p>As we have seen above we are able now to create much larger multi instances than before, with some drawbacks in performance, which needs to be investigated further.</p>
<p>When reaching a certain limit (maxMessageSize) we get a described rejection by the broker, until we reach the limit of NGINX where the description is not that optimal. Here we can and should improve further.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="found-bugs">Found Bugs<a href="https://zeebe-io.github.io/zeebe-chaos/2023/06/02/Using-Large-Multi-Instance#found-bugs" class="hash-link" aria-label="Direct link to Found Bugs" title="Direct link to Found Bugs">â€‹</a></h2>
<ul>
<li>in a previous test I run into <a href="https://github.com/camunda/camunda/issues/12918" target="_blank" rel="noopener noreferrer">https://github.com/camunda/camunda/issues/12918</a></li>
<li>Related bug regarding the input collection <a href="https://github.com/camunda/camunda/issues/12873" target="_blank" rel="noopener noreferrer">https://github.com/camunda/camunda/issues/12873</a></li>
</ul>]]></content:encoded>
            <category>availability</category>
        </item>
        <item>
            <title><![CDATA[Continuing SST Partitioning toggle]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle</guid>
            <pubDate>Fri, 19 May 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[Today we want to continue with the experiment from last Chaos day, but this time]]></description>
            <content:encoded><![CDATA[<p>Today we want to continue with the experiment from <a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle">last Chaos day</a>, but this time
with a bit more load. This should make sure that we trigger the compaction of RocksDB and cause the SST partitioning to happen, for real.</p>
<p>The reasons stay the same we want to find out whether it would be possible to enable and disable the flag/configuration without issues.</p>
<p><strong>TL;DR;</strong> Today's, experiments succeeded <!-- -->ðŸš€<!-- -->. We were able to show that even with a higher number of process instances (bigger state) we can easily disable and enable the SST partitioning flag without issues. I also got a confirmation from a RocksDb contributor that our observations are correct, and that we can easily toggle this feature without issues.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">â€‹</a></h2>
<p>Similar setup to the <a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle#chaos-experiment">last Chaos day</a>.
Except this time we will enable Operate as well, in order to verify easily whether all instances have been completed.
Other than that we use the standard benchmark configuration, without clients.</p>
<p>The verification of the steady state will consist, of checking the readiness and healthiness of the cluster, via zbchaos and metrics. Furthermore, we will verify that we can access operate and that no instances are running. As defined in chaos engineering principles the process of a chaos experiment looks always the same, Verify the steady state, introduce chaos, and verify the steady state.</p>
<p>In our first experiment, we will enable the SST partitioning.</p>
<p><strong>First chaos action</strong></p>
<ul>
<li>Deploy a process model (which contains a <a href="https://github.com/zeebe-io/zeebe-chaos/blob/main/go-chaos/internal/bpmn/one_task.bpmn" target="_blank" rel="noopener noreferrer">simple model</a>)</li>
<li>Start 1000 process instances (PIs), with a service task</li>
<li>Enable the SST partitioning</li>
<li>Restart the cluster, and await readiness</li>
<li>Complete the jobs (in consequence the PIs)</li>
</ul>
<p>In our second experiment, we will disable the SST partitioning again.</p>
<p><strong>Second chaos action:</strong></p>
<ul>
<li>Start 1000 process instances (PIs), with a service task</li>
<li>Disable the SST partitioning</li>
<li>Restart the cluster, and await readiness</li>
<li>Complete the jobs (in consequence the PIs)</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<blockquote>
<p>When operating a cluster, I can enable and disable the SST partitioning without an impact on executing existing process instances. Existing PIs should still be executable and completable.</p>
</blockquote>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>As linked above I used again our <a href="https://github.com/camunda/camunda/tree/main/benchmarks/setup" target="_blank" rel="noopener noreferrer">benchmark/setup</a> scripts to set up a cluster.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ diff ../default/values.yaml values.yaml </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">40c40</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;   replicas: 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">---</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;   replicas: 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">47c47</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;   replicas: 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">---</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;   replicas: 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">85a86</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;     zeebe.broker.experimental.rocksdb.enableSstPartitioning: "false"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">96a98,100</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;     identity:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;       auth:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;         enabled: false</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">326c330</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;     enabled: false</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">---</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;     enabled: true</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="first-experiment-verify-steady-state">First Experiment: Verify Steady state<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle#first-experiment-verify-steady-state" class="hash-link" aria-label="Direct link to First Experiment: Verify Steady state" title="Direct link to First Experiment: Verify Steady state">â€‹</a></h4>
<p>To verify the readiness and run all actions I used the <a href="https://github.com/zeebe-io/zeebe-chaos/tree/zbchaos-v1.0.0" target="_blank" rel="noopener noreferrer">zbchaos</a> tool.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify readiness</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Looking at the metrics shows that everything looks healthy. The only weird part is the topology panel which seems to be broken.
<img decoding="async" loading="lazy" alt="start" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/start-bfbabb5034107afa1b8f0a19e81c72eb.png" width="1853" height="906" class="img_ev3q"></p>
<p>When requesting the topology via <code>zbchaos</code> we retrieve this:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos topology</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{1 LEADER -1  10  msg false 1 LEADER -1 2 LEADER -1 1684476531915 false false true false false 30 false -1 benchmark 30  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Node      |Partition 1         |Partition 2         |Partition 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1         |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)    |FOLLOWER (HEALTHY)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">0         |LEADER (HEALTHY)    |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2         |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>For now, we assume the dashboard has an issue and continue with the experiment.</p>
<p>We are able to access operate without issues, and see no instances yet.</p>
<p><img decoding="async" loading="lazy" alt="operate" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/operate-c8609205a0832ffb0852c1c14c527e7e.png" width="1901" height="752" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="first-experiment-chaos-action">First Experiment: Chaos Action<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle#first-experiment-chaos-action" class="hash-link" aria-label="Direct link to First Experiment: Chaos Action" title="Direct link to First Experiment: Chaos Action">â€‹</a></h4>
<p>After the verification stage, we start with our chaos action, injecting chaos into the system.
The first step is to deploy the mentioned simple process model:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos deploy process -v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Connecting to zell-chaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Running experiment in self-managed environment.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Port forward to zell-chaos-zeebe-gateway-7bbdf9fd58-dl97j</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Successfully created port forwarding tunnel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Deploy file bpmn/one_task.bpmn (size: 2526 bytes).</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Deployed process model bpmn/one_task.bpmn successful with key 2251799813685249.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Deployed given process model , under key 2251799813685249!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This is then as well visible in operate.</p>
<p><img decoding="async" loading="lazy" alt="operate-process" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/operate-process-c2f4b5eac01d3b5334749518b3ed7eed.png" width="1091" height="503" class="img_ev3q"></p>
<p>As the next step, we will create 1000 process instances of our simple process model, with one service task.
For that, we can <a href="https://github.com/zeebe-io/zeebe-chaos/tree/zell-chaos-create-count-of-instances" target="_blank" rel="noopener noreferrer">use a new functionality</a> of <code>zbchaos</code> I built for this chaos day.</p>
<p>On the first try, I had smaller issues, with timeouts etc.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Send create process instance command, with BPMN process ID 'benchmark' and version '-1' (-1 means latest) [variables: '', awaitResult: false]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[299/999] Created process instance with key 6755399441056339 on partition 3.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">panic: Expected to create 999 process instances, but timed out after 30s created 299 instances.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This is the reason why I had to retry the creations in the end the count is not exactly 1000 :)</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">./dist/zbchaos verify instance-count --instanceCount 697 -v --timeoutInSec 300</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[695/697] Created process instance with key 4503599627372489 on partition 2.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Send create process instance command, with BPMN process ID 'benchmark' and version '-1' (-1 means latest) [variables: '', awaitResult: false]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[696/697] Created process instance with key 6755399441057737 on partition 3.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Send create process instance command, with BPMN process ID 'benchmark' and version '-1' (-1 means latest) [variables: '', awaitResult: false]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[697/697] Created process instance with key 2251799813687255 on partition 1.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img decoding="async" loading="lazy" alt="pi" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/operate-pi-14b1db18f29dfd9c2858179dde92da41.png" width="1905" height="510" class="img_ev3q"></p>
<p>Now we are coming to the interesting part. Enabling SST partitioning.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ diff ../default/values.yaml values.yaml </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">85a86</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;     zeebe.broker.experimental.rocksdb.enableSstPartitioning: "true"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ make update </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm upgrade --namespace zell-chaos zell-chaos zeebe-benchmark/zeebe-benchmark -f values.yaml</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<blockquote>
<p><strong>Note</strong>
Changing the configmap doesn't restart pods! We need to delete all Zeebe pods, to apply the configuration.</p>
</blockquote>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ k delete pod -l app=camunda-platform</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "zell-chaos-zeebe-0" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "zell-chaos-zeebe-1" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "zell-chaos-zeebe-2" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "zell-chaos-zeebe-gateway-7bbdf9fd58-8j7d6" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "zell-chaos-zeebe-gateway-7bbdf9fd58-dl97j" deleted</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify readiness </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Now starting to complete the previously created jobs, we can use again a new feature in <code>zbchaos</code> (<a href="https://github.com/zeebe-io/zeebe-chaos/tree/zell-chaos-create-count-of-instances" target="_blank" rel="noopener noreferrer">which has been added during the chaos day</a>)
Unfortunately, I missed using the verbose flag.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ ./dist/zbchaos verify job-completion --jobCount 1001 --timeoutInSec 1200</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady-state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="first-experiment-verify-steady-state-1">First Experiment: Verify Steady state<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle#first-experiment-verify-steady-state-1" class="hash-link" aria-label="Direct link to First Experiment: Verify Steady state" title="Direct link to First Experiment: Verify Steady state">â€‹</a></h4>
<p>The job completions worked without issues. The metrics are looking good, the topology panel seems to work again as well.</p>
<p><img decoding="async" loading="lazy" alt="complete" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/metrics-complete-6a55f56851581c51bf703a1431d75c3b.png" width="1845" height="894" class="img_ev3q"></p>
<p>In operate we can see that there are no longer any running instances and all of them have been completed.</p>
<p><img decoding="async" loading="lazy" alt="complete-operate" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/operate-complete-d4f703e6d9711b157856fd244294999a.png" width="1894" height="500" class="img_ev3q">
<img decoding="async" loading="lazy" alt="complete-operate2" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/operate-complete2-9a77531ed33a8b2a74c2d2b4bf5ff090.png" width="1887" height="793" class="img_ev3q"></p>
<p>The first part of the experiment worked as expected <!-- -->âœ…</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="second-experiment-chaos-action">Second Experiment: Chaos Action<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle#second-experiment-chaos-action" class="hash-link" aria-label="Direct link to Second Experiment: Chaos Action" title="Direct link to Second Experiment: Chaos Action">â€‹</a></h4>
<p>We are skipping the verification step, due to previous verification, we directly start with creating 1000 process instances.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ ./dist/zbchaos verify instance-count --instanceCount 1000 -v --timeoutInSec 300</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Send create process instance command, with BPMN process ID 'benchmark' and version '-1' (-1 means latest) [variables: '', awaitResult: false]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[1000/1000] Successful command sent, got response with key 2251799813690599 on partition 1.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady-state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img decoding="async" loading="lazy" alt="second" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/second-exp-e3fd7780bec7f168375839276a153572.png" width="1890" height="892" class="img_ev3q"></p>
<p>Disable the SST partitioning flag and update the cluster.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ make update </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ k delete pod -l app=camunda-platform</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify readiness</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Complete all jobs:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ ./dist/zbchaos verify job-completion --jobCount 1000 --timeoutInSec 1200 -v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[999/1000] Successful command sent, got response with key 6755399441061073 on partition 3.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Send job activate command, with job type 'benchmark-task'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[1000/1000] Successful command sent, got response with key 2251799813690604 on partition 1.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady-state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="second-experiment-verify-steady-state">Second Experiment: Verify Steady state<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle#second-experiment-verify-steady-state" class="hash-link" aria-label="Direct link to Second Experiment: Verify Steady state" title="Direct link to Second Experiment: Verify Steady state">â€‹</a></h4>
<p>Again the experiment succeeded, we were able to show that even with a higher number of process instances we can easily disable and enable the SST partitioning flag.</p>
<p><img decoding="async" loading="lazy" alt="verify" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/second-exp-verify-027ddb4d82b084f1da4fb7cf0804cd31.png" width="1840" height="892" class="img_ev3q">
<img decoding="async" loading="lazy" alt="op-complete" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/second-exp-operate-complete-fb1b93e473c3b44f74af441a0758c6e0.png" width="1087" height="614" class="img_ev3q"></p>
<p>In the snapshots at we can see that some more files are used.</p>
<p><img decoding="async" loading="lazy" alt="snap" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/second-exp-snap-619bf47a82dce280aed6013c81dde883.png" width="878" height="850" class="img_ev3q"></p>
<p>But in RocksDb metrics we see no real compaction going on, which is why we will retry the same with a higher amount of data.</p>
<p><img decoding="async" loading="lazy" alt="rocks" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/second-exp-rocks-ad699b1447a827a6cadc97e38b7e4536.png" width="884" height="422" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="sst-partitioning-and-compaction">SST Partitioning and compaction<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle#sst-partitioning-and-compaction" class="hash-link" aria-label="Direct link to SST Partitioning and compaction" title="Direct link to SST Partitioning and compaction">â€‹</a></h4>
<p>I tried to run the experiment again but with more data (~11K instances).</p>
<p>Even when the metrics don't show the compaction, I was able to see in the RocksDB that compacting is happening.</p>
<p>Around 11:56 between different loads</p>
<p><img decoding="async" loading="lazy" alt="thirdrun" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/thirdrun-d169e0524892c8521172f5d181e3c59d.png" width="1849" height="891" class="img_ev3q"></p>
<p>We see in the metrics of RocksDB that nothing</p>
<p><img decoding="async" loading="lazy" alt="rocks" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/compacting-16d643497e24f39e3aef93cabb91a0b7.png" width="1860" height="451" class="img_ev3q"></p>
<p>But when checking the RocksDB logs</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ cat data/raft-partition/partitions/1/runtime/LOG.old.1684493206724692 </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/19-09:56:40.652111 140580419004160  Options.sst_partitioner_factory: SstPartitionerFixedPrefixFactory</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/19-09:56:41.354244 140579153618688 (Original Log Time 2023/05/19-09:56:41.354149) EVENT_LOG_v1 {"time_micros": 1684490201354123, "job": 2, "event": "compaction_finished", "compaction_time_micros": 374078, "compaction_time_cpu_micros": 72361, "output_level": 3, "num_output_files": 14, "total_output_size": 6283132, "num_input_records": 69787, "num_output_records": 39118, "num_subcompactions": 1, "output_compression": "NoCompression", "num_single_delete_mismatches": 0, "num_single_delete_fallthrough": 0, "lsm_state": [0, 0, 0, 14]}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/19-09:56:41.354763 140579153618688 [le/delete_scheduler.cc:77] Deleted file /usr/local/zeebe/data/raft-partition/partitions/1/runtime/000045.sst immediately, rate_bytes_per_sec 0, total_trash_size 0 max_trash_db_ratio 0.250000</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/19-09:56:41.354786 140579153618688 EVENT_LOG_v1 {"time_micros": 1684490201354782, "job": 2, "event": "table_file_deletion", "file_number": 45}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/19-09:56:41.355217 140579153618688 [le/delete_scheduler.cc:77] Deleted file /usr/local/zeebe/data/raft-partition/partitions/1/runtime/000044.sst immediately, rate_bytes_per_sec 0, total_trash_size 0 max_trash_db_ratio 0.250000</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/19-09:56:41.355247 140579153618688 EVENT_LOG_v1 {"time_micros": 1684490201355243, "job": 2, "event": "table_file_deletion", "file_number": 44}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/19-09:56:41.355765 140579153618688 [le/delete_scheduler.cc:77] Deleted file /usr/local/zeebe/data/raft-partition/partitions/1/runtime/000043.sst immediately, rate_bytes_per_sec 0, total_trash_size 0 max_trash_db_ratio 0.250000</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We see several lines which indicate the compaction.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">â€‹</a></h2>
<p>We have seen that even when we toggle the SST partitioning, we are able to make progress and our stored data is not impacted. This is a great out come since it means we can easily enable such configuration on existing clusters and gains the performance benefits for larger states as we have seen in previous benchmarks.</p>
<p>I have posted a question related to this topic in the <a href="https://groups.google.com/g/rocksdb/c/Ys-yZIznZwU" target="_blank" rel="noopener noreferrer">RocksDb google group</a> and I got a private answer which contains the following:</p>
<blockquote>
<p>Partitioner is just a hinter when compaction should split the file. Default compaction is also splitting by file size. So it has no functional effect and you can change configuration anytime.</p>
<p>Partitioner does not need to be simple prefix only, but one can use more complicated strategy.</p>
</blockquote>
<p>This confirms our observation and makes it much more trustworthy.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="found-bugs">Found Bugs<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle#found-bugs" class="hash-link" aria-label="Direct link to Found Bugs" title="Direct link to Found Bugs">â€‹</a></h2>
<ul>
<li>Grafana Topology Panel seems to be buggy from time to time</li>
<li>RocksDB compaction panel seems to show no data (might be related to a short time frame)</li>
</ul>]]></content:encoded>
            <category>availability</category>
            <category>data</category>
        </item>
        <item>
            <title><![CDATA[SST Partitioning toggle]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle</guid>
            <pubDate>Mon, 15 May 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[On this chaos day I wanted to experiment with a new experimental feature we have released recently. The enablement of the partitioning of the SST files in RocksDB. This is an experimental feature from RocksDb, which we made available now for our users as well, since we have seen great benefits in performance, especially with larger runtime data.]]></description>
            <content:encoded><![CDATA[<p>On this chaos day I wanted to experiment with a new experimental feature we have released recently. The <a href="https://github.com/camunda/camunda/pull/12483" target="_blank" rel="noopener noreferrer">enablement of the partitioning of the SST files in RocksDB</a>. This is an experimental feature from RocksDb, which we made available now for our users as well, since we have seen great benefits in performance, especially with larger runtime data.</p>
<p>I wanted to experiment a bit with the SST partitioning and find out whether it would be possible to enable and disable the flag/configuration without issues.</p>
<p><strong>TL;DR;</strong> The first experiment was successful, it looks like we can enable and disable the partitioning without impacting the execution of one existing PI. We need to experiment a bit more with larger data sets to force RocksDB compaction, to be fully sure.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">â€‹</a></h2>
<p>For our chaos experiment we set up again our <a href="https://github.com/camunda/camunda/tree/main/benchmarks/setup" target="_blank" rel="noopener noreferrer">normal benchmark cluster</a>, this time without any clients (no workers/starters).</p>
<p>Setting all client replicas to zero:</p>
<div class="language-diff codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-diff codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ diff default/values.yaml zell-chaos/values.yaml </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">40c40</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;   replicas: 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">---</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;   replicas: 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">47c47</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;   replicas: 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">---</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;   replicas: 0</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The experiment we want to do on this chaos day will look like the following:</p>
<p><strong>First part:</strong></p>
<ul>
<li>Verify steady state:<!-- -->
<ul>
<li>verify the readiness of the cluster</li>
<li>deploy a process model (which contains a <a href="https://github.com/zeebe-io/zeebe-chaos/blob/main/go-chaos/internal/bpmn/one_task.bpmn" target="_blank" rel="noopener noreferrer">simple model</a>)</li>
</ul>
</li>
<li>Chaos Action:<!-- -->
<ul>
<li>start a process instance (PI), with a service task</li>
<li>enable the SST partitioning</li>
<li>restart the cluster</li>
<li>verify the readiness</li>
<li>verify that job is activatable</li>
<li>complete the job (in consequence the PI)</li>
</ul>
</li>
</ul>
<p><strong>Second part:</strong></p>
<ul>
<li>Chaos Action:<!-- -->
<ul>
<li>start a process instance (PI), with a service task</li>
<li>disable the SST partitioning</li>
<li>restart the cluster</li>
<li>verify the readiness</li>
<li>verify that job is activatable</li>
<li>complete the job (in consequence the PI)</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>When operating a cluster, I can enable the SST partitioning without an impact on executing existing process instances. Existing PIs should still be executable and completable.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>As linked above I used again our <a href="https://github.com/camunda/camunda/tree/main/benchmarks/setup" target="_blank" rel="noopener noreferrer">benchmark/setup</a> scripts to set up a cluster.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="first-part-verify-steady-state">First Part: Verify Steady state<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle#first-part-verify-steady-state" class="hash-link" aria-label="Direct link to First Part: Verify Steady state" title="Direct link to First Part: Verify Steady state">â€‹</a></h4>
<p>To verify the readiness and run all actions I used the <a href="https://github.com/zeebe-io/zeebe-chaos/tree/zbchaos-v1.0.0" target="_blank" rel="noopener noreferrer">zbchaos</a> tool.</p>
<p>Verifying readiness is fairly easy with zbchaos.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify readiness -v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Connecting to zell-chaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Running experiment in self-managed environment.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Pod zell-chaos-zeebe-0 is in phase Pending, and not ready. Wait for some seconds.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[...]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Pod zell-chaos-zeebe-0 is in phase Running, and not ready. Wait for some seconds.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Pod zell-chaos-zeebe-0 is in phase Running, and not ready. Wait for some seconds.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We then deploy the mentioned simple process model:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos deploy process -v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Connecting to zell-chaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Running experiment in self-managed environment.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Port forward to zell-chaos-zeebe-gateway-7bbdf9fd58-dl97j</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Successfully created port forwarding tunnel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Deploy file bpmn/one_task.bpmn (size: 2526 bytes).</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Deployed process model bpmn/one_task.bpmn successful with key 2251799813685249.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Deployed given process model , under key 2251799813685249!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="first-part-chaos-action">First Part: Chaos Action<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle#first-part-chaos-action" class="hash-link" aria-label="Direct link to First Part: Chaos Action" title="Direct link to First Part: Chaos Action">â€‹</a></h4>
<p>As the first step in the chaos action we create a process instance.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify instance-creation -v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Connecting to zell-chaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Running experiment in self-managed environment.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Port forward to zell-chaos-zeebe-gateway-7bbdf9fd58-dl97j</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Successfully created port forwarding tunnel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Send create process instance command, with BPMN process ID 'benchmark' and version '-1' (-1 means latest) [variables: '', awaitResult: false]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Created process instance with key 2251799813685251 on partition 1, required partition 1.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady-state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Next, we enable the SST partitioning in our broker configuration, we can do this in the <code>values.yaml</code> file and run a <code>helm update</code>.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ diff ../default/values.yaml values.yaml </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">85a86</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;     zeebe.broker.experimental.rocksdb.enableSstPartitioning: "true"</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ make update</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm upgrade --namespace zell-chaos zell-chaos zeebe-benchmark/zeebe-benchmark -f values.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Release "zell-chaos" has been upgraded. Happy Helming!</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME: zell-chaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">LAST DEPLOYED: Mon May 15 15:54:24 2023</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAMESPACE: zell-chaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">STATUS: deployed</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">REVISION: 2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NOTES:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Zeebe Benchmark</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Installed Zeebe cluster with:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * 3 Brokers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * 2 Gateways</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The benchmark is running with:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * Starter replicas=0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * Worker replicas=0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * Publisher replicas=0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * Timer replicas=0</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<blockquote>
<p><strong>Note</strong>
Changing the configmap doesn't restart pods! We need to delete all Zeebe pods, to apply the configuration.</p>
</blockquote>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ k delete pod -l app=camunda-platform</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "zell-chaos-zeebe-0" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "zell-chaos-zeebe-1" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "zell-chaos-zeebe-2" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "zell-chaos-zeebe-gateway-7bbdf9fd58-8j7d6" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "zell-chaos-zeebe-gateway-7bbdf9fd58-dl97j" deleted</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Next we can use <code>zbchaos verify readiness</code> again to await the readiness of the cluster.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Taking a look at the logs of the broker we can also see that the broker configuration was correctly set:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">   \"disableWal\" : true,\n      \"enableSstPartitioning\" : true\n    }</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<blockquote>
<p><strong>Note</strong>
Right now zbchaos can't complete an job (missing feature). We use zbctl for that, we need to port-forward to the gateway in order to send the commands.</p>
</blockquote>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ k port-forward svc/zell-chaos-zeebe-gateway 26500</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Forwarding from 127.0.0.1:26500 -&gt; 26500</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Forwarding from [::1]:26500 -&gt; 26500</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Activating the right job.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbctl --insecure activate jobs benchmark-task</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "jobs":  [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "key":  "2251799813685256",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "type":  "benchmark-task",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "processInstanceKey":  "2251799813685251",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "bpmnProcessId":  "benchmark",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "processDefinitionVersion":  1,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "processDefinitionKey":  "2251799813685249",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "elementId":  "task",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "elementInstanceKey":  "2251799813685255",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "customHeaders":  "{}",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "worker":  "zbctl",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "retries":  3,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "deadline":  "1684173544716",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "variables":  "{}"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Completing the job and the PI.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbctl complete job 2251799813685256 --insecure</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Completed job with key '2251799813685256' and variables '{}'</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="second-part">Second Part:<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle#second-part" class="hash-link" aria-label="Direct link to Second Part:" title="Direct link to Second Part:">â€‹</a></h4>
<p>Create again a process instance <code>$ zbchaos verify instance-creation</code></p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Created process instance with key 2251799813685263 on partition 1, required partition 1.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady-state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Disabling the configuration again, and running the update.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ diff default/values.yaml zell-chaos/values.yaml </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">85a86</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;     zeebe.broker.experimental.rocksdb.enableSstPartitioning: "false"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ make update </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm upgrade --namespace zell-chaos zell-chaos zeebe-benchmark/zeebe-benchmark -f values.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Release "zell-chaos" has been upgraded. Happy Helming!</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME: zell-chaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">LAST DEPLOYED: Mon May 15 20:00:53 2023</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ k delete pod -l app=camunda-platform</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify readiness</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Again the job completion worked without problems (skipping here the port-forward and activate output)</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbctl complete job 2251799813685268 --insecure</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Completed job with key '2251799813685268' and variables '{}'</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>âœ…<!-- --> The experiment was successful.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="further-investigation">Further investigation<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle#further-investigation" class="hash-link" aria-label="Direct link to Further investigation" title="Direct link to Further investigation">â€‹</a></h4>
<p><img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/general-after2-e0b4149303fb10808ec4d1e9215ed7af.png" width="1848" height="701" class="img_ev3q"></p>
<p>When running the experiment I also observed the metrics of the cluster and was not able to see any differences in the snapshot file counts, which we would expect on the SST partitioning (there should be more files).</p>
<p>Before the experiment:
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/snapshot-before-2140893bacefcc15a0d450c89274d8e2.png" width="932" height="814" class="img_ev3q"></p>
<p>After the experiment, we still see that for each partition we have around ~6 files.
<img decoding="async" loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/snapshot-after2-ca6970a41ba78ee802c74de8b18c195d.png" width="938" height="818" class="img_ev3q"></p>
<p>In order to make sure whether the options have been applied correctly I investigated the RocksDB log files and option files.</p>
<p>In the current LOG file, we can see the current options printed, which is indeed the disabled partitioner. Since this is the default as well it is not a proof yet.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/15-18:01:46.223234 139711509092096 [/column_family.cc:621] --------------- Options for column family [default]:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/15-18:01:46.223237 139711509092096               Options.comparator: leveldb.BytewiseComparator</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/15-18:01:46.223239 139711509092096           Options.merge_operator: None</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/15-18:01:46.223241 139711509092096        Options.compaction_filter: None</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/15-18:01:46.223242 139711509092096        Options.compaction_filter_factory: None</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/15-18:01:46.223244 139711509092096  Options.sst_partitioner_factory: None</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>What we can see in the runtime folder of the partition is that there exist two Options files, an older one <code>OPTIONS-000014</code>, and a newer one <code>OPTIONS-000023</code>.</p>
<p>The older one contains the expected configuration for the SST partitioning:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ cat OPTIONS-000014 </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[CFOptions "default"]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  sst_partitioner_factory={id=SstPartitionerFixedPrefixFactory;length=8;}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The most recent options file has the configuration set to null.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ cat OPTIONS-000023</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[CFOptions "default"]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sst_partitioner_factory=nullptr</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We can see that the current snapshot only copied the most recent options file:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ ll ../snapshots/188-4-230-244</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">total 56</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">drwxr-xr-x 2 root root 4096 May 15 18:13 ./</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">drwxr-xr-x 3 root root 4096 May 15 18:13 ../</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-rw-r--r-- 2 root root 7015 May 15 18:01 OPTIONS-000023</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-rw-r--r-- 1 root root   92 May 15 18:13 zeebe.metadata</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">â€‹</a></h3>
<p>We were able to toggle the SST partitioning flag without problems back and forth. We were able to make still progress on an existing process instance, which we wanted to prove.</p>
<p>Nevertheless, we need to prove this once more for multiple process instances (100-1000 PIs), which cause or forces compaction of the SST files. Right now I'm not 100% convinced whether this experiment was enough, but it was a good first step.</p>]]></content:encoded>
            <category>availability</category>
            <category>data</category>
        </item>
        <item>
            <title><![CDATA[Gateway Termination]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2023/04/06/gateway-termination</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2023/04/06/gateway-termination</guid>
            <pubDate>Thu, 06 Apr 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[In today's chaos day, we wanted to experiment with the gateway and resiliency of workers.]]></description>
            <content:encoded><![CDATA[<p>In today's chaos day, we wanted to experiment with the gateway and resiliency of workers.</p>
<p>We have seen in recent weeks some issues within our benchmarks when gateways have been restarted,
see <a href="https://github.com/camunda/camunda/issues/11975" target="_blank" rel="noopener noreferrer">zeebe#11975</a>.</p>
<p>We did a similar experiment <a href="https://zeebe-io.github.io/zeebe-chaos/2022/02/15/Standalone-Gateway-in-CCSaaS">in the past</a>,
today we want to focus on self-managed (<a href="https://helm.camunda.io/" target="_blank" rel="noopener noreferrer">benchmarks with our helm charts</a>).
Ideally, we can automate this as well soon.</p>
<p>Today <a href="https://github.com/npepinpe" target="_blank" rel="noopener noreferrer">Nicolas</a> joined me on the chaos day <!-- -->ðŸŽ‰</p>
<p><strong>TL;DR;</strong> We were able to show that the workers (clients) can reconnect after a gateway is shutdown <!-- -->âœ…<!-- -->
Furthermore, we have discovered a potential performance issue on lower load, which impacts process execution latency (<a href="https://github.com/camunda/camunda/issues/12311" target="_blank" rel="noopener noreferrer">zeebe#12311</a>).</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2023/04/06/gateway-termination#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">â€‹</a></h2>
<p>We will use our <a href="https://github.com/zeebe-io/benchmark-helm" target="_blank" rel="noopener noreferrer">Zeebe benchmark helm charts</a> to set up the test cluster, and
our helper scripts <a href="https://github.com/camunda/camunda/tree/main/benchmarks/setup" target="_blank" rel="noopener noreferrer">here</a>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="setup">Setup:<a href="https://zeebe-io.github.io/zeebe-chaos/2023/04/06/gateway-termination#setup" class="hash-link" aria-label="Direct link to Setup:" title="Direct link to Setup:">â€‹</a></h3>
<p>We will run with the default benchmark configuration, which means:</p>
<ul>
<li>three brokers</li>
<li>three partitions</li>
<li>replication count three</li>
<li>two gateways</li>
</ul>
<p>We will run the benchmark with a low load, 10 process instances per second created and completed. For that,
we deploy one starter and worker. This reduces the blast radius and allows us to observe more easily how the workers
behave when a gateway is restarted.</p>
<p>During the experiment, we will use our <a href="https://github.com/camunda/camunda/tree/main/monitor/grafana" target="_blank" rel="noopener noreferrer">grafana dashboard</a> to
observe to which gateway the worker will connect and which gateway we need to stop/restart.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">LAST DEPLOYED: Thu Apr  6 10:21:27 2023</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAMESPACE: zell-chaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">STATUS: deployed</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">REVISION: 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NOTES:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Zeebe Benchmark</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Installed Zeebe cluster with:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * 3 Brokers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * 2 Gateways</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The benchmark is running with:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * Starter replicas=1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * Worker replicas=1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * Publisher replicas=0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * Timer replicas=0</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/04/06/gateway-termination#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>When we terminate a gateway to which the worker has connected, <strong>we expect</strong> that the worker connects to the different
replica and starts completing jobs again.</p>
<p>The performance drop is expected to be not significant, or at least should recover fast.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/04/06/gateway-termination#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>We will run the experiment in two ways, first via terminating the gateway (using <a href="https://github.com/zeebe-io/zeebe-chaos/releases/tag/zbchaos-v1.0.0" target="_blank" rel="noopener noreferrer">zbchaos</a>)
and later via scaling down the gateway deployment to one replica.</p>
<p>We want to verify whether this makes any difference, since terminating will cause Kubernetes to recreate immediately the pod.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="termination">Termination<a href="https://zeebe-io.github.io/zeebe-chaos/2023/04/06/gateway-termination#termination" class="hash-link" aria-label="Direct link to Termination" title="Direct link to Termination">â€‹</a></h4>
<p>Before we start the experiment we check our current deployed state:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ kgpo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                        READY   STATUS      RESTARTS   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">camunda-platform-curator-28012860-zk72q     0/1     Completed   0          7m24s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-0                      1/1     Running     0          45m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-1                      1/1     Running     0          45m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-2                      1/1     Running     0          45m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">leader-balancer-28012860-7cwmd              0/1     Completed   0          7m25s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">starter-cb69c447f-l2zbh                     1/1     Running     0          45m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">worker-cb7f7c469-qvqqv                      1/1     Running     0          45m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-0                          1/1     Running     0          45m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-1                          1/1     Running     0          45m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-2                          1/1     Running     0          45m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-7bbdf9fd58-vs28f   1/1     Running     0          45m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-7bbdf9fd58-xc6d9   1/1     Running     0          45m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Via our Grafana dashboard (and the gRPC metrics) we are able to track to which gateway the worker connects to:</p>
<p><img decoding="async" loading="lazy" alt="grpc" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/grpc-13224311ab5e142b1d17c5bfeb3369d7.png" width="1545" height="840" class="img_ev3q"></p>
<p>It is <code>zell-chaos-zeebe-gateway-7bbdf9fd58-vs28f</code>.
Via zbchaos we can easily terminate the gateway (it will always take the first in the pod list).</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos terminate gateway </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{1 LEADER -1  10  msg false 1 LEADER -1 2 LEADER -1 1680772377704 false false true false false 30 false -1 benchmark 30  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Terminated zell-chaos-zeebe-gateway-7bbdf9fd58-vs28f</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>After terminating we can see that a new gateway pod has started.</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ kgpo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                        READY   STATUS      RESTARTS   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">camunda-platform-curator-28012860-zk72q     0/1     Completed   0          13m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-0                      1/1     Running     0          52m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-1                      1/1     Running     0          52m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-2                      1/1     Running     0          52m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">leader-balancer-28012860-7cwmd              0/1     Completed   0          13m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">starter-cb69c447f-l2zbh                     1/1     Running     0          52m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">worker-cb7f7c469-qvqqv                      1/1     Running     0          52m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-0                          1/1     Running     0          52m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-1                          1/1     Running     0          52m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-2                          1/1     Running     0          52m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-7bbdf9fd58-pkj48   1/1     Running     0          33s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-7bbdf9fd58-xc6d9   1/1     Running     0          52m</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>In the metrics, we can see that due to the restart, the throughput slightly dropped, but recovered pretty fast. The worker
was able to connect to the different gateway. <!-- -->âœ…</p>
<p><img decoding="async" loading="lazy" alt="restart" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/restart-fba3c5902c9b5523ca1f2fe9ba45def5.png" width="1848" height="883" class="img_ev3q"></p>
<blockquote>
<p><strong>Note</strong></p>
<p><em>In the panel <code>Pod Restarts</code> on the top right, we don't see any restarts and that is something
we should always be aware of that the <em>metrics are just samples of data</em>. If a pod, like a gateway, restarts fast enough
and the metric collect interval is higher (per default we have ~30 s (?)) then you might not see a change.</em></p>
</blockquote>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="scale-down">Scale down<a href="https://zeebe-io.github.io/zeebe-chaos/2023/04/06/gateway-termination#scale-down" class="hash-link" aria-label="Direct link to Scale down" title="Direct link to Scale down">â€‹</a></h4>
<p>As described earlier we wanted to verify whether it makes a difference if we scale down the replica instead of terminating/restarting
it, which causes restarting a new pod (which might get the same IP).</p>
<p>For scaling down Nicolas found this annotation: <code>controller.kubernetes.io/pod-deletion-cost</code></p>
<p><a href="https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/#pod-deletion-cost" target="_blank" rel="noopener noreferrer">That annotation allows giving hints to the schedule which pod to turn-down, because another pod might have a higher cost
to be deleted (this is of course best-effort).</a></p>
<p>This means we edit one pod and gave the following annotation:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">annotations</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">controller.kubernetes.io/pod-deletion-cost</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">  </span><span class="token string" style="color:#e3116c">"-1"</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We have similarly chosen the pod as we have seen above, based on the gRPC metrics.</p>
<p>Checking the running pods and editing the correct gateway:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[cqjawa 2023-04-06-gateway-termination/ cluster: zeebe-cluster ns:zell-chaos]$ kgpo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                        READY   STATUS      RESTARTS   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">camunda-platform-curator-28012875-tntdv     0/1     Completed   0          6m26s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-0                      1/1     Running     0          59m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-1                      1/1     Running     0          59m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-2                      1/1     Running     0          59m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">leader-balancer-28012875-sctwq              0/1     Completed   0          6m26s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">starter-cb69c447f-l2zbh                     1/1     Running     0          59m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">worker-cb7f7c469-qvqqv                      1/1     Running     0          59m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-0                          1/1     Running     0          59m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-1                          1/1     Running     0          59m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-2                          1/1     Running     0          59m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-7bbdf9fd58-pkj48   1/1     Running     0          8m29s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-7bbdf9fd58-xc6d9   1/1     Running     0          59m</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>When I did the following I was wondering why it didn't scale down the deployment, one pod was recreated.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[cqjawa 2023-04-06-gateway-termination/ cluster: zeebe-cluster ns:zell-chaos]$ k scale replicaset zell-chaos-zeebe-gateway-7bbdf9fd58 --replicas=1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Warning: spec.template.spec.containers[0].env[16].name: duplicate name "ZEEBE_LOG_LEVEL"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">replicaset.apps/zell-chaos-zeebe-gateway-7bbdf9fd58 scaled</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[cqjawa 2023-04-06-gateway-termination/ cluster: zeebe-cluster ns:zell-chaos]$ kgpo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                        READY   STATUS            RESTARTS   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">camunda-platform-curator-28012875-tntdv     0/1     Completed         0          6m53s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-0                      1/1     Running           0          60m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-1                      1/1     Running           0          60m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-2                      1/1     Running           0          60m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">leader-balancer-28012875-sctwq              0/1     Completed         0          6m53s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">starter-cb69c447f-l2zbh                     1/1     Running           0          60m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">worker-cb7f7c469-qvqqv                      1/1     Running           0          60m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-0                          1/1     Running           0          60m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-1                          1/1     Running           0          60m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-2                          1/1     Running           0          60m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-7bbdf9fd58-2v6gs   0/1     PodInitializing   0          7s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-7bbdf9fd58-pkj48   1/1     Running           0          8m56s</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<blockquote>
<p><strong>Note:</strong></p>
<p>During the experiment I learned that when you have deployed a <a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/" target="_blank" rel="noopener noreferrer">deployment</a>, you need to scale down the deployment, not the <a href="https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/" target="_blank" rel="noopener noreferrer">ReplicaSet</a>.
Otherwise your Kubernetes deployment controller will recreate the ReplicaSet in the next reconcile loop, which means you
will have again the same replicas as defined in the deployment.</p>
</blockquote>
<p>So correct is to scale down the deployment (!), if you ever wonder.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[cqjawa 2023-04-06-gateway-termination/ cluster: zeebe-cluster ns:zell-chaos]$ k edit pod zell-chaos-zeebe-gateway-7bbdf9fd58-pkj48</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod/zell-chaos-zeebe-gateway-7bbdf9fd58-pkj48 edited</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[cqjawa 2023-04-06-gateway-termination/ cluster: zeebe-cluster ns:zell-chaos]$ kgpo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                        READY   STATUS      RESTARTS   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">camunda-platform-curator-28012875-tntdv     0/1     Completed   0          10m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-0                      1/1     Running     0          63m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-1                      1/1     Running     0          63m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-2                      1/1     Running     0          63m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">leader-balancer-28012875-sctwq              0/1     Completed   0          10m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">starter-cb69c447f-l2zbh                     1/1     Running     0          63m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">worker-cb7f7c469-qvqqv                      1/1     Running     0          63m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-0                          1/1     Running     0          63m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-1                          1/1     Running     0          63m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-2                          1/1     Running     0          63m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-7bbdf9fd58-2v6gs   1/1     Running     0          3m40s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-7bbdf9fd58-pkj48   1/1     Running     0          12m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[cqjawa 2023-04-06-gateway-termination/ cluster: zeebe-cluster ns:zell-chaos]$ k scale deployment zell-chaos-zeebe-gateway --replicas=1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Warning: spec.template.spec.containers[0].env[16].name: duplicate name "ZEEBE_LOG_LEVEL"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">deployment.apps/zell-chaos-zeebe-gateway scaled</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[cqjawa 2023-04-06-gateway-termination/ cluster: zeebe-cluster ns:zell-chaos]$ kgpo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                        READY   STATUS      RESTARTS   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">camunda-platform-curator-28012875-tntdv     0/1     Completed   0          10m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-0                      1/1     Running     0          64m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-1                      1/1     Running     0          64m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-2                      1/1     Running     0          64m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">leader-balancer-28012875-sctwq              0/1     Completed   0          10m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">starter-cb69c447f-l2zbh                     1/1     Running     0          64m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">worker-cb7f7c469-qvqqv                      1/1     Running     0          64m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-0                          1/1     Running     0          64m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-1                          1/1     Running     0          64m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-2                          1/1     Running     0          64m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-7bbdf9fd58-2v6gs   1/1     Running     0          4m</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>With that, we have only one gateway pod left, and all traffic goes to that gateway. Based on the metrics
we can see that the workers recovered everytime when we restarted/terminated or scaled down.</p>
<p><img decoding="async" loading="lazy" alt="activate" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/activate-bd04e48187522a661ce740667de5dae7.png" width="917" height="414" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="general" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/general-eccb10353f089541f74a3f82593a836d.png" width="1845" height="903" class="img_ev3q"></p>
<p>The experiment itself succeeded <!-- -->ðŸ’ª<!-- --> :white_check_marks:</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="found-bugs">Found Bugs<a href="https://zeebe-io.github.io/zeebe-chaos/2023/04/06/gateway-termination#found-bugs" class="hash-link" aria-label="Direct link to Found Bugs" title="Direct link to Found Bugs">â€‹</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="zbchaos-print-verbose-logs">Zbchaos print verbose logs<a href="https://zeebe-io.github.io/zeebe-chaos/2023/04/06/gateway-termination#zbchaos-print-verbose-logs" class="hash-link" aria-label="Direct link to Zbchaos print verbose logs" title="Direct link to Zbchaos print verbose logs">â€‹</a></h3>
<p>I realized that we still have <a href="https://github.com/zeebe-io/zeebe-chaos/issues/323" target="_blank" rel="noopener noreferrer">the issue with zbchaos</a> which is printing verbose logs:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos terminate gateway </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{1 LEADER -1  10  msg false 1 LEADER -1 2 LEADER -1 1680772377704 false false true false false 30 false -1 benchmark 30  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Terminated zell-chaos-zeebe-gateway-7bbdf9fd58-vs28f</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="segment-creation-impact">Segment creation impact<a href="https://zeebe-io.github.io/zeebe-chaos/2023/04/06/gateway-termination#segment-creation-impact" class="hash-link" aria-label="Direct link to Segment creation impact" title="Direct link to Segment creation impact">â€‹</a></h3>
<p>During checking the metrics together with Nicolas, we realized that even on low load (10 PI/s) we have high spikes
in our processing execution latency.</p>
<p><img decoding="async" loading="lazy" alt="latency" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/latency-9fda0fdb0283c3af3831aef3813997e6.png" width="1852" height="822" class="img_ev3q"></p>
<p>The spikes are going up to 1-1.5 seconds, while the avg is at 0.06s. This happens every 6 minutes.</p>
<p>We can see that the commit latency is as well at the same time high, which might be an issue because of the high IO.</p>
<p><img decoding="async" loading="lazy" alt="commit" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/commit-541f81ca663ae80835fa6ef8357d94a7.png" width="1841" height="250" class="img_ev3q"></p>
<p>We first expected that to be related to snapshotting, but snapshots happen much more often.</p>
<p><img decoding="async" loading="lazy" alt="snapshot" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/snapshot-count-1b18a9a53eeaf2d45ab3a6f109b5d981.png" width="923" height="276" class="img_ev3q"></p>
<p>Interestingly is that it seems to be related to our segment creation (again), even if we have
async segment creation in our journal built recently. We need to investigate this further within <a href="https://github.com/camunda/camunda/issues/12311" target="_blank" rel="noopener noreferrer">zeebe#12311</a>.</p>
<p><img decoding="async" loading="lazy" alt="segment" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/segment-176d6a262460c14aa4dce22bdce1dab2.png" width="1850" height="402" class="img_ev3q"></p>]]></content:encoded>
            <category>availability</category>
            <category>resiliency</category>
        </item>
        <item>
            <title><![CDATA[Recursive call activity]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2023/02/23/Recursive-call-activity</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2023/02/23/Recursive-call-activity</guid>
            <pubDate>Thu, 23 Feb 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[Long time no see. Happy to do my first chaos day this year. In the last week have implemented interesting features, which I would like to experiment with.]]></description>
            <content:encoded><![CDATA[<p>Long time no see. Happy to do my first chaos day this year. In the last week have implemented interesting features, which I would like to experiment with.
<a href="https://github.com/camunda/camunda/issues/11416" target="_blank" rel="noopener noreferrer">Batch processing</a> was one of them.</p>
<p><strong>TL;DR;</strong> Chaos experiment failed. <!-- -->ðŸ’¥<!-- --> Batch processing doesn't seem to respect the configured limit, which causes issues with processing and influences the health of the system. We found a bug <!-- -->ðŸ’ª</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2023/02/23/Recursive-call-activity#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">â€‹</a></h2>
<p>In today's chaos experiment, we want to experiment with <a href="https://github.com/camunda/camunda/issues/11416" target="_blank" rel="noopener noreferrer">Batch processing</a> and how it can handle error conditions, like deploying an endless recursive process model.</p>
<p><img decoding="async" loading="lazy" alt="recursive process" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/call-8d5375c7dcbd4d2e36d20706dd178d3d.png" width="903" height="276" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/02/23/Recursive-call-activity#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">â€‹</a></h3>
<p>When we deploy such a process model and create an instance of it, we expect that the execution is done endlessly. In normal process models with batch processing, the execution of a process instance is done until a wait state is reached. In this process model, there exists no wait state. To handle such cases, we have implemented a batch limit, which can be configured via <a href="https://github.com/camunda/camunda/blob/main/dist/src/main/config/broker.standalone.yaml.template#L695" target="_blank" rel="noopener noreferrer">maxCommandsInBatch</a>. This configuration is by default set to 100 commands. Meaning the stream processor will process 100 commands until it stops, to make room for other things.</p>
<p>We expect that our limit handling steps in during the execution and we can execute also other instances or, cancel the problematic process instance. Furthermore, we expect to stay healthy, we should be able to update our health check continuously.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/02/23/Recursive-call-activity#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">â€‹</a></h3>
<p>Before we can start with our experiment we need to start our benchmark Zeebe cluster. This has become easier now since I have written the last post. Previously we had to use the scripts and Makefile in the <a href="https://github.com/camunda/camunda/tree/main/benchmarks/setup" target="_blank" rel="noopener noreferrer">zeebe/benchmark sub-directory</a>.</p>
<p>We have now provided new <a href="https://github.com/zeebe-io/benchmark-helm" target="_blank" rel="noopener noreferrer">Benchmark Helm charts</a>, based on our Camunda Platform Helm charts. They allow us to deploy a new zeebe benchmark setup via:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl create namespace zell-chaos # create a new namespace</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubens zell-chaos  # change context to a new namespace</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># deploy zeebe benchmark cluster - without starter and worker</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm install zell-chaos \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    zeebe-benchmark/zeebe-benchmark \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    --set starter.replicas=0 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    --set worker.replicas=0</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>To deploy the model we can use <a href="https://github.com/zeebe-io/zeebe-chaos/releases/tag/zbchaos-v1.0.0" target="_blank" rel="noopener noreferrer">zbchaos v1.0.0</a>.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos deploy process --processModelPath call.bpmn </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{1 LEADER -1 call.bpmn 10  msg false 1 LEADER -1 2 LEADER -1 1677157340943 false false true false false 30 false -1 benchmark 30  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Deployed given process model call.bpmn, under key 2251799813685249!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><em>Note: Looks like we have some left-over debug logs, which we should remove.</em></p>
<p>To create an instance we can use:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify instance-creation --bpmnProcessId super</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{1 LEADER -1  10  msg false 1 LEADER -1 2 LEADER -1 1677157569058 false false true false false 30 false -1 super 30  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>After creating the instance we can observe the behavior of the Zeebe via <a href="https://grafana.dev.zeebe.io/" target="_blank" rel="noopener noreferrer">grafana</a>.</p>
<p>We can see that the processing starts immediately quite high and is continuously going on.</p>
<p><img decoding="async" loading="lazy" alt="general" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/general-96c61dbea3faf18172737f97412ce400.png" width="1842" height="421" class="img_ev3q"></p>
<p><strong>We have two instances running, one on partition three and one on partition one.</strong></p>
<p><em>One interesting fact is that the topology request rate is also up to 0.400 per second, so potentially every 2.5 seconds we send a topology request to the gateway. But there is no application deployed that does this. <a href="https://github.com/camunda/camunda/pull/11599#discussion_r1109846523" target="_blank" rel="noopener noreferrer">I have recently found out again</a>, that we have the Zeebe client usage in the gateway to request the topology. Might be worth investigating whether this is an issue.</em></p>
<p>After observing this cluster for a while we can see that after around five minutes the cluster fails. The processing for the partitions breaks down to 1/10 of what was processed before. A bit later it looks like it tries to come back but, failed again.</p>
<p><img decoding="async" loading="lazy" alt="fail-general" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/fail-general-7f21e7fd29654bb0b4bac784a956c203.png" width="1853" height="975" class="img_ev3q"></p>
<p><em>We can see in the metrics that in between also the balancing was triggered. A feature we have as part of our Benchmark Helm charts.</em></p>
<p>The logs (at stack driver) doesn't give us many insights, <a href="https://console.cloud.google.com/logs/query;query=resource.type%3D%22k8s_container%22%0Aresource.labels.project_id%3D%22zeebe-io%22%0Aresource.labels.location%3D%22europe-west1-b%22%0Aresource.labels.cluster_name%3D%22zeebe-cluster%22%0Aresource.labels.namespace_name%3D%22zell-chaos%22%0Alabels.k8s-pod%2Fapp%3D%22camunda-platform%22%0Alabels.k8s-pod%2Fapp_kubernetes_io%2Fcomponent%3D%22zeebe-broker%22%0Alabels.k8s-pod%2Fapp_kubernetes_io%2Finstance%3D%22zell-chaos%22%0Alabels.k8s-pod%2Fapp_kubernetes_io%2Fmanaged-by%3D%22Helm%22%0Alabels.k8s-pod%2Fapp_kubernetes_io%2Fname%3D%22zeebe%22%0Alabels.k8s-pod%2Fapp_kubernetes_io%2Fpart-of%3D%22camunda-platform%22;timeRange=2023-02-23T12:17:49.128812Z%2F2023-02-23T14:18:59.101Z;pinnedLogId=2023-02-23T13:13:40.945376476Z%2Fdr4gxdklsxtgx6h6;cursorTimestamp=2023-02-23T13:13:40.945376476Z?project=zeebe-io" target="_blank" rel="noopener noreferrer">except that we see that nodes becoming unhealthy</a>. Similar information we can see in the metrics, that followers are unhealthy.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Partition-1 failed, marking it as unhealthy: Broker-2{status=HEALTHY}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Detected 'UNHEALTHY' components. The current health status of components: [Partition-2{status=HEALTHY}, Partition-1{status=UNHEALTHY, issue=HealthIssue[message=null, throwable=null, cause=Broker-2-StreamProcessor-1{status=UNHEALTHY, issue=HealthIssue[message=actor appears blocked, throwable=null, cause=null]}]}, Partition-3{status=HEALTHY}]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Interesting insights we can get in our new Batch processing metrics. We see that at the beginning we use our limit of 100 commands per batch, but soon as we start with the recursion we use an enormous high batch processing command count.</p>
<p><img decoding="async" loading="lazy" alt="fail-batchprocessing.png" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/fail-batchprocessing-1db16026a70bf497036fdaf1df98bf26.png" width="1829" height="552" class="img_ev3q"></p>
<p>The new sequence metric shows similar results, so there must be a problem with not respecting the limit.</p>
<p><img decoding="async" loading="lazy" alt="sequencer" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/sequencer-e1680cd2da0acc84faf51d494411962b.png" width="1855" height="513" class="img_ev3q"></p>
<p>With this, I mark this chaos experiment as failed. We need to investigate this further and fix the related issue.<!-- -->ðŸ’¥</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="found-bugs">Found Bugs<a href="https://zeebe-io.github.io/zeebe-chaos/2023/02/23/Recursive-call-activity#found-bugs" class="hash-link" aria-label="Direct link to Found Bugs" title="Direct link to Found Bugs">â€‹</a></h2>
<ul>
<li><a href="https://github.com/zeebe-io/zeebe-chaos/issues/323" target="_blank" rel="noopener noreferrer">zbchaos logs debug message on normal usage</a></li>
<li><a href="https://github.com/camunda/camunda/issues/11799" target="_blank" rel="noopener noreferrer">Every 2.5 seconds we send a topology request, which is shown in the metrics</a></li>
<li><a href="https://github.com/camunda/camunda/issues/11798" target="_blank" rel="noopener noreferrer">Batch processing doesn't respect the limit</a></li>
</ul>]]></content:encoded>
            <category>availability</category>
        </item>
    </channel>
</rss>