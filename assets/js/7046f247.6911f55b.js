"use strict";(self.webpackChunkzell_chaos=self.webpackChunkzell_chaos||[]).push([[9711],{21206:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>c});var i=n(74848),r=n(28453);const o={layout:"posts",title:"Using flow control to handle bottleneck on exporting",date:new Date("2024-07-25T00:00:00.000Z"),categories:["performance"],tags:["availability"],authors:"rodrigo"},a="Using flow control to handle bottleneck on exporting",s={permalink:"/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-bottlenecked-exporting",editUrl:"https://github.com/zeebe-io/zeebe-chaos/blob/master/chaos-days/blog/2024-07-25-Using-flow-control-to-handle-bottlenecked-exporting/index.md",source:"@site/blog/2024-07-25-Using-flow-control-to-handle-bottlenecked-exporting/index.md",title:"Using flow control to handle bottleneck on exporting",description:"Zeebe 8.6 introduces a new unified flow control mechanism that is able to limit user commands (by default it tries to achieve 200ms response times) and rate limit writes of new records in general (disabled by default).",date:"2024-07-25T00:00:00.000Z",tags:[{inline:!0,label:"availability",permalink:"/zeebe-chaos/tags/availability"}],readingTime:4.32,hasTruncateMarker:!1,authors:[{name:"Rodrigo Lopes",title:"Associate Software Engineer @ Zeebe",url:"https://github.com/rodrigo-lourenco-lopes",imageURL:"https://github.com/rodrigo-lourenco-lopes.png",key:"rodrigo",page:null}],frontMatter:{layout:"posts",title:"Using flow control to handle bottleneck on exporting",date:"2024-07-25T00:00:00.000Z",categories:["performance"],tags:["availability"],authors:"rodrigo"},unlisted:!1,prevItem:{title:"Operate load handling",permalink:"/zeebe-chaos/2024/08/16/Operate-load-handling"},nextItem:{title:"Using flow control to handle uncontrolled process loops",permalink:"/zeebe-chaos/2024/07/25/Using-flow-control-to-handle-uncontrolled-process-loops"}},l={authorsImageUrls:[void 0]},c=[{value:"Static write limit",id:"static-write-limit",level:2},{value:"Expected",id:"expected",level:3},{value:"Actual",id:"actual",level:3},{value:"Dynamic write rate throttling",id:"dynamic-write-rate-throttling",level:2},{value:"Expected",id:"expected-1",level:3},{value:"Actual",id:"actual-1",level:3}];function d(e){const t={code:"code",h2:"h2",h3:"h3",img:"img",p:"p",pre:"pre",strong:"strong",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.p,{children:"Zeebe 8.6 introduces a new unified flow control mechanism that is able to limit user commands (by default it tries to achieve 200ms response times) and rate limit writes of new records in general (disabled by default).\nLimiting the write rate is a new feature that can be used to prevent building up an excessive exporting backlog.\nThere are two ways to limit the write rate, either by setting a static limit or by enabling throttling that dynamically adjust the write rate based on the exporting backlog and rate.\nIn these experiments, we will test both ways of limiting the write rate and observe the effects on processing and exporting."}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"TL;DR;"}),"\nBoth setting a static write rate limit and enabling throttling of the write rate can be used to prevent building up an excessive exporting backlog.\nFor users, this will be seen as backpressure because processing speed is limited by the rate at which it can write processing results."]}),"\n",(0,i.jsx)(t.h2,{id:"static-write-limit",children:"Static write limit"}),"\n",(0,i.jsx)(t.p,{children:"We will construct a cluster under normal utilization and then artificially degrade the exporting process.\nAfter this we will apply flow control settings to statically rate limit all writes.\nThe limit will be set slightly lower than the observed exporting rate."}),"\n",(0,i.jsx)(t.p,{children:"For this we will use the flow control endpoint to temporarily configure the write rate limit."}),"\n",(0,i.jsx)(t.p,{children:"To fetch the current configuration we can port forward to one of the zeebe pods and use the command:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-Shell",children:"GET /actuator/flowControl\n"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"original-configuration",src:n(52572).A+"",width:"586",height:"532"})}),"\n",(0,i.jsx)(t.p,{children:"To configure the write rate limit we use the same endpoint, for example:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:'POST /actuator/flowControl\n{\n  "write": {\n    "enabled": true,\n    "limit": 400\n  }\n}\n'})}),"\n",(0,i.jsx)(t.h3,{id:"expected",children:"Expected"}),"\n",(0,i.jsx)(t.p,{children:"When we start to degrade the exporting rate, we expect to see the exporting backlog to increase steadily."}),"\n",(0,i.jsx)(t.p,{children:"Once a static write rate limit below the degraded exporting rate is applied, we expect fewer rates and slower processing.\nThe exporting backlog should decrease again until we eventually reach zero backlog again.\nBackpressure should increase because processing has slowed down and some requests will be rejected by the write rate limit."}),"\n",(0,i.jsx)(t.h3,{id:"actual",children:"Actual"}),"\n",(0,i.jsx)(t.p,{children:"After we artificially degrade the exporter performance, we see a constant increase in records not exported since the processing is still happening at the same rate."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"exporting-per-partition",src:n(70772).A+"",width:"1999",height:"379"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"processing-per-partition",src:n(82077).A+"",width:"1999",height:"378"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"exporter-backlog",src:n(96557).A+"",width:"1362",height:"534"})}),"\n",(0,i.jsx)(t.p,{children:"After applying a static rate limit of 400 to be slightly lower than the observed 500-600 of the exporting rate, we see that the processing speed changes accordingly."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"processing-per-partition-post-rate-limit",src:n(40850).A+"",width:"1999",height:"371"})}),"\n",(0,i.jsx)(t.p,{children:"As expected we also see this reflected in backpressure that sees the user commands being rejected in a much higher portion."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"backpressure",src:n(42424).A+"",width:"1532",height:"460"})}),"\n",(0,i.jsx)(t.p,{children:"We also observe that the backlog of records not exported starts to decrease at the rate of the difference between exported and written records."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"exporter-backlog-post-rate-limit",src:n(27170).A+"",width:"1360",height:"540"})}),"\n",(0,i.jsx)(t.p,{children:"These observations match our expectations and show that a static write rate limit can be used to prevent building up an excessive exporting backlog."}),"\n",(0,i.jsx)(t.h2,{id:"dynamic-write-rate-throttling",children:"Dynamic write rate throttling"}),"\n",(0,i.jsx)(t.p,{children:"Choosing a static write rate limit is not a full solution because we can't predict the actual exporting rates.\nTo address this, we can enable write rate throttling that will dynamically adjust the write rate based on the exporting backlog and rate."}),"\n",(0,i.jsx)(t.p,{children:"To enable write rate throttling we can use the flow control endpoint again, for example:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:'POST /actuator/flowControl\n{\n  "write": {\n    "enabled": true,\n    "limit": 2500,\n    "throttling": {\n      "enabled": true,\n      "acceptableBacklog": 100000,\n      "minimumLimit": 100,\n      "resolution": "15s"\n    }\n  }\n}\n'})}),"\n",(0,i.jsx)(t.h3,{id:"expected-1",children:"Expected"}),"\n",(0,i.jsx)(t.p,{children:"Similar to the first experiment, we expect to see the exporting backlog increase when we artificially degrade the exporting performance.\nAfter enabling write rate throttling, we expect that the write rate is reduced significantly and eventually matches the exporting rate.\nThe reduced write rate should show up as backpressure.\nEventually, the exporting backlog settles at the configured acceptable backlog."}),"\n",(0,i.jsx)(t.h3,{id:"actual-1",children:"Actual"}),"\n",(0,i.jsx)(t.p,{children:"Re-running the same setup, but using the throttling of writes with an acceptable backlog at 100,000  of not exported records, and a limit higher than our processing speed (so has to not impact the experience), we get the following results:"}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"number-of-records-not-exported-post-throttling",src:n(29963).A+"",width:"1098",height:"454"})}),"\n",(0,i.jsx)(t.p,{children:"The orange underline metric displays when the throttled write rate is applied."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"exporting-per-partition-post-throttling",src:n(10978).A+"",width:"1999",height:"293"})}),"\n",(0,i.jsx)(t.p,{children:"From the panels of the \u201cExporting per Partition\u201d and \u201cNumber of records not exported\u201d, we can observe that during the re-run of the experience our artificially degrading of the exporters only affected Exporters 2 and 3.\nAfter we enable throttling, the backlog on these affected exporters starts to decrease as expected, later stabilizing on around 100,000 records.\nThis will drop back to 0 once we remove the artificial degrading of the exporters."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"backpressure-post-throttling",src:n(40765).A+"",width:"1984",height:"460"})}),"\n",(0,i.jsx)(t.p,{children:"In the backpressure, we observe that this increases mostly on the affected partitions 2 and 3, and once the number of records not exported reaches the acceptable level this lowers slightly and stabilizes."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"processing-per-partition-post-throttling",src:n(8123).A+"",width:"1999",height:"290"})}),"\n",(0,i.jsx)(t.p,{children:"Finally, on the panel that shows the processing per partition, we also confirm the expectation that since one of the exporters was not affected by the artificial degrading of the exporter, some additional traffic gets re-routed to this partition, after the throttling gets applied.\nOn the affected partitions we see the processing decreasing slightly in line with the exporting on the same partitions."}),"\n",(0,i.jsx)(t.p,{children:"Overall the observations match our expectations and show that write rate throttling succeeds and keeps exporting backlog limited."})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},42424:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/backpressure-post-rate-limit-90eba93cb2dd681bfa3d67074ff83713.png"},40765:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/backpressure-post-throttling-77bb875c059269233e3d7b30c81ca1b9.png"},70772:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/exporting-per-partition-post-degraded-exporting-45c6750dac85bf4a0a2b949833b6dfd0.png"},10978:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/exporting-per-partition-post-throttling-725f5e30d24caaef42c564ce2a986dcd.png"},96557:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/number-of-records-not-exported-post-degraded-exporting-6df4c3931c2367ce522bac8f9a3a7698.png"},27170:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/number-of-records-not-exported-post-rate-limit-0e96e608f6826f596b09a32806640ea3.png"},29963:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/number-of-records-not-exported-post-throttling-89e888362474746d19c4047766c42cd0.png"},52572:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/original-configuration-568ece5f5f513848f06d772b821f7ba6.png"},82077:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/processing-per-partition-post-degraded-exporting-0e056df5c7a61f47f01c6a3cee5a3c41.png"},40850:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/processing-per-partition-post-rate-limit-3cf3e06b8171ca675e12333dce4385aa.png"},8123:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/processing-per-partition-post-throttling-9aa68235837dd795cbb5a10bd875f3b5.png"},28453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>s});var i=n(96540);const r={},o=i.createContext(r);function a(e){const t=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),i.createElement(o.Provider,{value:t},e.children)}}}]);