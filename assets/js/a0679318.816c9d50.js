"use strict";(self.webpackChunkzell_chaos=self.webpackChunkzell_chaos||[]).push([[1662],{48839:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>o,contentTitle:()=>r,default:()=>h,frontMatter:()=>s,metadata:()=>c,toc:()=>l});var n=a(85893),i=a(11151);const s={layout:"posts",title:"Using Large Multi-Instance",date:new Date("2023-06-02T00:00:00.000Z"),categories:["chaos_experiment","bpmn"],tags:["availability"],authors:"zell"},r="Chaos Day Summary",c={permalink:"/zeebe-chaos/2023/06/02/Using-Large-Multi-Instance",editUrl:"https://github.com/zeebe-io/zeebe-chaos/blob/master/chaos-days/blog/2023-06-02-Using-Large-Multi-Instance/index.md",source:"@site/blog/2023-06-02-Using-Large-Multi-Instance/index.md",title:"Using Large Multi-Instance",description:"New day new chaos. In today's chaos day I want to pick up a topic, which had bothered people for long time. I created a chaos day three years ago around this topic as well.",date:"2023-06-02T00:00:00.000Z",formattedDate:"June 2, 2023",tags:[{label:"availability",permalink:"/zeebe-chaos/tags/availability"}],readingTime:5.77,hasTruncateMarker:!0,authors:[{name:"Christopher Zell",title:"Chaos Engineer @ Zeebe",url:"https://github.com/zelldon",imageURL:"https://github.com/zelldon.png",key:"zell"}],frontMatter:{layout:"posts",title:"Using Large Multi-Instance",date:"2023-06-02T00:00:00.000Z",categories:["chaos_experiment","bpmn"],tags:["availability"],authors:"zell"},unlisted:!1,prevItem:{title:"Hot backups impact on processing",permalink:"/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing"},nextItem:{title:"Continuing SST Partitioning toggle",permalink:"/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle"}},o={authorsImageUrls:[void 0]},l=[{value:"Chaos Experiment",id:"chaos-experiment",level:2},{value:"Expected",id:"expected",level:3},{value:"Actual",id:"actual",level:3},{value:"Starting small (20k)",id:"starting-small-20k",level:4},{value:"Increase collection (200k)",id:"increase-collection-200k",level:4},{value:"Make it really big (2 million)",id:"make-it-really-big-2-million",level:4},{value:"Results",id:"results",level:3},{value:"Found Bugs",id:"found-bugs",level:2}];function p(e){const t={a:"a",code:"code",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.a)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(t.p,{children:["New day new chaos. ","\ud83d\udc80"," In today's chaos day I want to pick up a topic, which had bothered people for long time. I created a ",(0,n.jsx)(t.a,{href:"https://zeebe-io.github.io/zeebe-chaos/2020/07/16/big-multi-instance/",children:"chaos day three years ago"})," around this topic as well."]}),"\n",(0,n.jsxs)(t.p,{children:["Today, we experiment with large multi-instances again. In the recent patch release ",(0,n.jsx)(t.a,{href:"https://github.com/camunda/zeebe/releases/tag/8.2.5",children:"8.2.5"})," we fixed an issue with spawning larger multi instances. Previously if you have created a process instance with a large multi-instance it was likely that this caused to blacklist the process instance, since the multi-instance spawning ran into ",(0,n.jsx)(t.code,{children:"maxMessageSize"})," limitations."]}),"\n",(0,n.jsx)(t.p,{children:"This means the process instance was stuck and was no longer executable. In Operate this was not shown and caused a lot of friction or confusion to users. With the recent fix, Zeebe should chunk even large collections into smaller batches to spawn/execute the multi-instance without any issues."}),"\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"TL;DR;"})," We were able to see that even large multi-instances can be executed now. ","\u2705"," At some point, we experienced performance regressions (during creating new multi-instance elements) but the execution of the process instance doesn't fail anymore. One problem at a time, we will likely investigate further to improve the performance of such a use case."]}),"\n",(0,n.jsxs)(t.p,{children:["When we reached the ",(0,n.jsx)(t.code,{children:"maxMessageSize"})," we got a rejection, if the input collection is too large we see some weird unexpected errors from NGINX."]}),"\n",(0,n.jsx)(t.h2,{id:"chaos-experiment",children:"Chaos Experiment"}),"\n",(0,n.jsxs)(t.p,{children:["We do regularly game days in Camunda, and for such we also create projects to make incidents, etc. reproducible. In today's chaos day, I will reuse some code created by ",(0,n.jsx)(t.a,{href:"https://github.com/saig0",children:"Philipp Ossler"}),", thanks for that :bow: Since we mimic in such game days customers, the process is a bit more complex than necessary for such chaos day, but I will keep it like that."]}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"order-process",src:a(63238).Z+"",width:"3213",height:"1152"})}),"\n",(0,n.jsxs)(t.p,{children:["The input collection ",(0,n.jsx)(t.code,{children:"items"}),", which is used in the multi-instance is generated via:"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-shell",children:'    // input size\n    final var items = IntStream.range(0, size).mapToObj(i -> Map.ofEntries(\n        entry("id", i)\n    )).toList();\n'})}),"\n",(0,n.jsxs)(t.p,{children:["In the following experiment, we will play around with the ",(0,n.jsx)(t.code,{children:"size"})," value."]}),"\n",(0,n.jsxs)(t.p,{children:["For the experiment, we will use a Camunda 8 SaaS cluster with the generation ",(0,n.jsx)(t.code,{children:"Zeebe 8.2.5"})," (G3-S)."]}),"\n",(0,n.jsx)(t.h3,{id:"expected",children:"Expected"}),"\n",(0,n.jsx)(t.p,{children:"When creating a process instance with a large collection, we expect based on the recent bug fix that the multi-instance creation is batched and created without issues."}),"\n",(0,n.jsxs)(t.p,{children:["One limiting factor might be the ",(0,n.jsx)(t.code,{children:"maxMessageSize"})," with regard to the input collection, but in this case, I would expect that the creation of the process instance is already rejected before."]}),"\n",(0,n.jsx)(t.h3,{id:"actual",children:"Actual"}),"\n",(0,n.jsx)(t.p,{children:"Between the following experiments, I always recreated the clusters, to reduce the blast radius and better understand and isolate the impact."}),"\n",(0,n.jsx)(t.h4,{id:"starting-small-20k",children:"Starting small (20k)"}),"\n",(0,n.jsxs)(t.p,{children:["In previous versions, the multi-instance creation failed already quite early. For example in the game day reproducer project, we had a collection defined with ",(0,n.jsx)(t.code,{children:"20.000"})," items, which we are now reusing for the start."]}),"\n",(0,n.jsx)(t.p,{children:"The creation of the process instance worked without any issues. We can observe in Operate the incremental creation of sub-process instances, which is great."}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"incremental-creation-20k",src:a(65146).Z+"",width:"1757",height:"868"})}),"\n",(0,n.jsx)(t.p,{children:'We can see in the metrics that batch processing is limited by only 2-4 commands in a batch. That is an interesting fact that might explain why it takes a while until all instances of the multi-instance sub-process are created. We can even see rollbacks during batch processing, visible in the "Number of batch processing retries" panel.'}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"processing-metrics-20k",src:a(23113).Z+"",width:"1894",height:"755"})}),"\n",(0,n.jsx)(t.p,{children:"The processing queue seems to increase dramatically."}),"\n",(0,n.jsxs)(t.p,{children:["After a while, we can see that all 20k instances are created without any bigger issues. ","\ud83d\ude80"]}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"complete-20k",src:a(5069).Z+"",width:"1912",height:"834"})}),"\n",(0,n.jsx)(t.p,{children:"It took around 10 minutes. Taking a look at the metrics again we see that in between big command batches have been created/processed, which allowed us to reduce the processing queue."}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"processing-metrics-20k-pt2",src:a(10350).Z+"",width:"1896",height:"762"})}),"\n",(0,n.jsxs)(t.p,{children:["In between the backpressure was quite high, but after the creation of all instances, the cluster is in a healthy state again. The creation of such multi-instance worked ","\u2705"]}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"general-metrics-20k",src:a(71187).Z+"",width:"1893",height:"940"})}),"\n",(0,n.jsx)(t.h4,{id:"increase-collection-200k",children:"Increase collection (200k)"}),"\n",(0,n.jsx)(t.p,{children:"Again, the creation of such a process instance was not a problem itself. We can observe the creation of the sub-process instances (multi-instance) in Operate, which happens incrementally."}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"incremental-creation-200k",src:a(26642).Z+"",width:"1905",height:"871"})}),"\n",(0,n.jsx)(t.p,{children:"It takes ages until the instances are created (After 3h ~66k instances are created). Again we see here small chunks of batches, and there are also rollbacks during batch processing."}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"processing-metrics-200k",src:a(95471).Z+"",width:"1881",height:"753"})}),"\n",(0,n.jsxs)(t.p,{children:["The processing of that partitions is in this case blocked by the multi-instance creation, we can see that on the 100% back pressure. ","\u274c"]}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"general-metrics-200k",src:a(83750).Z+"",width:"1883",height:"868"})}),"\n",(0,n.jsx)(t.p,{children:"Even after one hour, not all instances are created (not even 20k), it takes longer than before the creation of 20.000 instances."}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"incremental-creation-200k-part2",src:a(92722).Z+"",width:"2251",height:"931"})}),"\n",(0,n.jsx)(t.h4,{id:"make-it-really-big-2-million",children:"Make it really big (2 million)"}),"\n",(0,n.jsx)(t.p,{children:"To escalate this even more I increase the input collection again by a factor of 10 to 2 million."}),"\n",(0,n.jsx)(t.p,{children:"After creation, I see as a response the following log message in my log:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:"Failed to create process instance of 'order-process'\n\nio.camunda.zeebe.client.api.command.ClientStatusException: HTTP status code 502\ninvalid content-type: text/html\nheaders: Metadata(:status=502,date=Fri, 02 Jun 2023 11:44:57 GMT,content-type=text/html,strict-transport-security=max-age=63072000; includeSubDomains,content-length=150)\nDATA-----------------------------\n<html>\n<head><title>502 Bad Gateway</title></head>\n<body>\n<center><h1>502 Bad Gateway</h1></center>\n<hr><center>nginx</center>\n</body>\n</html>\n\n\tat io.camunda.zeebe.client.impl.ZeebeClientFutureImpl.transformExecutionException(ZeebeClientFutureImpl.java:93) ~[zeebe-client-java-8.0.5.jar:8.0.5]\n\tat io.camunda.zeebe.client.impl.ZeebeClientFutureImpl.join(ZeebeClientFutureImpl.java:50) ~[zeebe-client-java-8.0.5.jar:8.0.5]\n\tat io.camunda.cloud.gameday.ProcessApplication.createProcessInstance(ProcessApplication.java:90) ~[classes/:na]\n\tat io.camunda.cloud.gameday.ProcessApplication.createInstanceOfProcess(ProcessApplication.java:71) ~[classes/:na]\n\tat io.camunda.cloud.gameday.ProcessApplication.run(ProcessApplication.java:58) ~[classes/:na]\n\tat org.springframework.boot.SpringApplication.callRunner(SpringApplication.java:791) ~[spring-boot-2.5.2.jar:2.5.2]\n\tat org.springframework.boot.SpringApplication.callRunners(SpringApplication.java:775) ~[spring-boot-2.5.2.jar:2.5.2]\n\tat org.springframework.boot.SpringApplication.run(SpringApplication.java:345) ~[spring-boot-2.5.2.jar:2.5.2]\n\tat org.springframework.boot.SpringApplication.run(SpringApplication.java:1343) ~[spring-boot-2.5.2.jar:2.5.2]\n\tat org.springframework.boot.SpringApplication.run(SpringApplication.java:1332) ~[spring-boot-2.5.2.jar:2.5.2]\n\tat io.camunda.cloud.gameday.ProcessApplication.main(ProcessApplication.java:46) ~[classes/:na]\nCaused by: java.util.concurrent.ExecutionException: io.grpc.StatusRuntimeException: UNAVAILABLE: HTTP status code 502\ninvalid content-type: text/html\nheaders: Metadata(:status=502,date=Fri, 02 Jun 2023 11:44:57 GMT,content-type=text/html,strict-transport-security=max-age=63072000; includeSubDomains,content-length=150)\nDATA-----------------------------\n<html>\n<head><title>502 Bad Gateway</title></head>\n<body>\n<center><h1>502 Bad Gateway</h1></center>\n<hr><center>nginx</center>\n</body>\n</html>\n\n\tat java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396) ~[na:na]\n\tat java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073) ~[na:na]\n\tat io.camunda.zeebe.client.impl.ZeebeClientFutureImpl.join(ZeebeClientFutureImpl.java:48) ~[zeebe-client-java-8.0.5.jar:8.0.5]\n\t... 9 common frames omitted\n"})}),"\n",(0,n.jsx)(t.p,{children:"I tried to incrementally decrease the input collection until it is working again, when reaching 250k I finally see a better understandable error."}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-shell",children:"2023-06-02 13:53:51.485 ERROR 29870 --- [           main] i.c.cloud.gameday.ProcessApplication     : Failed to create process instance of 'order-process'\n\nio.camunda.zeebe.client.api.command.ClientStatusException: Command 'CREATE' rejected with code 'EXCEEDED_BATCH_RECORD_SIZE': \n\tat io.camunda.zeebe.client.impl.ZeebeClientFutureImpl.transformExecutionException(ZeebeClientFutureImpl.java:93) ~[zeebe-client-java-8.0.5.jar:8.0.5]\n\tat io.camunda.zeebe.client.impl.ZeebeClientFutureImpl.join(ZeebeClientFutureImpl.java:50) ~[zeebe-client-java-8.0.5.jar:8.0.5]\n\tat io.camunda.cloud.gameday.ProcessApplication.createProcessInstance(ProcessApplication.java:90) ~[classes/:na]\n\tat io.camunda.cloud.gameday.ProcessApplication.createInstanceOfProcess(ProcessApplication.java:71) ~[classes/:na]\n\tat io.camunda.cloud.gameday.ProcessApplication.run(ProcessApplication.java:58) ~[classes/:na]\n\tat org.springframework.boot.SpringApplication.callRunner(SpringApplication.java:791) ~[spring-boot-2.5.2.jar:2.5.2]\n\tat org.springframework.boot.SpringApplication.callRunners(SpringApplication.java:775) ~[spring-boot-2.5.2.jar:2.5.2]\n\tat org.springframework.boot.SpringApplication.run(SpringApplication.java:345) ~[spring-boot-2.5.2.jar:2.5.2]\n\tat org.springframework.boot.SpringApplication.run(SpringApplication.java:1343) ~[spring-boot-2.5.2.jar:2.5.2]\n\tat org.springframework.boot.SpringApplication.run(SpringApplication.java:1332) ~[spring-boot-2.5.2.jar:2.5.2]\n\tat io.camunda.cloud.gameday.ProcessApplication.main(ProcessApplication.java:46) ~[classes/:na]\nCaused by: java.util.concurrent.ExecutionException: io.grpc.StatusRuntimeException: UNKNOWN: Command 'CREATE' rejected with code 'EXCEEDED_BATCH_RECORD_SIZE': \n\tat java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396) ~[na:na]\n\tat java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073) ~[na:na]\n\tat io.camunda.zeebe.client.impl.ZeebeClientFutureImpl.join(ZeebeClientFutureImpl.java:48) ~[zeebe-client-java-8.0.5.jar:8.0.5]\n\t... 9 common frames omitted\nCaused by: io.grpc.StatusRuntimeException: UNKNOWN: Command 'CREATE' rejected with code 'EXCEEDED_BATCH_RECORD_SIZE': \n\tat io.grpc.Status.asRuntimeException(Status.java:535) ~[grpc-api-1.45.1.jar:1.45.1]\n\tat io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:478) ~[grpc-stub-1.45.1.jar:1.45.1]\n\tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:562) ~[grpc-core-1.45.1.jar:1.45.1]\n\tat io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70) ~[grpc-core-1.45.1.jar:1.45.1]\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:743) ~[grpc-core-1.45.1.jar:1.45.1]\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:722) ~[grpc-core-1.45.1.jar:1.45.1]\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37) ~[grpc-core-1.45.1.jar:1.45.1]\n\tat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133) ~[grpc-core-1.45.1.jar:1.45.1]\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]\n\tat java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]\n\n2023-06-02 13:53:51.485  INFO 29870 --- [           main] i.c.cloud.gameday.ProcessApplication     : Created process instances with large collection. [order-id: 'ba65b59b-1584-48bb-af05-3724ea15fac9']\n\n"})}),"\n",(0,n.jsx)(t.h3,{id:"results",children:"Results"}),"\n",(0,n.jsx)(t.p,{children:"As we have seen above we are able now to create much larger multi instances than before, with some drawbacks in performance, which needs to be investigated further."}),"\n",(0,n.jsx)(t.p,{children:"When reaching a certain limit (maxMessageSize) we get a described rejection by the broker, until we reach the limit of NGINX where the description is not that optimal. Here we can and should improve further."}),"\n",(0,n.jsx)(t.h2,{id:"found-bugs",children:"Found Bugs"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["in a previous test I run into ",(0,n.jsx)(t.a,{href:"https://github.com/camunda/zeebe/issues/12918",children:"https://github.com/camunda/zeebe/issues/12918"})]}),"\n",(0,n.jsxs)(t.li,{children:["Related bug regarding the input collection ",(0,n.jsx)(t.a,{href:"https://github.com/camunda/zeebe/issues/12873",children:"https://github.com/camunda/zeebe/issues/12873"})]}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,i.a)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(p,{...e})}):p(e)}},83750:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/200k-general-metrics-3975fc0c4c761c321194cd69598a8d11.png"},26642:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/200k-operate-inc-586ee3f6c124c92cc6700df1b6213950.png"},92722:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/200k-operate-inc2-8e393502149c7dc21706229b02979515.png"},95471:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/200k-processing-metrics-7a21b4741eec54581b30f819b05f3de2.png"},71187:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/20k-general-metrics-a525d7f1500dac0fd03d460b849e12e4.png"},5069:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/20k-operate-complete-31c5d2b848c51c7b1a96e8dc6f23b5d6.png"},65146:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/20k-operate-inc-b0e507b77799c7f950ff444259c8341f.png"},10350:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/20k-processing-metrics-2-7976048beb0f6300cf5577d40f2c9f47.png"},23113:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/20k-processing-metrics-f3f057027ec451f9024d242df2d1bef6.png"},63238:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/order-process-0eb9e9dc5b698919f847deb859f67f2d.png"},11151:(e,t,a)=>{a.d(t,{Z:()=>c,a:()=>r});var n=a(67294);const i={},s=n.createContext(i);function r(e){const t=n.useContext(s);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function c(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),n.createElement(s.Provider,{value:t},e.children)}}}]);